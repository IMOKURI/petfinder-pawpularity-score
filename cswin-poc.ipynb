{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226c6f70-8b48-44ee-aa8c-aacc3bc0610d",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daba7563-6fba-48ca-b651-43afb0b59939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from box import Box\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90bb98a-b280-496d-8b1c-1ea9497257c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63bb88dc-e655-48be-a5c9-b8ecac004caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../input/CSWin-Transformer', '../input/CSWin-Transformer', '/data/jupyter/sugiyama/petfinder2/working', '/opt/miniconda3/envs/all-in-one/lib/python38.zip', '/opt/miniconda3/envs/all-in-one/lib/python3.8', '/opt/miniconda3/envs/all-in-one/lib/python3.8/lib-dynload', '', '/home/sugiyama/.local/lib/python3.8/site-packages', '/opt/miniconda3/envs/all-in-one/lib/python3.8/site-packages', '/opt/miniconda3/envs/all-in-one/lib/python3.8/site-packages/IPython/extensions', '/home/sugiyama/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# Additional local libraries\n",
    "\n",
    "# https://github.com/microsoft/CSWin-Transformer\n",
    "sys.path.insert(0, \"../input/CSWin-Transformer\")\n",
    "print(sys.path)\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206e3ae0-56bb-4825-8c5b-4a7fc9b467cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9655a4-bdf6-44c7-84e6-fe7bd4d2768f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93a47c5-1b4d-4083-a201-a146961eac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "# !rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06f6602b-96bb-461d-a790-b91c08f85a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2445e41-8256-44c9-a4fc-9253ce54ea3c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c718c5ff-9cc6-494b-bb5a-6d6f93e7f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4a2d5b2-0263-4bb0-8ac4-9dc764126419",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"momentum\": 0.9,\n",
    "    # \"model_name\": \"CSWin_144_24322_large_384\",\n",
    "    \"model_name\": \"swin_large_patch4_window12_384_in22k\",\n",
    "    \"size\": 384,\n",
    "    # \"models\": [\n",
    "    #     \"swin_large_patch4_window12_384_in22k:v14\",\n",
    "    # ],\n",
    "    # \"runs\": [\n",
    "    #     \"34qor14i\",  # swin large v14\n",
    "    #     \"tmbsq7j1\",  # swin base v1\n",
    "    # ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ecbb90-0191-430e-a63a-3cbdb798bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Box(config_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c3278e-527c-4e66-a9d2-76d6b3e564e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4bfc2-580e-40a8-ac36-1e645c88018a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5dfd5ad-5e12-44f2-b65c-5a55f108db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eadb29e-8fe9-469b-bd82-c6b093239470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0660322-5256-49eb-a1e0-0cc79e880cca",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa00a7c4-ef14-4c38-8bbd-455881251b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"attn_drop_rate\": 0.1,\n",
    "    \"drop_rate\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c042e832-6941-4e25-9576-b30fd494b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(self.model_name, pretrained=pretrained, num_classes=config.n_class, **params)\n",
    "\n",
    "        if \"convmixer\" in self.model_name:\n",
    "            self.head = nn.Linear(1000, config.n_class)\n",
    "\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        if \"convmixer\" in self.model_name:\n",
    "            x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a801f7-de3e-49e2-8b78-a709c9ee315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (model): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.2, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (0): BasicLayer(\n",
      "        dim=192, input_resolution=(96, 96), depth=2\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          input_resolution=(96, 96), dim=192\n",
      "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        dim=384, input_resolution=(48, 48), depth=2\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          input_resolution=(48, 48), dim=384\n",
      "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        dim=768, input_resolution=(24, 24), depth=18\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (12): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (13): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (14): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (15): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (16): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (17): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          input_resolution=(24, 24), dim=768\n",
      "          (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        dim=1536, input_resolution=(12, 12), depth=2\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "              (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "              (proj_drop): Dropout(p=0.2, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "              (drop): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "    (head): Linear(in_features=1536, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[ 0.3039],\n",
      "        [ 0.0234],\n",
      "        [-0.1107],\n",
      "        [ 0.0243]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(config.model_name)\n",
    "print(model)\n",
    "\n",
    "train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "for image, feature, label in train_loader:\n",
    "    output = model(image, feature)\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07899cba-fa01-4ffd-9971-ee47e58c5bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
