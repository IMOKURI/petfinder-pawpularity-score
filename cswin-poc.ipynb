{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226c6f70-8b48-44ee-aa8c-aacc3bc0610d",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daba7563-6fba-48ca-b651-43afb0b59939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from box import Box\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90bb98a-b280-496d-8b1c-1ea9497257c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bb88dc-e655-48be-a5c9-b8ecac004caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../input/CSWin-Transformer', '/data/jupyter/sugiyama/petfinder2/working', '/opt/miniconda3/envs/all-in-one/lib/python38.zip', '/opt/miniconda3/envs/all-in-one/lib/python3.8', '/opt/miniconda3/envs/all-in-one/lib/python3.8/lib-dynload', '', '/home/sugiyama/.local/lib/python3.8/site-packages', '/opt/miniconda3/envs/all-in-one/lib/python3.8/site-packages', '/opt/miniconda3/envs/all-in-one/lib/python3.8/site-packages/IPython/extensions', '/home/sugiyama/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# Additional local libraries\n",
    "\n",
    "# https://github.com/microsoft/CSWin-Transformer\n",
    "sys.path.insert(0, \"../input/CSWin-Transformer\")\n",
    "print(sys.path)\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206e3ae0-56bb-4825-8c5b-4a7fc9b467cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9655a4-bdf6-44c7-84e6-fe7bd4d2768f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93a47c5-1b4d-4083-a201-a146961eac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "# !rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f6602b-96bb-461d-a790-b91c08f85a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2445e41-8256-44c9-a4fc-9253ce54ea3c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c718c5ff-9cc6-494b-bb5a-6d6f93e7f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a2d5b2-0263-4bb0-8ac4-9dc764126419",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"momentum\": 0.9,\n",
    "    \"model_name\": \"CSWin_144_24322_large_384\",\n",
    "    \"size\": 384,\n",
    "    # \"models\": [\n",
    "    #     \"swin_large_patch4_window12_384_in22k:v14\",\n",
    "    # ],\n",
    "    # \"runs\": [\n",
    "    #     \"34qor14i\",  # swin large v14\n",
    "    #     \"tmbsq7j1\",  # swin base v1\n",
    "    # ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ecbb90-0191-430e-a63a-3cbdb798bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Box(config_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c3278e-527c-4e66-a9d2-76d6b3e564e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4bfc2-580e-40a8-ac36-1e645c88018a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dfd5ad-5e12-44f2-b65c-5a55f108db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eadb29e-8fe9-469b-bd82-c6b093239470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0660322-5256-49eb-a1e0-0cc79e880cca",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c042e832-6941-4e25-9576-b30fd494b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    # @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        x = self.head1(x)\n",
    "        x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a801f7-de3e-49e2-8b78-a709c9ee315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (model): CSWinTransformer(\n",
      "    (stage1_conv_embed): Sequential(\n",
      "      (0): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
      "      (1): Rearrange('b c h w -> b (h w) c', h=96, w=96)\n",
      "      (2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (stage1): ModuleList(\n",
      "      (0): CSWinBlock(\n",
      "        (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
      "        (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=144, out_features=576, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=576, out_features=144, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): CSWinBlock(\n",
      "        (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
      "        (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=144, out_features=576, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=576, out_features=144, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (merge1): Merge_Block(\n",
      "      (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (stage2): ModuleList(\n",
      "      (0): CSWinBlock(\n",
      "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
      "        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): CSWinBlock(\n",
      "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
      "        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): CSWinBlock(\n",
      "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
      "        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): CSWinBlock(\n",
      "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
      "        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (merge2): Merge_Block(\n",
      "      (conv): Conv2d(288, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (stage3): ModuleList(\n",
      "      (0): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (12): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (13): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (14): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (15): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (16): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (17): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (18): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (19): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (20): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (21): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (22): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (23): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (24): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (25): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (26): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (27): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (28): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (29): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (30): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (31): CSWinBlock(\n",
      "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
      "        (norm1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): LePEAttention(\n",
      "            (get_v): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2304, out_features=576, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (merge3): Merge_Block(\n",
      "      (conv): Conv2d(576, 1152, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (stage4): ModuleList(\n",
      "      (0): CSWinBlock(\n",
      "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "        (norm1): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1152, out_features=4608, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4608, out_features=1152, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): CSWinBlock(\n",
      "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "        (norm1): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (attns): ModuleList(\n",
      "          (0): LePEAttention(\n",
      "            (get_v): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1152, out_features=4608, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4608, out_features=1152, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=1152, out_features=128, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (head1): Linear(in_features=140, out_features=64, bias=True)\n",
      "  (head2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(config.model_name)\n",
    "print(model)\n",
    "\n",
    "train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "for image, feature, label in train_loader:\n",
    "    output = model(image, feature)\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07899cba-fa01-4ffd-9971-ee47e58c5bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
