{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YDQH4n9zdG"
   },
   "source": [
    "# ðŸ“” About this notebook\n",
    "\n",
    "PetFinder.my - Pawpularity Contest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0pnACt-CQd"
   },
   "source": [
    "## ðŸ“ Memo\n",
    "\n",
    "- transformer ã® output ã¨ feature ã‚’ SVR ã§å­¦ç¿’ã™ã‚‹ã€‚\n",
    "    - NN ã® head ã¨ SVR ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã™ã‚‹ã€‚ [Link](https://www.kaggle.com/cdeotte/rapids-svr-boost-17-8/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eezrDVYa_yav"
   },
   "source": [
    "# ðŸ“š Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1633394791716,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "32GYVF3l_wUO"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1633394792859,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "DhlpmaPbNqOs"
   },
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633394792860,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qPMtyPp8AWvZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ZHMIcuPvAdZI",
    "outputId": "8b28afb5-3466-40d4-9d0f-7a7a43f786b1"
   },
   "outputs": [],
   "source": [
    "# netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
    "# !cp -f {netrc} ~/\n",
    "!wandb login\n",
    "wandb_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "KPb3f6kLAYrP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uOtCk2BKGF"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m4LaDlPJBLil"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "!rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "xKKkrScBBf44"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQk8_n-5Bwun"
   },
   "source": [
    "# ðŸ›  Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "HfK7G4EQBxpt",
    "outputId": "266be0c6-6b79-4de4-8de1-8502eb577dc2"
   },
   "outputs": [],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "STqXGbUhBz5f"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    wandb_entity = \"imokuri\"\n",
    "    wandb_project = \"petfinder2\"\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    validate = False\n",
    "    inference = False\n",
    "\n",
    "    debug = True\n",
    "    num_debug_data = 1000\n",
    "\n",
    "    amp = True\n",
    "    multi_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAK99CZOhfMV"
   },
   "source": [
    "Model examples\n",
    "\n",
    "- resnext50_32x4d\n",
    "- vit_base_patch16_384\n",
    "- tf_efficientnetv2_m_in21k\n",
    "- swin_large_patch4_window12_384_in22k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "Vjl7MQHiFyFS"
   },
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"momentum\": 0.9,\n",
    "    \"model_name\": \"swin_large_patch4_window12_384_in22k\",\n",
    "    \"size\": 384,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "dgConxiYIqTM"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config_defaults[\"n_fold\"] = 3\n",
    "    config_defaults[\"epochs\"] = 1\n",
    "    Config.print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BteR9_gVItes"
   },
   "outputs": [],
   "source": [
    "if Config.train:\n",
    "    wandb_job_type = \"training\"\n",
    "\n",
    "elif Config.inference:\n",
    "    wandb_job_type = \"inference\"\n",
    "\n",
    "elif Config.validate:\n",
    "    wandb_job_type = \"validation\"\n",
    "\n",
    "else:\n",
    "    wandb_job_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "wBSFI0-_XL_-"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    wandb_tags.append(\"debug\")\n",
    "\n",
    "# if Config.amp:\n",
    "#     wandb_tags.append(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "LIDKN-b7jDOt"
   },
   "outputs": [],
   "source": [
    "# wandb_tags.append(\"feats\")\n",
    "wandb_tags.append(\"bins kfold\")\n",
    "wandb_tags.append(\"basic aug\")\n",
    "# wandb_tags.append(\"heavy aug\")\n",
    "# wandb_tags.append(\"mixup\")\n",
    "# wandb_tags.append(\"cutmix\")\n",
    "# wandb_tags.append(\"freeze norm\")\n",
    "# wandb_tags.append(\"crop image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1633394796778,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JaQsAlSfJbnt"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        tags=wandb_tags,\n",
    "        mode=\"disabled\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        job_type=wandb_job_type,\n",
    "        tags=wandb_tags,\n",
    "        save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633394796783,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0kD8_kP0JjAC"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYjWTUW9Jtem"
   },
   "source": [
    "# EDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1633394796784,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "-dEUJ_P9Jwzw",
    "outputId": "f98c8f40-5d7e-43f5-f524-58129cd3c758"
   },
   "outputs": [],
   "source": [
    "for df in [train, test, sub]:\n",
    "    print(f\"=\" * 120)\n",
    "    df.info()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1633394797327,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "uK-vChyCKVhZ",
    "outputId": "3d5cf17f-3df5-4163-a7ba-be4bd83f6211"
   },
   "outputs": [],
   "source": [
    "sns.distplot(train[\"Pawpularity\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nN20A-4KeX2"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDt-OBGKg33"
   },
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m2XP3TB7KhvW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFYIILAsKih4"
   },
   "source": [
    "# ðŸ‘‘ Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ahzUGk4sK6te"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "    if len(sub) > Config.num_debug_data:\n",
    "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF4pvz7-L7qT"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qrlmhizKMCku"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClI1iqtWLqU0"
   },
   "source": [
    "# Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BQVW6__Rjk_N"
   },
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(1 + np.log2(len(train))))\n",
    "train.loc[:, \"bins\"] = pd.cut(train[\"Pawpularity\"], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "raBuQ3EjLsmo",
    "outputId": "11fbcaa3-b48c-4143-c742-b0de3e717a2d"
   },
   "outputs": [],
   "source": [
    "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
    "print(train.groupby([\"fold\", \"bins\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKN3QPeMMFf"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"crop image\" in wandb_tags:\n",
    "    TRAIN_IMAGE_PATH = DATA_DIR + \"crop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "pX4piTk2MPVR"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\", \"fold\", \"bins\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1633394798564,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0CIysnf0OhGK",
    "outputId": "dca880e9-0d92-43e7-82e2-a11ecacb54c1"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train)\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797328,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "yJhnZyCOKf_8"
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    if data == \"train\":\n",
    "        if \"basic aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if \"heavy aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                    # A.CoarseDropout(p=0.5),\n",
    "                    # A.Cutout(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798565,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JwLeTm_EP9kK",
    "outputId": "9193e65d-197d-4e17-91d7-ee026dc0d38a"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = cutmix(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BqcwfvhMterO"
   },
   "outputs": [],
   "source": [
    "# https://github.com/yuhao318/mwh/blob/main/utils.py\n",
    "def mixup(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "\n",
    "    \"\"\"Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam = max(lam, 1 - lam)\n",
    "        # lam = min(lam, 1-lam)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    ## NO SYM\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # return mixed_image, mixed_label, lam\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "CiCqVeWhh2gr",
    "outputId": "81496b08-c725-48b9-ad02-573eb0346269"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = mixup(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbrC2J4KPEp4"
   },
   "source": [
    "# ðŸš— Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798566,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "827lYLgIPFyY"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        x = self.head1(x)\n",
    "        x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model):\n",
    "    model.train()\n",
    "\n",
    "    # Freeze layer normalization\n",
    "    if any(key in config.model_name for key in [\"vit\", \"swin\"]):\n",
    "        for m in model.modules():\n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.LayerNorm):\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83590,
     "status": "ok",
     "timestamp": 1633394882149,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "oudAIpPqQt6z",
    "outputId": "32564315-dd7d-4bc9-f24b-620488993b3a"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    model.apply(train_mode)\n",
    "\n",
    "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
    "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa8k53cRIi_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbkDI8DdRJ5w"
   },
   "outputs": [],
   "source": [
    "# https://github.com/davda54/sam/blob/main/sam.py\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFMHkJIMRLBi"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6jKOTHURLxM"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbNT_NeRMoB"
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4EF_M0NROIn"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fQUwt7adOSk"
   },
   "outputs": [],
   "source": [
    "def get_result(result_df, fold=config.n_fold):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"Pawpularity\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    if fold == config.n_fold:\n",
    "        wandb.log({\"Score\": score})\n",
    "    else:\n",
    "        wandb.log({f\"Score_fold{fold}\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Ga4Bb8RQsF"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRPW8QwiRbPC"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23roIn-jhfMe"
   },
   "outputs": [],
   "source": [
    "# https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_preds = None\n",
    "\n",
    "    def __call__(self, val_loss, score, model, preds):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss >= self.val_loss_min + self.delta:\n",
    "            if self.patience <= 0:\n",
    "                return\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9Kcw2bdeZR4"
   },
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2.0):\n",
    "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = [p for p in parameters if p.grad is not None]\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWtO4py7Rcud"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    if \"freeze norm\" in wandb_tags:\n",
    "        model.apply(train_mode)\n",
    "    else:\n",
    "        model.train()\n",
    "    start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            mix_decision = 1.0\n",
    "        else:\n",
    "            mix_decision = np.random.rand()\n",
    "\n",
    "        if epoch >= config.epochs - 5:\n",
    "            mix_decision *= 2\n",
    "\n",
    "        if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "            images, features, label_a, label_b, lam = mixup(images, features, labels, alpha=0.5)\n",
    "\n",
    "        with amp.autocast(enabled=Config.amp):\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "            if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "            else:\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "\n",
    "                def closure():\n",
    "                    # y_preds = model(images, features)\n",
    "                    y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "                    if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                        loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "                    else:\n",
    "                        loss = criterion(y_preds, labels)\n",
    "\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "                scaler.step(optimizer, closure)\n",
    "            else:\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            grad_norm = compute_grad_norm(model.parameters())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_lr()[0]:.2e}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlPZYJYgXRZ4"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ybZNlV6YEp8"
   },
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JIDycP9YFvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mwWqWJdX232"
   },
   "source": [
    "# ðŸƒâ€â™‚ï¸ Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ei3alnONX4RY"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"train\"))\n",
    "    train_dataset_ = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    train_loader_ = DataLoader(\n",
    "        train_dataset_,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Optimizer\n",
    "    # ====================================================\n",
    "    def get_optimizer(model):\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"SAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "            )\n",
    "        elif config.optimizer == \"ASAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "                rho=2.0,\n",
    "                adaptive=True,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer, train_dataset):\n",
    "        num_data = len(train_dataset)\n",
    "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
    "\n",
    "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
    "            scheduler = CosineAnnealingWarmupRestarts(\n",
    "                optimizer,\n",
    "                first_cycle_steps=num_steps,\n",
    "                max_lr=config.lr,\n",
    "                min_lr=config.min_lr,\n",
    "                warmup_steps=(num_steps // 10),\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(config.model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = amp.GradScaler(enabled=Config.amp)\n",
    "    scheduler = get_scheduler(optimizer, train_dataset)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif config.criterion == \"MSELoss\":\n",
    "            criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # Early stopping\n",
    "    # ====================================================\n",
    "    es = EarlyStopping(\n",
    "        patience=config.es_patience,\n",
    "        verbose=True,\n",
    "        path=MODEL_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            avg_loss = train_fn(train_loader_, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "        else:\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "        if config.criterion == \"BCEWithLogitsLoss\":\n",
    "            preds = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "        preds *= 100.0\n",
    "\n",
    "        # scoring\n",
    "        # score = get_score(valid_labels, preds.argmax(1))\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                f\"loss/train_fold{fold}\": avg_loss,\n",
    "                f\"loss/valid_fold{fold}\": avg_val_loss,\n",
    "                f\"score/fold{fold}\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        es(avg_val_loss, score, model, preds)\n",
    "\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    valid_folds[\"preds\"] = es.best_preds\n",
    "\n",
    "    return valid_folds, es.best_score, es.val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVj6cfuLc4VP"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpdJfNgUc5N3"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    if Config.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for fold in range(config.n_fold):\n",
    "            seed_torch(seed + fold)\n",
    "\n",
    "            _oof_df, score, loss = train_loop(train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_result.append([fold, score, loss])\n",
    "\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df, fold)\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        loss = statistics.mean([d[2] for d in oof_result])\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        table = wandb.Table(data=oof_result, columns=[\"fold\", \"score\", \"loss\"])\n",
    "        run.log({\"Fold Result\": table})\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(config.model_name, type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-J0CDXjkUaS"
   },
   "source": [
    "# ðŸš€ Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeDBzpKHdIie"
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ijJJUa2d2Lx"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "petfinder2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
