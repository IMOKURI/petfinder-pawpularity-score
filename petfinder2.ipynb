{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YDQH4n9zdG"
   },
   "source": [
    "# üìî About this notebook\n",
    "\n",
    "PetFinder.my - Pawpularity Contest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0pnACt-CQd"
   },
   "source": [
    "## üìù Memo\n",
    "\n",
    "- transformer „ÅÆ output „Å® feature „Çí SVR „ÅßÂ≠¶Áøí„Åô„Çã„ÄÇ\n",
    "    - NN „ÅÆ head „Å® SVR „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„Åô„Çã„ÄÇ [Link](https://www.kaggle.com/cdeotte/rapids-svr-boost-17-8/notebook)\n",
    "- swin base, large „Å® CSWin „Å® B7 „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÄÇ\n",
    "- ConvMixer [Link](https://github.com/tmp-iclr/convmixer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eezrDVYa_yav"
   },
   "source": [
    "# üìö Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1633394791716,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "32GYVF3l_wUO"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1633394792859,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "DhlpmaPbNqOs"
   },
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional local libraries\n",
    "\n",
    "# https://github.com/microsoft/CSWin-Transformer\n",
    "sys.path.append(\"../input/CSWin-Transformer\")\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633394792860,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qPMtyPp8AWvZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ZHMIcuPvAdZI",
    "outputId": "8b28afb5-3466-40d4-9d0f-7a7a43f786b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "# netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
    "# !cp -f {netrc} ~/\n",
    "!wandb login\n",
    "wandb_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "KPb3f6kLAYrP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uOtCk2BKGF"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m4LaDlPJBLil"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "!rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "xKKkrScBBf44"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQk8_n-5Bwun"
   },
   "source": [
    "# üõ† Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "HfK7G4EQBxpt",
    "outputId": "266be0c6-6b79-4de4-8de1-8502eb577dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "STqXGbUhBz5f"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    wandb_entity = \"imokuri\"\n",
    "    wandb_project = \"petfinder2\"\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    train2 = False  # SVR\n",
    "    train3 = False  # 100 or not\n",
    "    validate = False\n",
    "    inference = False\n",
    "\n",
    "    debug = False\n",
    "    num_debug_data = 1000\n",
    "\n",
    "    amp = True\n",
    "    multi_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAK99CZOhfMV"
   },
   "source": [
    "Model examples\n",
    "\n",
    "- resnext50_32x4d\n",
    "- vit_base_patch16_384\n",
    "- tf_efficientnet_b7_ns\n",
    "- tf_efficientnetv2_l_in21k\n",
    "- swin_base_patch4_window12_384_in22k\n",
    "- swin_large_patch4_window7_224_in22k\n",
    "- swin_large_patch4_window12_384_in22k\n",
    "- CSWin_144_24322_large_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "Vjl7MQHiFyFS"
   },
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"momentum\": 0.9,\n",
    "    \"model_name\": \"swin_base_patch4_window7_224_in22k\",\n",
    "    \"size\": 224,\n",
    "    \"models\": [\n",
    "        # \"swin_large_patch4_window12_384_in22k:v14\",\n",
    "        # \"swin_base_patch4_window12_384_in22k:v1\",\n",
    "    ],\n",
    "    \"runs\": [\n",
    "        # \"34qor14i\",  # swin large 384 v14\n",
    "        # \"tmbsq7j1\",  # swin base 384 v1\n",
    "        # \"1ngzxqt1\",  # swin large 224\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "dgConxiYIqTM"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config_defaults[\"n_fold\"] = 3\n",
    "    config_defaults[\"epochs\"] = 1\n",
    "    Config.print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BteR9_gVItes"
   },
   "outputs": [],
   "source": [
    "if Config.train:\n",
    "    wandb_job_type = \"training\"\n",
    "\n",
    "elif Config.train2:\n",
    "    wandb_job_type = \"training2\"\n",
    "\n",
    "elif Config.inference:\n",
    "    wandb_job_type = \"inference\"\n",
    "\n",
    "elif Config.validate:\n",
    "    wandb_job_type = \"validation\"\n",
    "\n",
    "else:\n",
    "    wandb_job_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "wBSFI0-_XL_-"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    wandb_tags.append(\"debug\")\n",
    "\n",
    "# if Config.amp:\n",
    "#     wandb_tags.append(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "LIDKN-b7jDOt"
   },
   "outputs": [],
   "source": [
    "wandb_tags.append(\"no feats\")\n",
    "wandb_tags.append(\"bins kfold\")\n",
    "wandb_tags.append(\"basic aug\")\n",
    "# wandb_tags.append(\"heavy aug\")\n",
    "# wandb_tags.append(\"mixup\")\n",
    "# wandb_tags.append(\"cutmix\")\n",
    "# wandb_tags.append(\"freeze norm\")\n",
    "# wandb_tags.append(\"crop image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1633394796778,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JaQsAlSfJbnt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/imokuri/petfinder2/runs/bulu150s\" target=\"_blank\">faithful-hill-74</a></strong> to <a href=\"https://wandb.ai/imokuri/petfinder2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.debug:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        tags=wandb_tags,\n",
    "        mode=\"disabled\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        job_type=wandb_job_type,\n",
    "        tags=wandb_tags,\n",
    "        save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633394796783,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0kD8_kP0JjAC"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYjWTUW9Jtem"
   },
   "source": [
    "# EDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1633394796784,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "-dEUJ_P9Jwzw",
    "outputId": "f98c8f40-5d7e-43f5-f524-58129cd3c758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9912 entries, 0 to 9911\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             9912 non-null   object\n",
      " 1   Subject Focus  9912 non-null   int64 \n",
      " 2   Eyes           9912 non-null   int64 \n",
      " 3   Face           9912 non-null   int64 \n",
      " 4   Near           9912 non-null   int64 \n",
      " 5   Action         9912 non-null   int64 \n",
      " 6   Accessory      9912 non-null   int64 \n",
      " 7   Group          9912 non-null   int64 \n",
      " 8   Collage        9912 non-null   int64 \n",
      " 9   Human          9912 non-null   int64 \n",
      " 10  Occlusion      9912 non-null   int64 \n",
      " 11  Info           9912 non-null   int64 \n",
      " 12  Blur           9912 non-null   int64 \n",
      " 13  Pawpularity    9912 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             8 non-null      object\n",
      " 1   Subject Focus  8 non-null      int64 \n",
      " 2   Eyes           8 non-null      int64 \n",
      " 3   Face           8 non-null      int64 \n",
      " 4   Near           8 non-null      int64 \n",
      " 5   Action         8 non-null      int64 \n",
      " 6   Accessory      8 non-null      int64 \n",
      " 7   Group          8 non-null      int64 \n",
      " 8   Collage        8 non-null      int64 \n",
      " 9   Human          8 non-null      int64 \n",
      " 10  Occlusion      8 non-null      int64 \n",
      " 11  Info           8 non-null      int64 \n",
      " 12  Blur           8 non-null      int64 \n",
      "dtypes: int64(12), object(1)\n",
      "memory usage: 960.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  \n",
       "3          0      0        0      0          0     1     0  \n",
       "4          1      0        1      0          1     1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8 non-null      object \n",
      " 1   Pawpularity  8 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>59.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>20.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>89.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3        67.75\n",
       "1  43a2262d7738e3d420d453815151079e        59.15\n",
       "2  4e429cead1848a298432a0acad014c9d        20.02\n",
       "3  80bc3ccafcc51b66303c2c263aa38486        94.53\n",
       "4  8f49844c382931444e68dffbe20228f4        89.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [train, test, sub]:\n",
    "    print(f\"=\" * 120)\n",
    "    df.info()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1633394797327,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "uK-vChyCKVhZ",
    "outputId": "3d5cf17f-3df5-4163-a7ba-be4bd83f6211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pawpularity'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[\"Pawpularity\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nN20A-4KeX2"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess(df):\n",
    "    df[\"Pawpularity100\"] = np.where(df[\"Pawpularity\"] == 100, 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.train3:\n",
    "    train = train_preprocess(df)\n",
    "    train[\"Pawpularity100\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDt-OBGKg33"
   },
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m2XP3TB7KhvW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFYIILAsKih4"
   },
   "source": [
    "# üëë Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.train2:\n",
    "    api = wandb.Api()\n",
    "    for artifact_id in config.models:\n",
    "        name_version = artifact_id.replace(\":\", \"-\")\n",
    "        if not os.path.exists(name_version):\n",
    "            os.makedirs(name_version)\n",
    "\n",
    "        try:\n",
    "            artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{artifact_id}\"\n",
    "            artifact = api.artifact(artifact_path)\n",
    "            artifact.download(name_version)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {artifact_path}, {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.validate:\n",
    "    api = wandb.Api()\n",
    "\n",
    "    for n, run_id in enumerate(config.runs):\n",
    "        if not os.path.exists(run_id):\n",
    "            os.makedirs(run_id)\n",
    "\n",
    "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
    "        run = api.run(run_path)\n",
    "\n",
    "        try:\n",
    "            run.file(\"oof_df.csv\").download(run_id)\n",
    "        except wandb.CommError:\n",
    "            # Already downloaded.\n",
    "            pass\n",
    "\n",
    "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"Id\", \"preds\"]]\n",
    "        oof.columns = [\"Id\", f\"preds{n}\"]\n",
    "        train = pd.merge(train, oof, on=\"Id\")\n",
    "\n",
    "    print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ahzUGk4sK6te"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "    if len(sub) > Config.num_debug_data:\n",
    "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF4pvz7-L7qT"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qrlmhizKMCku"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClI1iqtWLqU0"
   },
   "source": [
    "# Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BQVW6__Rjk_N"
   },
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(1 + np.log2(len(train))))\n",
    "train.loc[:, \"bins\"] = pd.cut(train[\"Pawpularity\"], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "raBuQ3EjLsmo",
    "outputId": "11fbcaa3-b48c-4143-c742-b0de3e717a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  bins\n",
      "0     0        33\n",
      "      1        42\n",
      "      2       111\n",
      "      3       203\n",
      "      4       188\n",
      "             ... \n",
      "9     9        28\n",
      "      10       20\n",
      "      11       14\n",
      "      12       11\n",
      "      13       36\n",
      "Length: 140, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
    "print(train.groupby([\"fold\", \"bins\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKN3QPeMMFf"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"crop image\" in wandb_tags:\n",
    "    TRAIN_IMAGE_PATH = DATA_DIR + \"crop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "pX4piTk2MPVR"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\", \"fold\", \"bins\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1633394798564,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0CIysnf0OhGK",
    "outputId": "dca880e9-0d92-43e7-82e2-a11ecacb54c1"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train)\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797328,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "yJhnZyCOKf_8"
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    if data == \"train\":\n",
    "        if \"basic aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if \"heavy aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                    # A.CoarseDropout(p=0.5),\n",
    "                    # A.Cutout(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798565,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JwLeTm_EP9kK",
    "outputId": "9193e65d-197d-4e17-91d7-ee026dc0d38a"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = cutmix(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BqcwfvhMterO"
   },
   "outputs": [],
   "source": [
    "# https://github.com/yuhao318/mwh/blob/main/utils.py\n",
    "def mixup(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "\n",
    "    \"\"\"Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam = max(lam, 1 - lam)\n",
    "        # lam = min(lam, 1-lam)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    ## NO SYM\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # return mixed_image, mixed_label, lam\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "CiCqVeWhh2gr",
    "outputId": "81496b08-c725-48b9-ad02-573eb0346269"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = mixup(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbrC2J4KPEp4"
   },
   "source": [
    "# üöó Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798566,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "827lYLgIPFyY"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        if \"no feats\" in wandb_tags:\n",
    "            self.head2 = nn.Linear(128, config.n_class)\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.head1 = nn.Linear(140, 64)\n",
    "            self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        if \"no feats\" in wandb_tags:\n",
    "            x = self.head2(x)\n",
    "        else:\n",
    "            x = self.dropout(x)\n",
    "            x = torch.cat([x, feats], dim=1)\n",
    "            x = self.head1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model):\n",
    "    model.train()\n",
    "\n",
    "    # Freeze layer normalization\n",
    "    if any(key in config.model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "        for m in model.modules():\n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.LayerNorm):\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83590,
     "status": "ok",
     "timestamp": 1633394882149,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "oudAIpPqQt6z",
    "outputId": "32564315-dd7d-4bc9-f24b-620488993b3a"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    model.apply(train_mode)\n",
    "\n",
    "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
    "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        # x = self.head1(x)\n",
    "        # x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BackboneModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa8k53cRIi_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FbkDI8DdRJ5w"
   },
   "outputs": [],
   "source": [
    "# https://github.com/davda54/sam/blob/main/sam.py\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFMHkJIMRLBi"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "f6jKOTHURLxM"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbNT_NeRMoB"
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "S4EF_M0NROIn"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "0fQUwt7adOSk"
   },
   "outputs": [],
   "source": [
    "def get_result(result_df, fold=config.n_fold):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"Pawpularity\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    if fold == config.n_fold:\n",
    "        wandb.log({\"Score\": score})\n",
    "    else:\n",
    "        wandb.log({f\"Score_fold{fold}\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Ga4Bb8RQsF"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rRPW8QwiRbPC"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "23roIn-jhfMe"
   },
   "outputs": [],
   "source": [
    "# https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_preds = None\n",
    "\n",
    "    def __call__(self, val_loss, score, model, preds):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss >= self.val_loss_min + self.delta:\n",
    "            if self.patience <= 0:\n",
    "                return\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "l9Kcw2bdeZR4"
   },
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2.0):\n",
    "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = [p for p in parameters if p.grad is not None]\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "sWtO4py7Rcud"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    if \"freeze norm\" in wandb_tags:\n",
    "        model.apply(train_mode)\n",
    "    else:\n",
    "        model.train()\n",
    "    start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            mix_decision = 1.0\n",
    "        else:\n",
    "            mix_decision = np.random.rand()\n",
    "\n",
    "        if epoch >= config.epochs - 5:\n",
    "            mix_decision *= 2\n",
    "\n",
    "        if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "            images, features, label_a, label_b, lam = mixup(images, features, labels, alpha=0.5)\n",
    "\n",
    "        with amp.autocast(enabled=Config.amp):\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "            if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "            else:\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "\n",
    "                def closure():\n",
    "                    # y_preds = model(images, features)\n",
    "                    y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "                    if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                        loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "                    else:\n",
    "                        loss = criterion(y_preds, labels)\n",
    "\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "                scaler.step(optimizer, closure)\n",
    "            else:\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            grad_norm = compute_grad_norm(model.parameters())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_lr()[0]:.2e}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wlPZYJYgXRZ4"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training2 (Inference by backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_inference_fn(data_loader, model, device):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images, features)\n",
    "            # y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(data_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(data_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(data_loader)):s} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ybZNlV6YEp8"
   },
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JIDycP9YFvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mwWqWJdX232"
   },
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ei3alnONX4RY"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"train\"))\n",
    "    train_dataset_ = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    train_loader_ = DataLoader(\n",
    "        train_dataset_,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Optimizer\n",
    "    # ====================================================\n",
    "    def get_optimizer(model):\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"SAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "            )\n",
    "        elif config.optimizer == \"ASAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "                rho=2.0,\n",
    "                adaptive=True,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer, train_dataset):\n",
    "        num_data = len(train_dataset)\n",
    "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
    "\n",
    "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
    "            scheduler = CosineAnnealingWarmupRestarts(\n",
    "                optimizer,\n",
    "                first_cycle_steps=num_steps,\n",
    "                max_lr=config.lr,\n",
    "                min_lr=config.min_lr,\n",
    "                warmup_steps=(num_steps // 10),\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(config.model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = amp.GradScaler(enabled=Config.amp)\n",
    "    scheduler = get_scheduler(optimizer, train_dataset)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif config.criterion == \"MSELoss\":\n",
    "            criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # Early stopping\n",
    "    # ====================================================\n",
    "    es = EarlyStopping(\n",
    "        patience=config.es_patience,\n",
    "        verbose=True,\n",
    "        path=MODEL_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            avg_loss = train_fn(train_loader_, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "        else:\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "        if config.criterion == \"BCEWithLogitsLoss\":\n",
    "            preds = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "        preds *= 100.0\n",
    "\n",
    "        # scoring\n",
    "        # score = get_score(valid_labels, preds.argmax(1))\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                f\"loss/train_fold{fold}\": avg_loss,\n",
    "                f\"loss/valid_fold{fold}\": avg_val_loss,\n",
    "                f\"score/fold{fold}\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        es(avg_val_loss, score, model, preds)\n",
    "\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    valid_folds[\"preds\"] = es.best_preds\n",
    "\n",
    "    return valid_folds, es.best_score, es.val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏èüèÉ‚Äç‚ôÇÔ∏è Train2 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_loop(df, artifact_id, fold):\n",
    "    LOGGER.info(f\"========== ID: {artifact_id} fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model_name = artifact_id.split(\":\")[0]\n",
    "    model = BackboneModel(model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    path = f\"{artifact_id.replace(':', '-')}/{model_name}_fold{fold}_best.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    # ====================================================\n",
    "    # Inference by backbone\n",
    "    # ====================================================\n",
    "\n",
    "    train_preds = train2_inference_fn(train_loader, model, device)\n",
    "    valid_preds = train2_inference_fn(valid_loader, model, device)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler.fit(np.vstack([train_preds, valid_preds]))\n",
    "\n",
    "    train_norm = scaler.fit_transform(train_preds)\n",
    "    valid_norm = scaler.transform(valid_preds)\n",
    "\n",
    "    scaler_path = MODEL_DIR + f\"{model_name}-StandardScaler_fold{fold}_best.pkl\"\n",
    "    pickle.dump(scaler, open(scaler_path, \"wb\"))\n",
    "\n",
    "    # ====================================================\n",
    "    # Tuning SVR parameters\n",
    "    # ====================================================\n",
    "    # https://github.com/hkaneko1985/fastoptsvrhyperparams/blob/master/fastoptsvrhyperparams.ipynb\n",
    "    start_time = time.time()\n",
    "\n",
    "    svr_epss = 2 ** np.arange(-10, 1, dtype=float)  # Candidates of epsilon\n",
    "    svr_cs = 2 ** np.arange(-5, 11, dtype=float)  # Candidates of C\n",
    "    svr_gammas = 2 ** np.arange(-20, 11, dtype=float)  # Candidates of gamma\n",
    "\n",
    "    # Optimize epsilon with cross-validation\n",
    "    model_tune_eps = GridSearchCV(SVR(kernel=\"rbf\", C=3), {\"epsilon\": svr_epss}, verbose=1)\n",
    "    model_tune_eps.fit(train_norm, train_dataset.labels)\n",
    "    optimal_eps = model_tune_eps.best_params_[\"epsilon\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized eps: {elapsed:.0f}s\")\n",
    "\n",
    "    # Optimize C with cross-validation\n",
    "    model_tune_c = GridSearchCV(SVR(kernel=\"rbf\", epsilon=optimal_eps), {\"C\": svr_cs}, verbose=1)\n",
    "    model_tune_c.fit(train_norm, train_dataset.labels)\n",
    "    optimal_c = model_tune_c.best_params_[\"C\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized c: {elapsed:.0f}s\")\n",
    "\n",
    "    # Optimize gamma with cross-validation (optional)\n",
    "    model_tune_gamma = GridSearchCV(\n",
    "        SVR(kernel=\"rbf\", epsilon=optimal_eps, C=optimal_c), {\"gamma\": svr_gammas}, verbose=1\n",
    "    )\n",
    "    model_tune_gamma.fit(train_norm, train_dataset.labels)\n",
    "    optimal_gamma = model_tune_gamma.best_params_[\"gamma\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized gamma: {elapsed:.0f}s\")\n",
    "\n",
    "    best_params = {\n",
    "        \"C\": optimal_c,\n",
    "        \"epsilon\": optimal_eps,\n",
    "        \"gamma\": optimal_gamma,\n",
    "    }\n",
    "    print(f\"{best_params}\")\n",
    "\n",
    "    param_path = MODEL_DIR + f\"{model_name}-SVR-params_fold{fold}_best.json\"\n",
    "    with open(param_path, \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_svr = SVR(C=optimal_c, epsilon=optimal_eps, gamma=optimal_gamma)\n",
    "    model_svr.fit(train_norm, train_dataset.labels)\n",
    "\n",
    "    preds = model_svr.predict(valid_norm)\n",
    "    preds *= 100.0\n",
    "\n",
    "    # scoring\n",
    "    # score = get_score(valid_labels, preds.argmax(1))\n",
    "    score = get_score(valid_labels, preds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    LOGGER.info(f\"Score: {score}  time: {elapsed:.0f}s\")\n",
    "\n",
    "    svr_path = MODEL_DIR + f\"{model_name}-SVR_fold{fold}_best.pkl\"\n",
    "    pickle.dump(model_svr, open(svr_path, \"wb\"))\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    # valid_folds[\"preds\"] = es.best_preds\n",
    "    valid_folds[\"preds\"] = preds\n",
    "\n",
    "    return valid_folds, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVj6cfuLc4VP"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PpdJfNgUc5N3"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    if Config.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for fold in range(config.n_fold):\n",
    "            seed_torch(seed + fold)\n",
    "\n",
    "            _oof_df, score, loss = train_loop(train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_result.append([fold, score, loss])\n",
    "\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df, fold)\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        loss = statistics.mean([d[2] for d in oof_result])\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        table = wandb.Table(data=oof_result, columns=[\"fold\", \"score\", \"loss\"])\n",
    "        run.log({\"Fold Result\": table})\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(config.model_name, type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)\n",
    "\n",
    "    # ====================================================\n",
    "    # Validation\n",
    "    # ====================================================\n",
    "    if Config.validate:\n",
    "        cols = [f\"preds{n}\" for n in range(len(config.runs))]\n",
    "        train[\"preds\"] = train[cols].values.mean(axis=1)\n",
    "\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(train)\n",
    "\n",
    "        # save result\n",
    "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    if Config.train2:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for n, artifact_id in enumerate(config.models):\n",
    "\n",
    "            for fold in range(config.n_fold):\n",
    "                seed_torch(seed + fold)\n",
    "                _oof_df, score = train2_loop(train, artifact_id, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df, fold)\n",
    "\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "\n",
    "            break\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(f\"{artifact_id.split(':')[0]}-SVR\", type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-J0CDXjkUaS"
   },
   "source": [
    "# üöÄ Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "oeDBzpKHdIie"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 28s (remain 64m 38s) Loss: 0.7065 Grad: 1.3585 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 15s (remain 0m 28s) Loss: 0.6547 Grad: 0.5462 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 32s (remain 0m 0s) Loss: 0.6526 Grad: 0.6455 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6592 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6438 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6526  avg_val_loss: 0.6438  time: 99s\n",
      "Epoch 1 - Score: 17.934272989495916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643831).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 6m 6s) Loss: 0.6237 Grad: 0.6831 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6386 Grad: 0.5302 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6386 Grad: 0.5598 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6545 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6410 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6386  avg_val_loss: 0.6410  time: 75s\n",
      "Epoch 2 - Score: 17.545837913443602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643831 --> 0.641009).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 30s) Loss: 0.6529 Grad: 1.0248 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6492 Grad: 1.1608 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6485 Grad: 0.6672 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6613 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6485  avg_val_loss: 0.6433  time: 75s\n",
      "Epoch 3 - Score: 17.815067346738157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 30s) Loss: 0.6546 Grad: 1.1039 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6447 Grad: 0.5391 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6447 Grad: 0.7621 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6613 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6447  avg_val_loss: 0.6408  time: 76s\n",
      "Epoch 4 - Score: 17.50157841890283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641009 --> 0.640753).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 16s) Loss: 0.6656 Grad: 0.6591 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6425 Grad: 0.6864 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6430 Grad: 0.8706 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 36s) Loss: 0.6639 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6430  avg_val_loss: 0.6433  time: 77s\n",
      "Epoch 5 - Score: 17.8003883725943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 41s) Loss: 0.6501 Grad: 0.9715 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6425 Grad: 0.8188 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6421 Grad: 1.7663 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6635 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6421  avg_val_loss: 0.6431  time: 76s\n",
      "Epoch 6 - Score: 17.786109393962242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 6m 4s) Loss: 0.6359 Grad: 0.7675 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6417 Grad: 0.6539 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6412 Grad: 0.8476 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6639 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6417 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6412  avg_val_loss: 0.6417  time: 77s\n",
      "Epoch 7 - Score: 17.60670610599091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 42s) Loss: 0.6441 Grad: 0.7436 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6401 Grad: 0.9992 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6400 Grad: 0.6614 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6649 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6400  avg_val_loss: 0.6433  time: 77s\n",
      "Epoch 8 - Score: 17.780824821506076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 20s) Loss: 0.6360 Grad: 0.6477 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6275 Grad: 0.9761 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6280 Grad: 1.1237 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6634 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6412 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6280  avg_val_loss: 0.6412  time: 77s\n",
      "Epoch 9 - Score: 17.540011835623606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 42s) Loss: 0.6416 Grad: 0.5104 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6272 Grad: 0.5360 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6261 Grad: 0.6374 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6632 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6413 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6261  avg_val_loss: 0.6413  time: 76s\n",
      "Epoch 10 - Score: 17.541708785441458\n",
      "========== fold: 0 result ==========\n",
      "Score: 17.50158\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 6m 1s) Loss: 0.6824 Grad: 1.3781 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6558 Grad: 0.4962 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6528 Grad: 0.6166 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6292 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6422 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6528  avg_val_loss: 0.6422  time: 75s\n",
      "Epoch 1 - Score: 17.93286587466181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.642179).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 39s) Loss: 0.6539 Grad: 0.4654 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 50s (remain 0m 18s) Loss: 0.6383 Grad: 0.5564 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6388 Grad: 0.9347 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6255 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6388  avg_val_loss: 0.6393  time: 75s\n",
      "Epoch 2 - Score: 17.54193921201767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642179 --> 0.639263).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 16s) Loss: 0.6648 Grad: 0.6940 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6466 Grad: 0.7453 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6464 Grad: 0.7159 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6249 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6464  avg_val_loss: 0.6393  time: 75s\n",
      "Epoch 3 - Score: 17.543145822563297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 44s) Loss: 0.6638 Grad: 0.8000 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 50s (remain 0m 18s) Loss: 0.6440 Grad: 1.1473 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6440 Grad: 0.7152 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6245 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6440  avg_val_loss: 0.6393  time: 74s\n",
      "Epoch 4 - Score: 17.539626601530486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 31s) Loss: 0.6420 Grad: 1.3139 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 50s (remain 0m 18s) Loss: 0.6435 Grad: 0.8789 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6429 Grad: 0.7526 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6265 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6397 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6429  avg_val_loss: 0.6397  time: 74s\n",
      "Epoch 5 - Score: 17.599147829976644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 24s) Loss: 0.6445 Grad: 1.0438 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6423 Grad: 0.7036 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6416 Grad: 1.3292 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6216 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6416  avg_val_loss: 0.6404  time: 76s\n",
      "Epoch 6 - Score: 17.684649331779625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 37s) Loss: 0.6340 Grad: 0.4736 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6414 Grad: 0.9685 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6399 Grad: 0.5534 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6222 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6392 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6399  avg_val_loss: 0.6392  time: 76s\n",
      "Epoch 7 - Score: 17.535771788170457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639263 --> 0.639223).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 37s) Loss: 0.6398 Grad: 0.5536 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6385 Grad: 0.7248 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6401 Grad: 1.0408 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6218 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6401  avg_val_loss: 0.6393  time: 76s\n",
      "Epoch 8 - Score: 17.546722258037057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 34s) Loss: 0.6276 Grad: 0.5071 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6281 Grad: 0.7180 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6276 Grad: 0.4344 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6234 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6389 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6276  avg_val_loss: 0.6389  time: 76s\n",
      "Epoch 9 - Score: 17.492828875761965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639223 --> 0.638880).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 21s) Loss: 0.6062 Grad: 0.5640 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6259 Grad: 0.5697 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6256 Grad: 0.5578 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6235 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6391 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6256  avg_val_loss: 0.6391  time: 74s\n",
      "Epoch 10 - Score: 17.520974516703664\n",
      "========== fold: 1 result ==========\n",
      "Score: 17.49283\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 43s) Loss: 0.6965 Grad: 1.9779 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6554 Grad: 0.4990 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6528 Grad: 0.8247 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6396 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6511 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6528  avg_val_loss: 0.6511  time: 75s\n",
      "Epoch 1 - Score: 19.075339717405193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.651070).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 17s) Loss: 0.6519 Grad: 0.9212 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 50s (remain 0m 18s) Loss: 0.6389 Grad: 0.8726 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6388 Grad: 0.5069 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 37s) Loss: 0.6360 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6442 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6388  avg_val_loss: 0.6442  time: 74s\n",
      "Epoch 2 - Score: 18.276379312198426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.651070 --> 0.644181).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 56s) Loss: 0.6673 Grad: 1.1030 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6463 Grad: 0.8808 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6464 Grad: 0.6857 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6398 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6446 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6464  avg_val_loss: 0.6446  time: 75s\n",
      "Epoch 3 - Score: 18.316905350640052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 34s) Loss: 0.6485 Grad: 0.9041 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6444 Grad: 1.1818 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6448 Grad: 0.6198 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6374 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6448  avg_val_loss: 0.6437  time: 78s\n",
      "Epoch 4 - Score: 18.220930766044017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644181 --> 0.643749).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 54s) Loss: 0.6410 Grad: 0.6070 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6411 Grad: 0.7432 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6424 Grad: 0.6358 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6357 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6443 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6424  avg_val_loss: 0.6443  time: 75s\n",
      "Epoch 5 - Score: 18.277512114146184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 31s) Loss: 0.6398 Grad: 1.1189 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6418 Grad: 0.8708 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6414 Grad: 0.6979 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6377 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6445 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6414  avg_val_loss: 0.6445  time: 76s\n",
      "Epoch 6 - Score: 18.304428553886805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 18s) Loss: 0.6543 Grad: 0.6989 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6411 Grad: 0.6336 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6405 Grad: 0.7254 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6380 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6405  avg_val_loss: 0.6447  time: 75s\n",
      "Epoch 7 - Score: 18.317193045313992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 41s) Loss: 0.6240 Grad: 0.5525 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6407 Grad: 0.6892 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6401 Grad: 1.0042 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6382 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6443 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6401  avg_val_loss: 0.6443  time: 75s\n",
      "Epoch 8 - Score: 18.28278427754682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 33s) Loss: 0.6209 Grad: 0.4860 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6284 Grad: 0.5262 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6272 Grad: 0.5846 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6389 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6272  avg_val_loss: 0.6447  time: 75s\n",
      "Epoch 9 - Score: 18.325510337186106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 38s) Loss: 0.6148 Grad: 0.5131 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6265 Grad: 0.9425 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6254 Grad: 0.7249 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6397 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6453 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6254  avg_val_loss: 0.6453  time: 74s\n",
      "Epoch 10 - Score: 18.38411582814505\n",
      "========== fold: 2 result ==========\n",
      "Score: 18.22093\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 6m 21s) Loss: 0.6997 Grad: 1.2401 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6563 Grad: 0.5251 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6536 Grad: 0.4476 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6497 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6536  avg_val_loss: 0.6431  time: 75s\n",
      "Epoch 1 - Score: 17.92101706479351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643077).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 34s) Loss: 0.6326 Grad: 0.4961 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6393 Grad: 0.5428 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6392 Grad: 0.8906 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6500 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6391 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6392  avg_val_loss: 0.6391  time: 74s\n",
      "Epoch 2 - Score: 17.39517159865656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643077 --> 0.639078).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 24s) Loss: 0.6809 Grad: 1.0693 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 49s (remain 0m 18s) Loss: 0.6466 Grad: 0.7421 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6471 Grad: 0.6252 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6481 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6471  avg_val_loss: 0.6394  time: 74s\n",
      "Epoch 3 - Score: 17.43027533369699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 31s) Loss: 0.6565 Grad: 0.8476 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6458 Grad: 0.8334 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6455 Grad: 0.8512 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6476 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6455  avg_val_loss: 0.6384  time: 75s\n",
      "Epoch 4 - Score: 17.30538340254332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639078 --> 0.638410).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 35s) Loss: 0.6570 Grad: 1.0722 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6425 Grad: 0.8634 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 11s (remain 0m 0s) Loss: 0.6428 Grad: 0.8186 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6463 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6428  avg_val_loss: 0.6386  time: 78s\n",
      "Epoch 5 - Score: 17.329014790593014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 31s) Loss: 0.6439 Grad: 0.5227 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6443 Grad: 1.8258 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6424 Grad: 0.7628 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6489 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6424  avg_val_loss: 0.6390  time: 78s\n",
      "Epoch 6 - Score: 17.36888627934202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 25s) Loss: 0.6398 Grad: 0.7820 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6415 Grad: 0.5827 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6408 Grad: 0.7925 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 36s) Loss: 0.6474 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6408  avg_val_loss: 0.6386  time: 78s\n",
      "Epoch 7 - Score: 17.317372795389545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 49s) Loss: 0.6431 Grad: 0.6775 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6409 Grad: 2.6162 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6404 Grad: 1.0752 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6477 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6404  avg_val_loss: 0.6386  time: 77s\n",
      "Epoch 8 - Score: 17.31998529101936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 6m 16s) Loss: 0.6181 Grad: 0.7457 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6278 Grad: 0.4585 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6282 Grad: 0.6767 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6478 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6385 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6282  avg_val_loss: 0.6385  time: 78s\n",
      "Epoch 9 - Score: 17.30954340358647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 40s) Loss: 0.6245 Grad: 0.9658 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6269 Grad: 0.3636 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6264 Grad: 0.6182 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6465 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6264  avg_val_loss: 0.6381  time: 76s\n",
      "Epoch 10 - Score: 17.254662752456575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.638410 --> 0.638069).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 17.25466\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 6m 36s) Loss: 0.6705 Grad: 1.0274 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6522 Grad: 0.8989 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6501 Grad: 0.4260 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6460 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6501  avg_val_loss: 0.6431  time: 77s\n",
      "Epoch 1 - Score: 18.114996218521593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643144).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 45s) Loss: 0.6076 Grad: 0.7609 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6378 Grad: 0.7478 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6376 Grad: 0.8891 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6461 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6376  avg_val_loss: 0.6425  time: 78s\n",
      "Epoch 2 - Score: 18.016188510934953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643144 --> 0.642498).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 22s) Loss: 0.6463 Grad: 1.2677 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6459 Grad: 2.0284 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6466 Grad: 1.0653 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6450 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6413 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6466  avg_val_loss: 0.6413  time: 78s\n",
      "Epoch 3 - Score: 17.884599665510784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642498 --> 0.641291).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 11s) Loss: 0.6343 Grad: 0.7900 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6438 Grad: 0.7266 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6434 Grad: 0.5943 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 38s) Loss: 0.6435 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6414 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6434  avg_val_loss: 0.6414  time: 77s\n",
      "Epoch 4 - Score: 17.880583250689078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6479 Grad: 0.8170 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6426 Grad: 0.6075 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6420 Grad: 0.9804 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6420 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6420  avg_val_loss: 0.6408  time: 77s\n",
      "Epoch 5 - Score: 17.821475253816452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641291 --> 0.640826).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6548 Grad: 0.9269 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6428 Grad: 0.8110 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6425 Grad: 0.7072 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 38s) Loss: 0.6419 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6402 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6425  avg_val_loss: 0.6402  time: 78s\n",
      "Epoch 6 - Score: 17.733011305017257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.640826 --> 0.640196).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 47s) Loss: 0.6372 Grad: 0.5483 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6413 Grad: 2.3193 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6407 Grad: 0.8949 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6435 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6407  avg_val_loss: 0.6405  time: 77s\n",
      "Epoch 7 - Score: 17.772019636826027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 6m 25s) Loss: 0.6475 Grad: 0.9098 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6384 Grad: 0.8281 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6388 Grad: 1.1782 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6410 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6406 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6388  avg_val_loss: 0.6406  time: 78s\n",
      "Epoch 8 - Score: 17.778970802259288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 58s) Loss: 0.6138 Grad: 0.5136 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6263 Grad: 0.7010 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6274 Grad: 0.7227 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 38s) Loss: 0.6425 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6274  avg_val_loss: 0.6405  time: 77s\n",
      "Epoch 9 - Score: 17.77915050887943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 55s) Loss: 0.6334 Grad: 0.5123 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6250 Grad: 0.5325 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6251 Grad: 0.6038 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6420 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6251  avg_val_loss: 0.6408  time: 77s\n",
      "Epoch 10 - Score: 17.806402097450245\n",
      "========== fold: 4 result ==========\n",
      "Score: 17.73301\n",
      "========== fold: 5 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 58s) Loss: 0.7256 Grad: 1.7738 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6572 Grad: 0.5092 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6539 Grad: 0.6546 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6581 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6432 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6539  avg_val_loss: 0.6432  time: 78s\n",
      "Epoch 1 - Score: 17.846917851357162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643247).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 23s) Loss: 0.6447 Grad: 0.5737 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6404 Grad: 0.6461 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6394 Grad: 1.8644 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6528 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6394  avg_val_loss: 0.6399  time: 78s\n",
      "Epoch 2 - Score: 17.378613846193936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643247 --> 0.639863).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 40s) Loss: 0.6456 Grad: 0.6446 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6467 Grad: 0.9855 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6470 Grad: 1.2325 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6542 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6410 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6470  avg_val_loss: 0.6410  time: 77s\n",
      "Epoch 3 - Score: 17.49433295931116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 14s) Loss: 0.6514 Grad: 1.1241 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6455 Grad: 0.9935 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6444 Grad: 0.6698 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6541 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6444  avg_val_loss: 0.6393  time: 77s\n",
      "Epoch 4 - Score: 17.282833289391313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639863 --> 0.639279).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 6m 14s) Loss: 0.6248 Grad: 0.4858 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6417 Grad: 0.4989 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6428 Grad: 0.6023 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6534 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6382 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6428  avg_val_loss: 0.6382  time: 77s\n",
      "Epoch 5 - Score: 17.153754526753634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639279 --> 0.638185).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 6m 0s) Loss: 0.6421 Grad: 0.5644 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6419 Grad: 0.6166 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6421 Grad: 0.4741 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6519 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6380 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6421  avg_val_loss: 0.6380  time: 77s\n",
      "Epoch 6 - Score: 17.12356805798342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.638185 --> 0.637987).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 45s) Loss: 0.6531 Grad: 0.8007 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6402 Grad: 1.2622 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6412 Grad: 0.9488 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6509 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6383 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6412  avg_val_loss: 0.6383  time: 76s\n",
      "Epoch 7 - Score: 17.153726291540035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 22s) Loss: 0.6372 Grad: 0.8386 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6393 Grad: 0.6728 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6392 Grad: 0.5028 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6528 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6385 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6392  avg_val_loss: 0.6385  time: 75s\n",
      "Epoch 8 - Score: 17.17314718693254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 6m 30s) Loss: 0.6058 Grad: 0.5502 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6287 Grad: 0.6900 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6286 Grad: 0.6965 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6538 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6286  avg_val_loss: 0.6386  time: 75s\n",
      "Epoch 9 - Score: 17.18195932166567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6127 Grad: 0.5682 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6280 Grad: 1.0473 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6272 Grad: 0.8186 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6541 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6272  avg_val_loss: 0.6384  time: 77s\n",
      "Epoch 10 - Score: 17.167063909113587\n",
      "========== fold: 5 result ==========\n",
      "Score: 17.12357\n",
      "========== fold: 6 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 54s) Loss: 0.6884 Grad: 1.2856 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6542 Grad: 0.7419 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6508 Grad: 0.6316 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6647 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6443 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6508  avg_val_loss: 0.6443  time: 75s\n",
      "Epoch 1 - Score: 17.96388401104775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.644266).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 6m 30s) Loss: 0.6446 Grad: 0.6509 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6371 Grad: 0.7038 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6377 Grad: 0.8448 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6593 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6410 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6377  avg_val_loss: 0.6410  time: 76s\n",
      "Epoch 2 - Score: 17.5387287740129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644266 --> 0.641037).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 6m 0s) Loss: 0.6810 Grad: 1.0119 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6463 Grad: 0.7867 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6467 Grad: 0.4965 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6575 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6467  avg_val_loss: 0.6394  time: 76s\n",
      "Epoch 3 - Score: 17.322928464976407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641037 --> 0.639435).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 6m 2s) Loss: 0.6318 Grad: 0.6977 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6431 Grad: 1.8834 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6438 Grad: 0.7303 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6615 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6398 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6438  avg_val_loss: 0.6398  time: 76s\n",
      "Epoch 4 - Score: 17.373206216695866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 52s) Loss: 0.6517 Grad: 0.9100 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6428 Grad: 0.6671 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6425 Grad: 0.9537 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 39s) Loss: 0.6565 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6385 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6425  avg_val_loss: 0.6385  time: 75s\n",
      "Epoch 5 - Score: 17.199418018155914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639435 --> 0.638542).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 59s) Loss: 0.6462 Grad: 0.7149 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6420 Grad: 0.7111 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6411 Grad: 1.5143 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 37s) Loss: 0.6576 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6411  avg_val_loss: 0.6396  time: 76s\n",
      "Epoch 6 - Score: 17.33618220322285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 51s) Loss: 0.6443 Grad: 0.6589 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6403 Grad: 0.8163 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6405 Grad: 0.8656 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6553 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6387 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6405  avg_val_loss: 0.6387  time: 75s\n",
      "Epoch 7 - Score: 17.22651389246708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 55s) Loss: 0.6515 Grad: 0.5151 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6390 Grad: 0.8080 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6395 Grad: 0.7067 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6563 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6395  avg_val_loss: 0.6394  time: 76s\n",
      "Epoch 8 - Score: 17.308175849548224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 6m 1s) Loss: 0.6477 Grad: 0.6980 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6265 Grad: 0.5868 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6273 Grad: 0.6025 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6562 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6387 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6273  avg_val_loss: 0.6387  time: 77s\n",
      "Epoch 9 - Score: 17.220799568140453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 6m 23s) Loss: 0.6376 Grad: 2.0736 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6255 Grad: 0.5494 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6254 Grad: 0.9411 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6578 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6254  avg_val_loss: 0.6396  time: 76s\n",
      "Epoch 10 - Score: 17.326863829410993\n",
      "========== fold: 6 result ==========\n",
      "Score: 17.19942\n",
      "========== fold: 7 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 53s) Loss: 0.7081 Grad: 1.4627 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6562 Grad: 0.7620 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6527 Grad: 0.4880 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6297 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6451 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6527  avg_val_loss: 0.6451  time: 76s\n",
      "Epoch 1 - Score: 18.29434649279823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.645124).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 6m 22s) Loss: 0.6410 Grad: 0.7584 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6392 Grad: 1.6154 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6386 Grad: 0.8461 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6287 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6461 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6386  avg_val_loss: 0.6461  time: 75s\n",
      "Epoch 2 - Score: 18.387845623980404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 54s) Loss: 0.6434 Grad: 1.0311 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6473 Grad: 0.7270 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6481 Grad: 0.9793 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 37s) Loss: 0.6275 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6435 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6481  avg_val_loss: 0.6435  time: 76s\n",
      "Epoch 3 - Score: 18.07538406480238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645124 --> 0.643484).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 50s) Loss: 0.6601 Grad: 1.0301 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6447 Grad: 0.5802 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6445 Grad: 0.6461 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6282 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6445  avg_val_loss: 0.6428  time: 76s\n",
      "Epoch 4 - Score: 17.97886011020475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643484 --> 0.642769).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 39s) Loss: 0.6532 Grad: 0.8394 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6430 Grad: 2.8845 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6438 Grad: 0.7786 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6310 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6444 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6438  avg_val_loss: 0.6444  time: 76s\n",
      "Epoch 5 - Score: 18.183638283823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 49s) Loss: 0.6340 Grad: 0.6752 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6410 Grad: 0.9593 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6415 Grad: 0.8199 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6312 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6432 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6415  avg_val_loss: 0.6432  time: 75s\n",
      "Epoch 6 - Score: 18.0286914422038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 47s) Loss: 0.6490 Grad: 0.5756 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6397 Grad: 0.9763 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6409 Grad: 0.7115 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6313 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6430 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6409  avg_val_loss: 0.6430  time: 76s\n",
      "Epoch 7 - Score: 18.007044750075675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 49s) Loss: 0.6706 Grad: 1.3387 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6396 Grad: 0.7299 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6399 Grad: 0.8078 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 36s) Loss: 0.6308 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6432 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6399  avg_val_loss: 0.6432  time: 76s\n",
      "Epoch 8 - Score: 18.023819809149785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 6m 28s) Loss: 0.6319 Grad: 1.0999 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6286 Grad: 0.8506 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6281 Grad: 1.0198 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6304 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6281  avg_val_loss: 0.6425  time: 76s\n",
      "Epoch 9 - Score: 17.942526947632757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642769 --> 0.642537).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 30s) Loss: 0.6504 Grad: 0.9089 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6279 Grad: 0.6265 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6266 Grad: 0.5212 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6306 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6266  avg_val_loss: 0.6425  time: 75s\n",
      "Epoch 10 - Score: 17.940843866459467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642537 --> 0.642524).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 7 result ==========\n",
      "Score: 17.94084\n",
      "========== fold: 8 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 6m 51s) Loss: 0.7006 Grad: 1.2428 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6539 Grad: 0.6593 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6514 Grad: 0.8237 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6373 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6514  avg_val_loss: 0.6447  time: 77s\n",
      "Epoch 1 - Score: 18.200422887008866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.644738).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 39s) Loss: 0.6501 Grad: 0.5560 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 49s (remain 0m 18s) Loss: 0.6374 Grad: 0.5457 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6380 Grad: 0.5676 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6344 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6380  avg_val_loss: 0.6437  time: 74s\n",
      "Epoch 2 - Score: 18.050898701693736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644738 --> 0.643656).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 6m 35s) Loss: 0.6750 Grad: 1.2060 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6457 Grad: 1.7364 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6466 Grad: 1.2886 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6367 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6429 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6466  avg_val_loss: 0.6429  time: 75s\n",
      "Epoch 3 - Score: 17.942148429469658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643656 --> 0.642937).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 25s) Loss: 0.6381 Grad: 0.6207 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6442 Grad: 0.5547 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6443 Grad: 0.5470 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6338 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6418 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6443  avg_val_loss: 0.6418  time: 76s\n",
      "Epoch 4 - Score: 17.80448210188006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642937 --> 0.641756).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 54s) Loss: 0.6485 Grad: 0.5604 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6422 Grad: 0.6235 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6419 Grad: 0.4832 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6359 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6434 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6419  avg_val_loss: 0.6434  time: 77s\n",
      "Epoch 5 - Score: 17.993729423948217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 6m 3s) Loss: 0.6294 Grad: 0.5006 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6420 Grad: 0.6743 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6409 Grad: 0.6510 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6350 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6409  avg_val_loss: 0.6428  time: 77s\n",
      "Epoch 6 - Score: 17.91353960262225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 39s) Loss: 0.6483 Grad: 0.6219 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6389 Grad: 0.6068 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6397 Grad: 0.6861 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6345 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6413 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6397  avg_val_loss: 0.6413  time: 75s\n",
      "Epoch 7 - Score: 17.73453133474392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641756 --> 0.641282).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 36s) Loss: 0.6307 Grad: 1.1041 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6386 Grad: 0.6142 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6389 Grad: 0.6166 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6353 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6420 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6389  avg_val_loss: 0.6420  time: 76s\n",
      "Epoch 8 - Score: 17.828171658085314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 47s) Loss: 0.6071 Grad: 0.5302 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6282 Grad: 0.5410 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6273 Grad: 0.6255 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6336 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6420 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6273  avg_val_loss: 0.6420  time: 75s\n",
      "Epoch 9 - Score: 17.810104030420153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 47s) Loss: 0.6252 Grad: 0.6006 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6250 Grad: 0.5268 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6256 Grad: 0.8062 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 36s) Loss: 0.6352 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6256  avg_val_loss: 0.6421  time: 76s\n",
      "Epoch 10 - Score: 17.820281952897012\n",
      "========== fold: 8 result ==========\n",
      "Score: 17.73453\n",
      "========== fold: 9 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 52s) Loss: 0.7087 Grad: 1.7835 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6551 Grad: 0.4770 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6523 Grad: 0.5445 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 37s) Loss: 0.6520 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6434 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6523  avg_val_loss: 0.6434  time: 76s\n",
      "Epoch 1 - Score: 18.11219107761662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643398).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 51s) Loss: 0.6367 Grad: 0.4413 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6392 Grad: 0.9471 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6384 Grad: 0.5043 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6478 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6423 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6384  avg_val_loss: 0.6423  time: 76s\n",
      "Epoch 2 - Score: 17.945283610577835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643398 --> 0.642302).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 19s) Loss: 0.6658 Grad: 0.7210 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6467 Grad: 0.7573 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6467 Grad: 0.7419 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6473 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6426 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6467  avg_val_loss: 0.6426  time: 75s\n",
      "Epoch 3 - Score: 17.978083912551714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 6m 32s) Loss: 0.6444 Grad: 0.6748 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6450 Grad: 0.7244 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6446 Grad: 0.6666 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 33s) Loss: 0.6487 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6446  avg_val_loss: 0.6431  time: 76s\n",
      "Epoch 4 - Score: 18.046204532454087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 49s) Loss: 0.6306 Grad: 0.5848 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6422 Grad: 0.7364 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6426 Grad: 0.8557 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 35s) Loss: 0.6494 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6427 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6426  avg_val_loss: 0.6427  time: 77s\n",
      "Epoch 5 - Score: 17.997775627594386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 6m 3s) Loss: 0.6357 Grad: 1.3765 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6415 Grad: 0.5836 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6413 Grad: 0.7461 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6464 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6426 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6413  avg_val_loss: 0.6426  time: 76s\n",
      "Epoch 6 - Score: 17.992041472425754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 53s) Loss: 0.6545 Grad: 1.5397 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6409 Grad: 1.4559 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 10s (remain 0m 0s) Loss: 0.6415 Grad: 0.5113 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6479 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6422 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6415  avg_val_loss: 0.6422  time: 77s\n",
      "Epoch 7 - Score: 17.93677519027366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642302 --> 0.642190).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 51s) Loss: 0.6481 Grad: 1.0047 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 50s (remain 0m 19s) Loss: 0.6408 Grad: 0.6336 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6396 Grad: 0.8522 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6475 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6396  avg_val_loss: 0.6425  time: 75s\n",
      "Epoch 8 - Score: 17.968906799443648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 6m 23s) Loss: 0.6274 Grad: 0.6894 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 52s (remain 0m 19s) Loss: 0.6290 Grad: 0.6304 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6277 Grad: 8.8130 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 34s) Loss: 0.6449 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6277  avg_val_loss: 0.6421  time: 77s\n",
      "Epoch 9 - Score: 17.923068742920986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642190 --> 0.642133).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 42s) Loss: 0.6289 Grad: 0.4744 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 51s (remain 0m 19s) Loss: 0.6257 Grad: 0.5630 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 9s (remain 0m 0s) Loss: 0.6258 Grad: 0.7392 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 36s) Loss: 0.6461 \n",
      "EVAL: [15/16] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6422 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6258  avg_val_loss: 0.6422  time: 77s\n",
      "Epoch 10 - Score: 17.930792700012937\n",
      "========== fold: 9 result ==========\n",
      "Score: 17.92307\n",
      "========== CV ==========\n",
      "Score: 17.61574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 5.9s\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "8ijJJUa2d2Lx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 75311... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 3331.16MB of 3331.16MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>‚ñÅ</td></tr><tr><td>Score_fold0</td><td>‚ñÅ</td></tr><tr><td>Score_fold1</td><td>‚ñÅ</td></tr><tr><td>Score_fold2</td><td>‚ñÅ</td></tr><tr><td>Score_fold3</td><td>‚ñÅ</td></tr><tr><td>Score_fold4</td><td>‚ñÅ</td></tr><tr><td>Score_fold5</td><td>‚ñÅ</td></tr><tr><td>Score_fold6</td><td>‚ñÅ</td></tr><tr><td>Score_fold7</td><td>‚ñÅ</td></tr><tr><td>Score_fold8</td><td>‚ñÅ</td></tr><tr><td>Score_fold9</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñà</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr><tr><td>loss/train_fold0</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold1</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold2</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold3</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold4</td><td>‚ñà‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold5</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold6</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold7</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold8</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold9</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/valid_fold0</td><td>‚ñà‚ñÇ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÉ‚ñá‚ñÇ‚ñÇ</td></tr><tr><td>loss/valid_fold1</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>loss/valid_fold2</td><td>‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>loss/valid_fold3</td><td>‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>loss/valid_fold4</td><td>‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>loss/valid_fold5</td><td>‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>loss/valid_fold6</td><td>‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>loss/valid_fold7</td><td>‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold8</td><td>‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÉ</td></tr><tr><td>loss/valid_fold9</td><td>‚ñà‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold0</td><td>‚ñà‚ñÇ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold1</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold2</td><td>‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold3</td><td>‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>score/fold4</td><td>‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold5</td><td>‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr><tr><td>score/fold6</td><td>‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>score/fold7</td><td>‚ñá‚ñà‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold8</td><td>‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold9</td><td>‚ñà‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>17.61574</td></tr><tr><td>Score_fold0</td><td>17.50158</td></tr><tr><td>Score_fold1</td><td>17.49283</td></tr><tr><td>Score_fold2</td><td>18.22093</td></tr><tr><td>Score_fold3</td><td>17.25466</td></tr><tr><td>Score_fold4</td><td>17.73301</td></tr><tr><td>Score_fold5</td><td>17.12357</td></tr><tr><td>Score_fold6</td><td>17.19942</td></tr><tr><td>Score_fold7</td><td>17.94084</td></tr><tr><td>Score_fold8</td><td>17.73453</td></tr><tr><td>Score_fold9</td><td>17.92307</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.64041</td></tr><tr><td>loss/train_fold0</td><td>0.6261</td></tr><tr><td>loss/train_fold1</td><td>0.62557</td></tr><tr><td>loss/train_fold2</td><td>0.62536</td></tr><tr><td>loss/train_fold3</td><td>0.62636</td></tr><tr><td>loss/train_fold4</td><td>0.62505</td></tr><tr><td>loss/train_fold5</td><td>0.62722</td></tr><tr><td>loss/train_fold6</td><td>0.62539</td></tr><tr><td>loss/train_fold7</td><td>0.62665</td></tr><tr><td>loss/train_fold8</td><td>0.62564</td></tr><tr><td>loss/train_fold9</td><td>0.62579</td></tr><tr><td>loss/valid_fold0</td><td>0.64131</td></tr><tr><td>loss/valid_fold1</td><td>0.63914</td></tr><tr><td>loss/valid_fold2</td><td>0.64526</td></tr><tr><td>loss/valid_fold3</td><td>0.63807</td></tr><tr><td>loss/valid_fold4</td><td>0.64076</td></tr><tr><td>loss/valid_fold5</td><td>0.63839</td></tr><tr><td>loss/valid_fold6</td><td>0.63964</td></tr><tr><td>loss/valid_fold7</td><td>0.64252</td></tr><tr><td>loss/valid_fold8</td><td>0.64213</td></tr><tr><td>loss/valid_fold9</td><td>0.6422</td></tr><tr><td>score/fold0</td><td>17.54171</td></tr><tr><td>score/fold1</td><td>17.52097</td></tr><tr><td>score/fold2</td><td>18.38412</td></tr><tr><td>score/fold3</td><td>17.25466</td></tr><tr><td>score/fold4</td><td>17.8064</td></tr><tr><td>score/fold5</td><td>17.16706</td></tr><tr><td>score/fold6</td><td>17.32686</td></tr><tr><td>score/fold7</td><td>17.94084</td></tr><tr><td>score/fold8</td><td>17.82028</td></tr><tr><td>score/fold9</td><td>17.93079</td></tr></table>\n",
       "</div></div>\n",
       "Synced 7 W&B file(s), 1 media file(s), 11 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">faithful-hill-74</strong>: <a href=\"https://wandb.ai/imokuri/petfinder2/runs/bulu150s\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2/runs/bulu150s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211010_183444-bulu150s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "petfinder2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
