{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YDQH4n9zdG"
   },
   "source": [
    "# üìî About this notebook\n",
    "\n",
    "PetFinder.my - Pawpularity Contest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0pnACt-CQd"
   },
   "source": [
    "## üìù Memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eezrDVYa_yav"
   },
   "source": [
    "# üìö Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "32GYVF3l_wUO"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DhlpmaPbNqOs"
   },
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qPMtyPp8AWvZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHMIcuPvAdZI",
    "outputId": "a71431c4-ffb2-49da-9dd0-521e058cf409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "# netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
    "# !cp -f {netrc} ~/\n",
    "!wandb login\n",
    "wandb_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KPb3f6kLAYrP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uOtCk2BKGF"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m4LaDlPJBLil"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "!rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xKKkrScBBf44"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "# TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"crop/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQk8_n-5Bwun"
   },
   "source": [
    "# ü§î Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfK7G4EQBxpt",
    "outputId": "18adfc6c-9ff0-4652-bbf4-f1e2e931bdb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "STqXGbUhBz5f"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    wandb_entity = \"imokuri\"\n",
    "    wandb_project = \"petfinder2\"\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    validate = False\n",
    "    inference = False\n",
    "\n",
    "    debug = False\n",
    "    num_debug_data = 1000\n",
    "\n",
    "    amp = True\n",
    "    multi_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model list\n",
    "\n",
    "- resnext50_32x4d\n",
    "- vit_base_patch16_384\n",
    "- tf_efficientnetv2_m_in21k\n",
    "- swin_base_patch4_window12_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Vjl7MQHiFyFS"
   },
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 5,\n",
    "    \"epochs\": 20,\n",
    "    \"es_patience\": 5,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"model_name\": \"swin_base_patch4_window12_384_in22k\",\n",
    "    \"size\": 384,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dgConxiYIqTM"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config_defaults[\"n_fold\"] = 3\n",
    "    config_defaults[\"epochs\"] = 1\n",
    "    Config.print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BteR9_gVItes"
   },
   "outputs": [],
   "source": [
    "if Config.train:\n",
    "    wandb_job_type = \"training\"\n",
    "\n",
    "elif Config.inference:\n",
    "    wandb_job_type = \"inference\"\n",
    "\n",
    "elif Config.validate:\n",
    "    wandb_job_type = \"validation\"\n",
    "\n",
    "else:\n",
    "    wandb_job_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wBSFI0-_XL_-"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    wandb_tags.append(\"debug\")\n",
    "\n",
    "if Config.amp:\n",
    "    wandb_tags.append(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "JaQsAlSfJbnt",
    "outputId": "c2d21fae-09f0-4e17-e2c9-61f80760b2eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">peach-rain-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/imokuri/petfinder2\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/imokuri/petfinder2/runs/1glelmip\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2/runs/1glelmip</a><br/>\n",
       "                Run data is saved locally in <code>/data/jupyter/sugiyama/petfinder2/working/wandb/run-20211001_184051-1glelmip</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.debug:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        tags=wandb_tags,\n",
    "        mode=\"disabled\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        job_type=wandb_job_type,\n",
    "        tags=wandb_tags,\n",
    "        save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0kD8_kP0JjAC"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYjWTUW9Jtem"
   },
   "source": [
    "# EDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "-dEUJ_P9Jwzw",
    "outputId": "b6bee62a-8a84-4431-bd69-cfaecfc65207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9912 entries, 0 to 9911\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             9912 non-null   object\n",
      " 1   Subject Focus  9912 non-null   int64 \n",
      " 2   Eyes           9912 non-null   int64 \n",
      " 3   Face           9912 non-null   int64 \n",
      " 4   Near           9912 non-null   int64 \n",
      " 5   Action         9912 non-null   int64 \n",
      " 6   Accessory      9912 non-null   int64 \n",
      " 7   Group          9912 non-null   int64 \n",
      " 8   Collage        9912 non-null   int64 \n",
      " 9   Human          9912 non-null   int64 \n",
      " 10  Occlusion      9912 non-null   int64 \n",
      " 11  Info           9912 non-null   int64 \n",
      " 12  Blur           9912 non-null   int64 \n",
      " 13  Pawpularity    9912 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             8 non-null      object\n",
      " 1   Subject Focus  8 non-null      int64 \n",
      " 2   Eyes           8 non-null      int64 \n",
      " 3   Face           8 non-null      int64 \n",
      " 4   Near           8 non-null      int64 \n",
      " 5   Action         8 non-null      int64 \n",
      " 6   Accessory      8 non-null      int64 \n",
      " 7   Group          8 non-null      int64 \n",
      " 8   Collage        8 non-null      int64 \n",
      " 9   Human          8 non-null      int64 \n",
      " 10  Occlusion      8 non-null      int64 \n",
      " 11  Info           8 non-null      int64 \n",
      " 12  Blur           8 non-null      int64 \n",
      "dtypes: int64(12), object(1)\n",
      "memory usage: 960.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  \n",
       "3          0      0        0      0          0     1     0  \n",
       "4          1      0        1      0          1     1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8 non-null      object \n",
      " 1   Pawpularity  8 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>59.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>20.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>89.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3        67.75\n",
       "1  43a2262d7738e3d420d453815151079e        59.15\n",
       "2  4e429cead1848a298432a0acad014c9d        20.02\n",
       "3  80bc3ccafcc51b66303c2c263aa38486        94.53\n",
       "4  8f49844c382931444e68dffbe20228f4        89.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [train, test, sub]:\n",
    "    print(f\"=\" * 120)\n",
    "    df.info()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "uK-vChyCKVhZ",
    "outputId": "b7079faf-595b-4266-93eb-b45a15b2bc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pawpularity'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[\"Pawpularity\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nN20A-4KeX2"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yJhnZyCOKf_8"
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    if data == \"train\":\n",
    "        return A.Compose(\n",
    "            [\n",
    "                # A.Resize(config.size, config.size),\n",
    "                A.RandomResizedCrop(config.size, config.size),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(p=0.5),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    elif data == \"valid\":\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(config.size, config.size),\n",
    "                # A.CenterCrop(config.size, config.size),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDt-OBGKg33"
   },
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2XP3TB7KhvW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFYIILAsKih4"
   },
   "source": [
    "# üëë Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ahzUGk4sK6te"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "    if len(sub) > Config.num_debug_data:\n",
    "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF4pvz7-L7qT"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qrlmhizKMCku"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClI1iqtWLqU0"
   },
   "source": [
    "# Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raBuQ3EjLsmo",
    "outputId": "34daeb0b-754e-4661-ca9e-933cf98da029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1983\n",
      "1    1983\n",
      "2    1982\n",
      "3    1982\n",
      "4    1982\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fold_ = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(fold_.split(train[\"Id\"], train[\"Pawpularity\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
    "print(train.groupby([\"fold\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKN3QPeMMFf"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pX4piTk2MPVR"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, label\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "0CIysnf0OhGK",
    "outputId": "9ff2ea2f-3374-4a3b-e28e-acc95bba0227"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train)\n",
    "    image, label = train_ds[0]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "JwLeTm_EP9kK",
    "outputId": "281d1494-53f0-4a1f-938a-c2dd26c4dcd2"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    image, label = train_ds[0]\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbrC2J4KPEp4"
   },
   "source": [
    "# üöó Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "827lYLgIPFyY"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, config.n_class)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, config.n_class)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oudAIpPqQt6z",
    "outputId": "aa43e851-1f76-4709-f135-d3eb7eb248ee"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, label in train_loader:\n",
    "        output = model(image)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa8k53cRIi_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbkDI8DdRJ5w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFMHkJIMRLBi"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "f6jKOTHURLxM"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbNT_NeRMoB"
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "S4EF_M0NROIn"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0fQUwt7adOSk"
   },
   "outputs": [],
   "source": [
    "def get_result(result_df, fold=config.n_fold):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"Pawpularity\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    if fold == config.n_fold:\n",
    "        wandb.log({\"Score\": score})\n",
    "    else:\n",
    "        wandb.log({f\"Score_fold{fold}\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Ga4Bb8RQsF"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rRPW8QwiRbPC"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_preds = None\n",
    "\n",
    "    def __call__(self, val_loss, score, model, preds):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss >= self.val_loss_min + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "l9Kcw2bdeZR4"
   },
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2.0):\n",
    "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = [p for p in parameters if p.grad is not None]\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sWtO4py7Rcud"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=Config.amp):\n",
    "            # y_preds = model(images)\n",
    "            y_preds = model(images).squeeze(1)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            grad_norm = compute_grad_norm(model.parameters())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wlPZYJYgXRZ4"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # y_preds = model(images)\n",
    "            y_preds = model(images).squeeze(1)\n",
    "\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ybZNlV6YEp8"
   },
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JIDycP9YFvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mwWqWJdX232"
   },
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ei3alnONX4RY"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Optimizer\n",
    "    # ====================================================\n",
    "    def get_optimizer(model):\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"AdamW\":\n",
    "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer, train_folds):\n",
    "        num_data = len(train_folds)\n",
    "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
    "\n",
    "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
    "            scheduler = CosineAnnealingWarmupRestarts(\n",
    "                optimizer,\n",
    "                first_cycle_steps=num_steps,\n",
    "                max_lr=config.lr,\n",
    "                min_lr=config.min_lr,\n",
    "                warmup_steps=(num_steps // 10),\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(config.model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = amp.GradScaler(enabled=Config.amp)\n",
    "    scheduler = get_scheduler(optimizer, train_folds)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif config.criterion == \"MSELoss\":\n",
    "            criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # Early stopping\n",
    "    # ====================================================\n",
    "    es = EarlyStopping(\n",
    "        patience=config.es_patience,\n",
    "        verbose=True,\n",
    "        path=MODEL_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    )\n",
    "    \n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "        if config.criterion == \"BCEWithLogitsLoss\":\n",
    "            preds = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "        preds *= 100.0\n",
    "\n",
    "        # scoring\n",
    "        # score = get_score(valid_labels, preds.argmax(1))\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                f\"loss/train_fold{fold}\": avg_loss,\n",
    "                f\"loss/valid_fold{fold}\": avg_val_loss,\n",
    "                f\"score/fold{fold}\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        es(avg_val_loss, score, model, preds)\n",
    "        \n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    valid_folds[\"preds\"] = es.best_preds\n",
    "\n",
    "    return valid_folds, es.best_score, es.val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVj6cfuLc4VP"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "PpdJfNgUc5N3"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    if Config.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for fold in range(config.n_fold):\n",
    "            seed_torch(seed + fold)\n",
    "\n",
    "            _oof_df, score, loss = train_loop(train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_result.append([fold, score, loss])\n",
    "\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df, fold)\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        loss = statistics.mean([d[2] for d in oof_result])\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        table = wandb.Table(data=oof_result, columns=[\"fold\", \"score\", \"loss\"])\n",
    "        run.log({\"Fold Result\": table})\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(config.model_name, type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-J0CDXjkUaS"
   },
   "source": [
    "# üöÄ Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oeDBzpKHdIie",
    "outputId": "1d9d194b-eb20-4a24-9af0-29ab14beb789"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth\" to /home/sugiyama/.cache/torch/hub/checkpoints/swin_base_patch4_window12_384_22k.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/123] Elapsed 0m 25s (remain 52m 24s) Loss: 0.7021 Grad: 1.9864 LR: 0.000010  \n",
      "Epoch: [1][100/123] Elapsed 1m 19s (remain 0m 17s) Loss: 0.6592 Grad: 0.7039 LR: 0.000010  \n",
      "Epoch: [1][122/123] Elapsed 1m 30s (remain 0m 0s) Loss: 0.6563 Grad: 0.7838 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 11s) Loss: 0.6714 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6563  avg_val_loss: 0.6447  time: 104s\n",
      "Epoch 1 - Score: 18.18920738325412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6447 \n",
      "Validation loss decreased (inf --> 0.644689).  Saving model ...\n",
      "Epoch: [2][0/123] Elapsed 0m 2s (remain 5m 20s) Loss: 0.6469 Grad: 0.6479 LR: 0.000010  \n",
      "Epoch: [2][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6415 Grad: 0.9361 LR: 0.000010  \n",
      "Epoch: [2][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6413 Grad: 0.6676 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 5s) Loss: 0.6654 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6415 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6413  avg_val_loss: 0.6415  time: 79s\n",
      "Epoch 2 - Score: 17.781072311053325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644689 --> 0.641477).  Saving model ...\n",
      "Epoch: [3][0/123] Elapsed 0m 2s (remain 5m 30s) Loss: 0.6247 Grad: 0.6836 LR: 0.000010  \n",
      "Epoch: [3][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6349 Grad: 0.9158 LR: 0.000010  \n",
      "Epoch: [3][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6351 Grad: 0.7591 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 15s) Loss: 0.6688 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6351  avg_val_loss: 0.6408  time: 79s\n",
      "Epoch 3 - Score: 17.68356616506945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641477 --> 0.640842).  Saving model ...\n",
      "Epoch: [4][0/123] Elapsed 0m 2s (remain 5m 35s) Loss: 0.6226 Grad: 0.6883 LR: 0.000010  \n",
      "Epoch: [4][100/123] Elapsed 0m 55s (remain 0m 11s) Loss: 0.6276 Grad: 2.0567 LR: 0.000009  \n",
      "Epoch: [4][122/123] Elapsed 1m 5s (remain 0m 0s) Loss: 0.6285 Grad: 1.2758 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 11s) Loss: 0.6682 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6285  avg_val_loss: 0.6415  time: 79s\n",
      "Epoch 4 - Score: 17.759978757392904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6415 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: [5][0/123] Elapsed 0m 2s (remain 5m 28s) Loss: 0.6089 Grad: 0.8940 LR: 0.000009  \n",
      "Epoch: [5][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6215 Grad: 0.9356 LR: 0.000009  \n",
      "Epoch: [5][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6215 Grad: 1.0685 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 19s) Loss: 0.6790 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6441 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6215  avg_val_loss: 0.6441  time: 79s\n",
      "Epoch 5 - Score: 18.03523322895825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: [6][0/123] Elapsed 0m 2s (remain 5m 40s) Loss: 0.5934 Grad: 0.9523 LR: 0.000009  \n",
      "Epoch: [6][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6136 Grad: 1.1981 LR: 0.000008  \n",
      "Epoch: [6][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6127 Grad: 1.1494 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 10s) Loss: 0.6891 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6127  avg_val_loss: 0.6487  time: 81s\n",
      "Epoch 6 - Score: 18.600532714882778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6487 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: [7][0/123] Elapsed 0m 2s (remain 5m 42s) Loss: 0.6300 Grad: 1.6374 LR: 0.000008  \n",
      "Epoch: [7][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6059 Grad: 1.9478 LR: 0.000008  \n",
      "Epoch: [7][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6064 Grad: 1.3933 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 10s) Loss: 0.6833 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6469 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6064  avg_val_loss: 0.6469  time: 79s\n",
      "Epoch 7 - Score: 18.352355377321206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch: [8][0/123] Elapsed 0m 2s (remain 5m 49s) Loss: 0.5735 Grad: 0.8503 LR: 0.000008  \n",
      "Epoch: [8][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.5994 Grad: 1.0393 LR: 0.000007  \n",
      "Epoch: [8][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.5992 Grad: 1.4891 LR: 0.000007  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 18s) Loss: 0.6929 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.5992  avg_val_loss: 0.6509  time: 80s\n",
      "Epoch 8 - Score: 18.786584171871773\n",
      "========== fold: 0 result ==========\n",
      "Score: 17.68357\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6509 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Epoch: [1][0/123] Elapsed 0m 2s (remain 5m 51s) Loss: 0.7023 Grad: 2.1253 LR: 0.000010  \n",
      "Epoch: [1][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6529 Grad: 0.8759 LR: 0.000010  \n",
      "Epoch: [1][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6518 Grad: 0.7117 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 18s) Loss: 0.6305 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6518  avg_val_loss: 0.6431  time: 80s\n",
      "Epoch 1 - Score: 17.97402407237852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643061).  Saving model ...\n",
      "Epoch: [2][0/123] Elapsed 0m 2s (remain 6m 3s) Loss: 0.6491 Grad: 0.8118 LR: 0.000010  \n",
      "Epoch: [2][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6402 Grad: 0.7534 LR: 0.000010  \n",
      "Epoch: [2][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6396 Grad: 0.6902 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 10s) Loss: 0.6229 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6412 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6396  avg_val_loss: 0.6412  time: 80s\n",
      "Epoch 2 - Score: 17.720226053862177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643061 --> 0.641210).  Saving model ...\n",
      "Epoch: [3][0/123] Elapsed 0m 2s (remain 5m 55s) Loss: 0.6266 Grad: 1.1918 LR: 0.000010  \n",
      "Epoch: [3][100/123] Elapsed 0m 57s (remain 0m 12s) Loss: 0.6325 Grad: 1.5810 LR: 0.000010  \n",
      "Epoch: [3][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6338 Grad: 1.1677 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 11s) Loss: 0.6207 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6338  avg_val_loss: 0.6407  time: 81s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6407 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Score: 17.66449628228026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641210 --> 0.640731).  Saving model ...\n",
      "Epoch: [4][0/123] Elapsed 0m 2s (remain 5m 56s) Loss: 0.6202 Grad: 0.8960 LR: 0.000010  \n",
      "Epoch: [4][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6269 Grad: 1.1031 LR: 0.000009  \n",
      "Epoch: [4][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6268 Grad: 1.5198 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 15s) Loss: 0.6232 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6268  avg_val_loss: 0.6428  time: 80s\n",
      "Epoch 4 - Score: 17.852012858071653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6428 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: [5][0/123] Elapsed 0m 2s (remain 5m 38s) Loss: 0.6323 Grad: 1.4705 LR: 0.000009  \n",
      "Epoch: [5][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6207 Grad: 1.1388 LR: 0.000009  \n",
      "Epoch: [5][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6198 Grad: 1.2048 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6238 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6198  avg_val_loss: 0.6448  time: 81s\n",
      "Epoch 5 - Score: 18.109419994196912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6448 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: [6][0/123] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6063 Grad: 1.0657 LR: 0.000009  \n",
      "Epoch: [6][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6121 Grad: 1.3114 LR: 0.000008  \n",
      "Epoch: [6][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6116 Grad: 1.4437 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 13s) Loss: 0.6218 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6116  avg_val_loss: 0.6467  time: 80s\n",
      "Epoch 6 - Score: 18.325112392970134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6467 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: [7][0/123] Elapsed 0m 2s (remain 5m 34s) Loss: 0.5993 Grad: 1.3719 LR: 0.000008  \n",
      "Epoch: [7][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6053 Grad: 1.8624 LR: 0.000008  \n",
      "Epoch: [7][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6038 Grad: 1.4808 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6248 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6038  avg_val_loss: 0.6493  time: 80s\n",
      "Epoch 7 - Score: 18.56326431163183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch: [8][0/123] Elapsed 0m 2s (remain 5m 37s) Loss: 0.6092 Grad: 1.3581 LR: 0.000008  \n",
      "Epoch: [8][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.5992 Grad: 1.0709 LR: 0.000007  \n",
      "Epoch: [8][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.5983 Grad: 1.2093 LR: 0.000007  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6232 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6524 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.5983  avg_val_loss: 0.6524  time: 80s\n",
      "Epoch 8 - Score: 18.925302968126\n",
      "========== fold: 1 result ==========\n",
      "Score: 17.66450\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Epoch: [1][0/123] Elapsed 0m 2s (remain 5m 23s) Loss: 0.6872 Grad: 1.6578 LR: 0.000010  \n",
      "Epoch: [1][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6529 Grad: 0.5938 LR: 0.000010  \n",
      "Epoch: [1][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6514 Grad: 0.4454 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 13s) Loss: 0.6592 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6514  avg_val_loss: 0.6443  time: 79s\n",
      "Epoch 1 - Score: 18.154186745632312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6443 \n",
      "Validation loss decreased (inf --> 0.644320).  Saving model ...\n",
      "Epoch: [2][0/123] Elapsed 0m 2s (remain 6m 2s) Loss: 0.6463 Grad: 0.4510 LR: 0.000010  \n",
      "Epoch: [2][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6399 Grad: 0.6208 LR: 0.000010  \n",
      "Epoch: [2][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6392 Grad: 0.6633 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 21s) Loss: 0.6632 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6392  avg_val_loss: 0.6431  time: 79s\n",
      "Epoch 2 - Score: 17.979641350956808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6431 \n",
      "Validation loss decreased (0.644320 --> 0.643140).  Saving model ...\n",
      "Epoch: [3][0/123] Elapsed 0m 2s (remain 5m 39s) Loss: 0.6246 Grad: 0.6036 LR: 0.000010  \n",
      "Epoch: [3][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6325 Grad: 1.2983 LR: 0.000010  \n",
      "Epoch: [3][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6330 Grad: 0.7501 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 19s) Loss: 0.6646 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6330  avg_val_loss: 0.6432  time: 79s\n",
      "Epoch 3 - Score: 18.00223039259268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6432 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: [4][0/123] Elapsed 0m 2s (remain 6m 5s) Loss: 0.6429 Grad: 0.7328 LR: 0.000010  \n",
      "Epoch: [4][100/123] Elapsed 0m 57s (remain 0m 12s) Loss: 0.6262 Grad: 0.9886 LR: 0.000009  \n",
      "Epoch: [4][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6268 Grad: 1.0194 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 11s) Loss: 0.6699 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6268  avg_val_loss: 0.6435  time: 81s\n",
      "Epoch 4 - Score: 18.0157806171476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6435 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: [5][0/123] Elapsed 0m 3s (remain 6m 12s) Loss: 0.6100 Grad: 1.1879 LR: 0.000009  \n",
      "Epoch: [5][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6200 Grad: 0.9797 LR: 0.000009  \n",
      "Epoch: [5][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6199 Grad: 1.3834 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 15s) Loss: 0.6781 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6199  avg_val_loss: 0.6482  time: 79s\n",
      "Epoch 5 - Score: 18.48730898529937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6482 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: [6][0/123] Elapsed 0m 2s (remain 5m 52s) Loss: 0.6096 Grad: 1.1987 LR: 0.000009  \n",
      "Epoch: [6][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6111 Grad: 1.1338 LR: 0.000008  \n",
      "Epoch: [6][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6118 Grad: 1.7231 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 14s) Loss: 0.6813 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6118  avg_val_loss: 0.6500  time: 80s\n",
      "Epoch 6 - Score: 18.66886603928171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch: [7][0/123] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6001 Grad: 1.1839 LR: 0.000008  \n",
      "Epoch: [7][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6056 Grad: 1.8872 LR: 0.000008  \n",
      "Epoch: [7][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6049 Grad: 1.3438 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6890 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6547 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6049  avg_val_loss: 0.6547  time: 79s\n",
      "Epoch 7 - Score: 19.130285444010827\n",
      "========== fold: 2 result ==========\n",
      "Score: 17.97964\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Epoch: [1][0/123] Elapsed 0m 2s (remain 5m 55s) Loss: 0.8005 Grad: 4.3991 LR: 0.000010  \n",
      "Epoch: [1][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6560 Grad: 1.0572 LR: 0.000010  \n",
      "Epoch: [1][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6544 Grad: 0.7197 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 20s) Loss: 0.6376 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6426 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6544  avg_val_loss: 0.6426  time: 80s\n",
      "Epoch 1 - Score: 17.935701943971072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.642610).  Saving model ...\n",
      "Epoch: [2][0/123] Elapsed 0m 3s (remain 6m 7s) Loss: 0.6428 Grad: 1.2461 LR: 0.000010  \n",
      "Epoch: [2][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6384 Grad: 0.7206 LR: 0.000010  \n",
      "Epoch: [2][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6391 Grad: 1.3826 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 18s) Loss: 0.6364 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6391  avg_val_loss: 0.6422  time: 81s\n",
      "Epoch 2 - Score: 17.87461693873287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6422 \n",
      "Validation loss decreased (0.642610 --> 0.642194).  Saving model ...\n",
      "Epoch: [3][0/123] Elapsed 0m 3s (remain 6m 16s) Loss: 0.6308 Grad: 0.9440 LR: 0.000010  \n",
      "Epoch: [3][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6331 Grad: 1.6551 LR: 0.000010  \n",
      "Epoch: [3][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6327 Grad: 1.1270 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 14s) Loss: 0.6390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6327  avg_val_loss: 0.6423  time: 80s\n",
      "Epoch 3 - Score: 17.872209778765477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6423 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: [4][0/123] Elapsed 0m 2s (remain 5m 31s) Loss: 0.6462 Grad: 0.9109 LR: 0.000010  \n",
      "Epoch: [4][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6252 Grad: 1.2425 LR: 0.000009  \n",
      "Epoch: [4][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6266 Grad: 1.9174 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 11s) Loss: 0.6420 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6266  avg_val_loss: 0.6439  time: 81s\n",
      "Epoch 4 - Score: 18.066538033122466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6439 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: [5][0/123] Elapsed 0m 2s (remain 5m 56s) Loss: 0.6372 Grad: 1.5254 LR: 0.000009  \n",
      "Epoch: [5][100/123] Elapsed 0m 57s (remain 0m 12s) Loss: 0.6187 Grad: 2.2047 LR: 0.000009  \n",
      "Epoch: [5][122/123] Elapsed 1m 8s (remain 0m 0s) Loss: 0.6181 Grad: 1.9208 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 10s) Loss: 0.6443 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6181  avg_val_loss: 0.6472  time: 81s\n",
      "Epoch 5 - Score: 18.383123252091966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6472 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: [6][0/123] Elapsed 0m 2s (remain 5m 41s) Loss: 0.6096 Grad: 1.3912 LR: 0.000009  \n",
      "Epoch: [6][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6106 Grad: 2.9157 LR: 0.000008  \n",
      "Epoch: [6][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6106 Grad: 1.9214 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6450 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6106  avg_val_loss: 0.6495  time: 81s\n",
      "Epoch 6 - Score: 18.662080172896424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6495 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch: [7][0/123] Elapsed 0m 2s (remain 5m 37s) Loss: 0.5846 Grad: 1.7361 LR: 0.000008  \n",
      "Epoch: [7][100/123] Elapsed 0m 57s (remain 0m 12s) Loss: 0.6026 Grad: 1.4824 LR: 0.000008  \n",
      "Epoch: [7][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6032 Grad: 3.0460 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6510 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6531 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6032  avg_val_loss: 0.6531  time: 81s\n",
      "Epoch 7 - Score: 19.038605511528615\n",
      "========== fold: 3 result ==========\n",
      "Score: 17.87462\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Epoch: [1][0/123] Elapsed 0m 2s (remain 6m 2s) Loss: 0.7023 Grad: 1.7766 LR: 0.000010  \n",
      "Epoch: [1][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6542 Grad: 0.8006 LR: 0.000010  \n",
      "Epoch: [1][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6532 Grad: 0.8652 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6418 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6532  avg_val_loss: 0.6483  time: 80s\n",
      "Epoch 1 - Score: 18.593488386829858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6483 \n",
      "Validation loss decreased (inf --> 0.648259).  Saving model ...\n",
      "Epoch: [2][0/123] Elapsed 0m 2s (remain 5m 35s) Loss: 0.6366 Grad: 1.1266 LR: 0.000010  \n",
      "Epoch: [2][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6377 Grad: 0.9662 LR: 0.000010  \n",
      "Epoch: [2][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6385 Grad: 0.9517 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 15s) Loss: 0.6424 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6385  avg_val_loss: 0.6456  time: 80s\n",
      "Epoch 2 - Score: 18.26413058654688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6456 \n",
      "Validation loss decreased (0.648259 --> 0.645640).  Saving model ...\n",
      "Epoch: [3][0/123] Elapsed 0m 2s (remain 5m 45s) Loss: 0.6351 Grad: 0.8098 LR: 0.000010  \n",
      "Epoch: [3][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6326 Grad: 0.8978 LR: 0.000010  \n",
      "Epoch: [3][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6329 Grad: 1.2898 LR: 0.000010  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 12s) Loss: 0.6461 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6329  avg_val_loss: 0.6462  time: 79s\n",
      "Epoch 3 - Score: 18.297786515629774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6462 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: [4][0/123] Elapsed 0m 2s (remain 6m 3s) Loss: 0.6135 Grad: 1.3352 LR: 0.000010  \n",
      "Epoch: [4][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6253 Grad: 1.4536 LR: 0.000009  \n",
      "Epoch: [4][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6257 Grad: 0.8490 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 15s) Loss: 0.6509 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6470 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6257  avg_val_loss: 0.6470  time: 81s\n",
      "Epoch 4 - Score: 18.3652991068181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: [5][0/123] Elapsed 0m 2s (remain 6m 4s) Loss: 0.6299 Grad: 1.0571 LR: 0.000009  \n",
      "Epoch: [5][100/123] Elapsed 0m 56s (remain 0m 12s) Loss: 0.6176 Grad: 1.5912 LR: 0.000009  \n",
      "Epoch: [5][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6186 Grad: 1.2407 LR: 0.000009  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 13s) Loss: 0.6546 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6498 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6186  avg_val_loss: 0.6498  time: 80s\n",
      "Epoch 5 - Score: 18.680478780931296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: [6][0/123] Elapsed 0m 2s (remain 5m 38s) Loss: 0.6024 Grad: 1.2107 LR: 0.000009  \n",
      "Epoch: [6][100/123] Elapsed 0m 57s (remain 0m 12s) Loss: 0.6107 Grad: 1.3069 LR: 0.000008  \n",
      "Epoch: [6][122/123] Elapsed 1m 7s (remain 0m 0s) Loss: 0.6113 Grad: 1.3369 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 13s) Loss: 0.6662 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6113  avg_val_loss: 0.6545  time: 81s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6545 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Score: 19.13935934570412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch: [7][0/123] Elapsed 0m 2s (remain 5m 46s) Loss: 0.6125 Grad: 1.2369 LR: 0.000008  \n",
      "Epoch: [7][100/123] Elapsed 0m 55s (remain 0m 12s) Loss: 0.6033 Grad: 3.8647 LR: 0.000008  \n",
      "Epoch: [7][122/123] Elapsed 1m 6s (remain 0m 0s) Loss: 0.6041 Grad: 1.4651 LR: 0.000008  \n",
      "EVAL: [0/31] Elapsed 0m 2s (remain 1m 23s) Loss: 0.6657 \n",
      "EVAL: [30/31] Elapsed 0m 12s (remain 0m 0s) Loss: 0.6547 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6041  avg_val_loss: 0.6547  time: 79s\n",
      "Epoch 7 - Score: 19.201712796036635\n",
      "========== fold: 4 result ==========\n",
      "Score: 18.26413\n",
      "========== CV ==========\n",
      "Score: 17.89460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 3.1s\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8ijJJUa2d2Lx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 752280<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1723.34MB of 1723.34MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/data/jupyter/sugiyama/petfinder2/working/wandb/run-20211001_184051-1glelmip/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/data/jupyter/sugiyama/petfinder2/working/wandb/run-20211001_184051-1glelmip/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Score</td><td>17.8946</td></tr><tr><td>Score_fold0</td><td>17.68357</td></tr><tr><td>Score_fold1</td><td>17.6645</td></tr><tr><td>Score_fold2</td><td>17.97964</td></tr><tr><td>Score_fold3</td><td>17.87462</td></tr><tr><td>Score_fold4</td><td>18.26413</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.64251</td></tr><tr><td>loss/train_fold0</td><td>0.59916</td></tr><tr><td>loss/train_fold1</td><td>0.59831</td></tr><tr><td>loss/train_fold2</td><td>0.60495</td></tr><tr><td>loss/train_fold3</td><td>0.60324</td></tr><tr><td>loss/train_fold4</td><td>0.60408</td></tr><tr><td>loss/valid_fold0</td><td>0.65087</td></tr><tr><td>loss/valid_fold1</td><td>0.65242</td></tr><tr><td>loss/valid_fold2</td><td>0.65466</td></tr><tr><td>loss/valid_fold3</td><td>0.65309</td></tr><tr><td>loss/valid_fold4</td><td>0.6547</td></tr><tr><td>score/fold0</td><td>18.78658</td></tr><tr><td>score/fold1</td><td>18.9253</td></tr><tr><td>score/fold2</td><td>19.13029</td></tr><tr><td>score/fold3</td><td>19.03861</td></tr><tr><td>score/fold4</td><td>19.20171</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Score</td><td>‚ñÅ</td></tr><tr><td>Score_fold0</td><td>‚ñÅ</td></tr><tr><td>Score_fold1</td><td>‚ñÅ</td></tr><tr><td>Score_fold2</td><td>‚ñÅ</td></tr><tr><td>Score_fold3</td><td>‚ñÅ</td></tr><tr><td>Score_fold4</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr><tr><td>loss/train_fold0</td><td>‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold1</td><td>‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold2</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold3</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold4</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>loss/valid_fold0</td><td>‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñà</td></tr><tr><td>loss/valid_fold1</td><td>‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>loss/valid_fold2</td><td>‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà</td></tr><tr><td>loss/valid_fold3</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà</td></tr><tr><td>loss/valid_fold4</td><td>‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà</td></tr><tr><td>score/fold0</td><td>‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñà</td></tr><tr><td>score/fold1</td><td>‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>score/fold2</td><td>‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà</td></tr><tr><td>score/fold3</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà</td></tr><tr><td>score/fold4</td><td>‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 6 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">peach-rain-8</strong>: <a href=\"https://wandb.ai/imokuri/petfinder2/runs/1glelmip\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2/runs/1glelmip</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTImibVrWtn7FUurH3VbyQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "WandB Baseline - Image.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
