{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YDQH4n9zdG"
   },
   "source": [
    "# üìî About this notebook\n",
    "\n",
    "PetFinder.my - Pawpularity Contest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0pnACt-CQd"
   },
   "source": [
    "## üìù Memo\n",
    "\n",
    "- transformer „ÅÆ output „Å® feature „Çí SVR „ÅßÂ≠¶Áøí„Åô„Çã„ÄÇ\n",
    "    - NN „ÅÆ head „Å® SVR „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„Åô„Çã„ÄÇ [Link](https://www.kaggle.com/cdeotte/rapids-svr-boost-17-8/notebook)\n",
    "- swin base, large „Å® CSWin „Å® B7 „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÄÇ\n",
    "- ConvMixer [Link](https://github.com/tmp-iclr/convmixer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eezrDVYa_yav"
   },
   "source": [
    "# üìö Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1633394791716,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "32GYVF3l_wUO"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1633394792859,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "DhlpmaPbNqOs"
   },
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional local libraries\n",
    "\n",
    "# https://github.com/microsoft/CSWin-Transformer\n",
    "sys.path.append(\"../input/CSWin-Transformer\")\n",
    "import models\n",
    "\n",
    "# https://github.com/rwightman/efficientdet-pytorch\n",
    "# sys.path.append(\"../input/efficientdet-pytorch\")\n",
    "# import effdet\n",
    "\n",
    "# https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
    "sys.path.append(\"../input/Yet-Another-EfficientDet-Pytorch\")\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import (\n",
    "    STANDARD_COLORS,\n",
    "    get_index_label,\n",
    "    invert_affine,\n",
    "    plot_one_box,\n",
    "    postprocess,\n",
    "    preprocess,\n",
    "    standard_to_bgr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633394792860,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qPMtyPp8AWvZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ZHMIcuPvAdZI",
    "outputId": "8b28afb5-3466-40d4-9d0f-7a7a43f786b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "# netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
    "# !cp -f {netrc} ~/\n",
    "!wandb login\n",
    "wandb_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "KPb3f6kLAYrP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uOtCk2BKGF"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m4LaDlPJBLil"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "!rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "xKKkrScBBf44"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQk8_n-5Bwun"
   },
   "source": [
    "# üõ† Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "HfK7G4EQBxpt",
    "outputId": "266be0c6-6b79-4de4-8de1-8502eb577dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "STqXGbUhBz5f"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    wandb_entity = \"imokuri\"\n",
    "    wandb_project = \"petfinder2\"\n",
    "    print_freq = 100\n",
    "\n",
    "    preprocess = False  # crop images\n",
    "    train = True\n",
    "    train2 = False  # SVR\n",
    "    train3 = False  # 100 or not, TODO\n",
    "    validate = False\n",
    "    inference = False\n",
    "\n",
    "    debug = False\n",
    "    num_debug_data = 1000\n",
    "\n",
    "    amp = True\n",
    "    multi_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAK99CZOhfMV"
   },
   "source": [
    "Model examples\n",
    "\n",
    "- resnext50_32x4d\n",
    "- vit_base_patch16_384\n",
    "- tf_efficientnet_b7_ns\n",
    "- tf_efficientnetv2_l_in21k\n",
    "- swin_base_patch4_window12_384_in22k\n",
    "- swin_large_patch4_window7_224_in22k\n",
    "- swin_large_patch4_window12_384_in22k\n",
    "- CSWin_144_24322_large_384\n",
    "- convmixer_1536_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "Vjl7MQHiFyFS"
   },
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-7,\n",
    "    \"min_lr\": 1e-7,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    # \"momentum\": 0.9,\n",
    "    \"model_name\": \"swin_large_patch4_window12_384_in22k\",\n",
    "    \"size\": 384,\n",
    "    # \"compound_coef\": 6,\n",
    "    \"models\": [\n",
    "        # \"swin_large_patch4_window12_384_in22k:v14\",\n",
    "        # \"swin_base_patch4_window12_384_in22k:v1\",\n",
    "    ],\n",
    "    \"runs\": [\n",
    "        # with feats\n",
    "        # \"34qor14i\",  # 48 - swin large 384\n",
    "        # \"tmbsq7j1\",  # 55 - swin base 384\n",
    "        # \"1ngzxqt1\",  # 66 - swin large 224\n",
    "        # \"1b0qxlbc\",  # 67 - swin base 224\n",
    "        # no feats\n",
    "        # \"ymawjqn2\",  # 71 - swin large 384\n",
    "        # \"tppuuj4q\",  # 72 - swin large 224\n",
    "        # \"3ptw9dio\",  # 73 - swin base 384\n",
    "        # \"bulu150s\",  # 74 - swin base 224\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "dgConxiYIqTM"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config_defaults[\"n_fold\"] = 3\n",
    "    config_defaults[\"epochs\"] = 1\n",
    "    Config.print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BteR9_gVItes"
   },
   "outputs": [],
   "source": [
    "if Config.train:\n",
    "    wandb_job_type = \"training\"\n",
    "\n",
    "elif Config.train2:\n",
    "    wandb_job_type = \"training2\"\n",
    "\n",
    "elif Config.train3:\n",
    "    wandb_job_type = \"training3\"\n",
    "\n",
    "elif Config.preprocess:\n",
    "    wandb_job_type = \"preprocess\"\n",
    "\n",
    "elif Config.inference:\n",
    "    wandb_job_type = \"inference\"\n",
    "\n",
    "elif Config.validate:\n",
    "    wandb_job_type = \"validation\"\n",
    "\n",
    "else:\n",
    "    wandb_job_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "wBSFI0-_XL_-"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    wandb_tags.append(\"debug\")\n",
    "\n",
    "# if Config.amp:\n",
    "#     wandb_tags.append(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "LIDKN-b7jDOt"
   },
   "outputs": [],
   "source": [
    "wandb_tags.append(\"no feats\")\n",
    "wandb_tags.append(\"bins kfold\")\n",
    "wandb_tags.append(\"basic aug\")\n",
    "# wandb_tags.append(\"heavy aug\")\n",
    "# wandb_tags.append(\"mixup\")\n",
    "# wandb_tags.append(\"cutmix\")\n",
    "# wandb_tags.append(\"freeze norm\")\n",
    "wandb_tags.append(\"crop image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1633394796778,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JaQsAlSfJbnt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/imokuri/petfinder2/runs/23uqyg9f\" target=\"_blank\">vivid-microwave-84</a></strong> to <a href=\"https://wandb.ai/imokuri/petfinder2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.debug or Config.preprocess:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        tags=wandb_tags,\n",
    "        mode=\"disabled\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        job_type=wandb_job_type,\n",
    "        tags=wandb_tags,\n",
    "        save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633394796783,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0kD8_kP0JjAC"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYjWTUW9Jtem"
   },
   "source": [
    "# EDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1633394796784,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "-dEUJ_P9Jwzw",
    "outputId": "f98c8f40-5d7e-43f5-f524-58129cd3c758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9912 entries, 0 to 9911\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             9912 non-null   object\n",
      " 1   Subject Focus  9912 non-null   int64 \n",
      " 2   Eyes           9912 non-null   int64 \n",
      " 3   Face           9912 non-null   int64 \n",
      " 4   Near           9912 non-null   int64 \n",
      " 5   Action         9912 non-null   int64 \n",
      " 6   Accessory      9912 non-null   int64 \n",
      " 7   Group          9912 non-null   int64 \n",
      " 8   Collage        9912 non-null   int64 \n",
      " 9   Human          9912 non-null   int64 \n",
      " 10  Occlusion      9912 non-null   int64 \n",
      " 11  Info           9912 non-null   int64 \n",
      " 12  Blur           9912 non-null   int64 \n",
      " 13  Pawpularity    9912 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             8 non-null      object\n",
      " 1   Subject Focus  8 non-null      int64 \n",
      " 2   Eyes           8 non-null      int64 \n",
      " 3   Face           8 non-null      int64 \n",
      " 4   Near           8 non-null      int64 \n",
      " 5   Action         8 non-null      int64 \n",
      " 6   Accessory      8 non-null      int64 \n",
      " 7   Group          8 non-null      int64 \n",
      " 8   Collage        8 non-null      int64 \n",
      " 9   Human          8 non-null      int64 \n",
      " 10  Occlusion      8 non-null      int64 \n",
      " 11  Info           8 non-null      int64 \n",
      " 12  Blur           8 non-null      int64 \n",
      "dtypes: int64(12), object(1)\n",
      "memory usage: 960.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  \n",
       "3          0      0        0      0          0     1     0  \n",
       "4          1      0        1      0          1     1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8 non-null      object \n",
      " 1   Pawpularity  8 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>59.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>20.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>89.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3        67.75\n",
       "1  43a2262d7738e3d420d453815151079e        59.15\n",
       "2  4e429cead1848a298432a0acad014c9d        20.02\n",
       "3  80bc3ccafcc51b66303c2c263aa38486        94.53\n",
       "4  8f49844c382931444e68dffbe20228f4        89.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [train, test, sub]:\n",
    "    print(f\"=\" * 120)\n",
    "    df.info()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1633394797327,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "uK-vChyCKVhZ",
    "outputId": "3d5cf17f-3df5-4163-a7ba-be4bd83f6211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pawpularity'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[\"Pawpularity\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nN20A-4KeX2"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess(df):\n",
    "    df[\"Pawpularity100\"] = np.where(df[\"Pawpularity\"] == 100, 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.train3:\n",
    "    train = train_preprocess(df)\n",
    "    train[\"Pawpularity100\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDt-OBGKg33"
   },
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m2XP3TB7KhvW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFYIILAsKih4"
   },
   "source": [
    "# üëë Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.train2:\n",
    "    api = wandb.Api()\n",
    "    for artifact_id in config.models:\n",
    "        name_version = artifact_id.replace(\":\", \"-\")\n",
    "        if not os.path.exists(name_version):\n",
    "            os.makedirs(name_version)\n",
    "\n",
    "        try:\n",
    "            artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{artifact_id}\"\n",
    "            artifact = api.artifact(artifact_path)\n",
    "            artifact.download(name_version)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {artifact_path}, {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.validate:\n",
    "    api = wandb.Api()\n",
    "\n",
    "    for n, run_id in enumerate(config.runs):\n",
    "        if not os.path.exists(run_id):\n",
    "            os.makedirs(run_id)\n",
    "\n",
    "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
    "        run = api.run(run_path)\n",
    "\n",
    "        try:\n",
    "            run.file(\"oof_df.csv\").download(run_id)\n",
    "        except wandb.CommError:\n",
    "            # Already downloaded.\n",
    "            pass\n",
    "\n",
    "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"Id\", \"preds\"]]\n",
    "        oof.columns = [\"Id\", f\"preds{n}\"]\n",
    "        train = pd.merge(train, oof, on=\"Id\")\n",
    "\n",
    "    print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ahzUGk4sK6te"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "    if len(sub) > Config.num_debug_data:\n",
    "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF4pvz7-L7qT"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qrlmhizKMCku"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClI1iqtWLqU0"
   },
   "source": [
    "# Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BQVW6__Rjk_N"
   },
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(1 + np.log2(len(train))))\n",
    "train.loc[:, \"bins\"] = pd.cut(train[\"Pawpularity\"], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "raBuQ3EjLsmo",
    "outputId": "11fbcaa3-b48c-4143-c742-b0de3e717a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  bins\n",
      "0     0        33\n",
      "      1        42\n",
      "      2       111\n",
      "      3       203\n",
      "      4       188\n",
      "             ... \n",
      "9     9        28\n",
      "      10       20\n",
      "      11       14\n",
      "      12       11\n",
      "      13       36\n",
      "Length: 140, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
    "print(train.groupby([\"fold\", \"bins\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKN3QPeMMFf"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use croped images.\n"
     ]
    }
   ],
   "source": [
    "if \"crop image\" in wandb_tags:\n",
    "    TRAIN_IMAGE_PATH = DATA_DIR + \"crop/\"\n",
    "    print(\"Use croped images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "pX4piTk2MPVR"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\", \"fold\", \"bins\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1633394798564,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0CIysnf0OhGK",
    "outputId": "dca880e9-0d92-43e7-82e2-a11ecacb54c1"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train)\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionDataset(Dataset):\n",
    "    def __init__(self, df, force_input_size=None):\n",
    "        self.df = df\n",
    "        self.files = (f\"{TRAIN_IMAGE_PATH}/\" + df[\"Id\"] + \".jpg\").values\n",
    "\n",
    "        input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
    "        self.input_size = input_sizes[config.compound_coef] if force_input_size is None else force_input_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_img, framed_img, framed_meta = preprocess(self.files[idx], max_size=self.input_size)\n",
    "\n",
    "        x = torch.from_numpy(framed_img[0]).permute(2, 0, 1)\n",
    "\n",
    "        return x, ori_img, framed_img, framed_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and Config.preprocess:\n",
    "    train_ds = DetectionDataset(train)\n",
    "    x, ori_img, framed_img, framed_meta = train_ds[0]\n",
    "    plt.imshow(framed_img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797328,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "yJhnZyCOKf_8"
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    if data == \"train\":\n",
    "        if \"basic aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if \"heavy aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                    # A.CoarseDropout(p=0.5),\n",
    "                    # A.Cutout(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798565,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JwLeTm_EP9kK",
    "outputId": "9193e65d-197d-4e17-91d7-ee026dc0d38a"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = cutmix(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BqcwfvhMterO"
   },
   "outputs": [],
   "source": [
    "# https://github.com/yuhao318/mwh/blob/main/utils.py\n",
    "def mixup(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "\n",
    "    \"\"\"Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam = max(lam, 1 - lam)\n",
    "        # lam = min(lam, 1-lam)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    ## NO SYM\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # return mixed_image, mixed_label, lam\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "CiCqVeWhh2gr",
    "outputId": "81496b08-c725-48b9-ad02-573eb0346269"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = mixup(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbrC2J4KPEp4"
   },
   "source": [
    "# üöó Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/3867\n",
    "# TODO: Padding same „ÅÆ nn.Conv2d\n",
    "\n",
    "\n",
    "# https://github.com/tmp-iclr/convmixer\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "\n",
    "def ConvMixer(dim, depth, kernel_size=9, patch_size=7, n_classes=1000):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[\n",
    "            nn.Sequential(\n",
    "                Residual(\n",
    "                    nn.Sequential(\n",
    "                        nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"), nn.GELU(), nn.BatchNorm2d(dim)\n",
    "                    )\n",
    "                ),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim),\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )\n",
    "\n",
    "\n",
    "_cfg = {\n",
    "    \"url\": \"\",\n",
    "    \"num_classes\": 1000,\n",
    "    \"input_size\": (3, 224, 224),\n",
    "    \"pool_size\": None,\n",
    "    \"crop_pct\": 0.96,\n",
    "    \"interpolation\": \"bicubic\",\n",
    "    \"mean\": timm.data.IMAGENET_DEFAULT_MEAN,\n",
    "    \"std\": timm.data.IMAGENET_DEFAULT_STD,\n",
    "    \"classifier\": \"head\",\n",
    "}\n",
    "\n",
    "\n",
    "@timm.models.registry.register_model\n",
    "def convmixer_1536_20(pretrained=False, **kwargs):\n",
    "    model = ConvMixer(1536, 20, kernel_size=9, patch_size=7, n_classes=128)\n",
    "    model.default_cfg = _cfg\n",
    "    return model\n",
    "\n",
    "\n",
    "@timm.models.registry.register_model\n",
    "def convmixer_768_32(pretrained=False, **kwargs):\n",
    "    model = ConvMixer(768, 32, kernel_size=7, patch_size=7, n_classes=128)\n",
    "    model.default_cfg = _cfg\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798566,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "827lYLgIPFyY"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        if \"no feats\" in wandb_tags:\n",
    "            self.head2 = nn.Linear(128, config.n_class)\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.head1 = nn.Linear(140, 64)\n",
    "            self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        if \"no feats\" in wandb_tags:\n",
    "            x = self.head2(x)\n",
    "        else:\n",
    "            x = self.dropout(x)\n",
    "            x = torch.cat([x, feats], dim=1)\n",
    "            x = self.head1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model):\n",
    "    model.train()\n",
    "\n",
    "    # Freeze layer normalization\n",
    "    if any(key in config.model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "        for m in model.modules():\n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.LayerNorm):\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83590,
     "status": "ok",
     "timestamp": 1633394882149,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "oudAIpPqQt6z",
    "outputId": "32564315-dd7d-4bc9-f24b-620488993b3a"
   },
   "outputs": [],
   "source": [
    "if False and Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    model.apply(train_mode)\n",
    "\n",
    "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
    "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        # x = self.head1(x)\n",
    "        # x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and Config.debug and config.model_name != \"\":\n",
    "    model = BackboneModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa8k53cRIi_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FbkDI8DdRJ5w"
   },
   "outputs": [],
   "source": [
    "# https://github.com/davda54/sam/blob/main/sam.py\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    @torch.inference_mode()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    @torch.inference_mode()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    @torch.inference_mode()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFMHkJIMRLBi"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "f6jKOTHURLxM"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbNT_NeRMoB"
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "S4EF_M0NROIn"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0fQUwt7adOSk"
   },
   "outputs": [],
   "source": [
    "def get_result(result_df, fold=config.n_fold):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"Pawpularity\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    if fold == config.n_fold:\n",
    "        wandb.log({\"Score\": score})\n",
    "    else:\n",
    "        wandb.log({f\"Score_fold{fold}\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Ga4Bb8RQsF"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "rRPW8QwiRbPC"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "23roIn-jhfMe"
   },
   "outputs": [],
   "source": [
    "# https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_preds = None\n",
    "\n",
    "    def __call__(self, val_loss, score, model, preds):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss >= self.val_loss_min + self.delta:\n",
    "            if self.patience <= 0:\n",
    "                return\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "l9Kcw2bdeZR4"
   },
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2.0):\n",
    "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = [p for p in parameters if p.grad is not None]\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(data_loader, model, device):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "sWtO4py7Rcud",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    if \"freeze norm\" in wandb_tags:\n",
    "        model.apply(train_mode)\n",
    "    else:\n",
    "        model.train()\n",
    "    start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            mix_decision = 1.0\n",
    "        else:\n",
    "            mix_decision = np.random.rand()\n",
    "\n",
    "        if epoch >= config.epochs - 5:\n",
    "            mix_decision *= 2\n",
    "\n",
    "        if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "            images, features, label_a, label_b, lam = mixup(images, features, labels, alpha=0.5)\n",
    "\n",
    "        with amp.autocast(enabled=Config.amp):\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "            if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "            else:\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "\n",
    "                def closure():\n",
    "                    # y_preds = model(images, features)\n",
    "                    y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "                    if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                        loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "                    else:\n",
    "                        loss = criterion(y_preds, labels)\n",
    "\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "                scaler.step(optimizer, closure)\n",
    "            else:\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            grad_norm = compute_grad_norm(model.parameters())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_lr()[0]:.2e}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "wlPZYJYgXRZ4"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        with torch.inference_mode():\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training2 (Inference by backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_inference_fn(data_loader, model, device):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        with torch.inference_mode():\n",
    "            y_preds = model(images, features)\n",
    "            # y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(data_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(data_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(data_loader)):s} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ybZNlV6YEp8"
   },
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JIDycP9YFvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Preprocess Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(preds, imgs, files, imshow=False, imwrite=True):\n",
    "    for i in range(len(imgs)):\n",
    "        # if len(preds[i]['rois']) == 0:\n",
    "        #     continue\n",
    "\n",
    "        imgs[i] = imgs[i].copy()\n",
    "\n",
    "        for j in range(len(preds[i][\"rois\"])):\n",
    "            # cat or dog\n",
    "            if preds[i][\"class_ids\"][j] not in (16, 17):\n",
    "                continue\n",
    "            \n",
    "            x1, y1, x2, y2 = preds[i][\"rois\"][j].astype(np.int)\n",
    "            # obj = obj_list[preds[i][\"class_ids\"][j]]\n",
    "            # score = float(preds[i][\"scores\"][j])\n",
    "            # plot_one_box(\n",
    "            #     imgs[i], [x1, y1, x2, y2], label=obj, score=score, color=color_list[get_index_label(obj, obj_list)]\n",
    "            # )\n",
    "\n",
    "            # Crop image\n",
    "            imgs[i] = imgs[i][y1:y2, x1:x2, :]\n",
    "\n",
    "            # Apply only highest preds\n",
    "            break\n",
    "\n",
    "        if imshow:\n",
    "            cv2.imshow(\"img\", imgs[i])\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        if imwrite:\n",
    "            cv2.imwrite(f\"{DATA_DIR}/crop/{os.path.basename(files[i])}\", imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_loop(df):\n",
    "    crop_output_dir = f\"{DATA_DIR}/crop/\"\n",
    "    !rm -rf {crop_output_dir}\n",
    "    os.makedirs(crop_output_dir, exist_ok=True)\n",
    "    \n",
    "    # replace this part with your project's anchor config\n",
    "    anchor_ratios = [(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]\n",
    "    anchor_scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n",
    "\n",
    "    threshold = 0.2\n",
    "    iou_threshold = 0.2\n",
    "\n",
    "    color_list = standard_to_bgr(STANDARD_COLORS)\n",
    "    # tf bilinear interpolation is different from any other's, just make do\n",
    "    force_input_size = None  # set None to use default size\n",
    "    input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
    "    input_size = input_sizes[config.compound_coef] if force_input_size is None else force_input_size\n",
    "\n",
    "    model = EfficientDetBackbone(\n",
    "        compound_coef=config.compound_coef, num_classes=90, ratios=anchor_ratios, scales=anchor_scales\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"../input/pretrained-weights/efficientdet-d{config.compound_coef}.pth\", map_location=\"cpu\")\n",
    "    )\n",
    "\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    files = (f\"{TRAIN_IMAGE_PATH}/\" + df[\"Id\"] + \".jpg\").values\n",
    "\n",
    "    for file_ in tqdm(files, total=len(files)):\n",
    "        ori_imgs, framed_imgs, framed_metas = preprocess(file_, max_size=input_size)\n",
    "        x = torch.stack([torch.from_numpy(fi).to(device) for fi in framed_imgs], 0).permute(0, 3, 1, 2)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        with torch.inference_mode():\n",
    "            _, regression, classification, anchors = model(x)\n",
    "\n",
    "            regressBoxes = BBoxTransform()\n",
    "            clipBoxes = ClipBoxes()\n",
    "\n",
    "            out = postprocess(x, anchors, regression, classification, regressBoxes, clipBoxes, threshold, iou_threshold)\n",
    "\n",
    "        out = invert_affine(framed_metas, out)\n",
    "        save_image(out, ori_imgs, [file_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mwWqWJdX232"
   },
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ei3alnONX4RY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"train\"))\n",
    "    train_dataset_ = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    train_loader_ = DataLoader(\n",
    "        train_dataset_,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Optimizer\n",
    "    # ====================================================\n",
    "    def get_optimizer(model):\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"AdamW\":\n",
    "            optimizer = AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"SAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "            )\n",
    "        elif config.optimizer == \"ASAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "                rho=2.0,\n",
    "                adaptive=True,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer, train_dataset):\n",
    "        num_data = len(train_dataset)\n",
    "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
    "\n",
    "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
    "            scheduler = CosineAnnealingWarmupRestarts(\n",
    "                optimizer,\n",
    "                first_cycle_steps=num_steps,\n",
    "                max_lr=config.lr,\n",
    "                min_lr=config.min_lr,\n",
    "                warmup_steps=(num_steps // 10),\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(config.model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = amp.GradScaler(enabled=Config.amp)\n",
    "    scheduler = get_scheduler(optimizer, train_dataset)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif config.criterion == \"MSELoss\":\n",
    "            criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # Early stopping\n",
    "    # ====================================================\n",
    "    es = EarlyStopping(\n",
    "        patience=config.es_patience,\n",
    "        verbose=True,\n",
    "        path=MODEL_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            avg_loss = train_fn(train_loader_, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "        else:\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "        if config.criterion == \"BCEWithLogitsLoss\":\n",
    "            preds = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "        preds *= 100.0\n",
    "\n",
    "        # scoring\n",
    "        # score = get_score(valid_labels, preds.argmax(1))\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                f\"loss/train_fold{fold}\": avg_loss,\n",
    "                f\"loss/valid_fold{fold}\": avg_val_loss,\n",
    "                f\"score/fold{fold}\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        es(avg_val_loss, score, model, preds)\n",
    "\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    valid_folds[\"preds\"] = es.best_preds\n",
    "\n",
    "    return valid_folds, es.best_score, es.val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Train2 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_loop(df, artifact_id, fold):\n",
    "    LOGGER.info(f\"========== ID: {artifact_id} fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model_name = artifact_id.split(\":\")[0]\n",
    "    model = BackboneModel(model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    path = f\"{artifact_id.replace(':', '-')}/{model_name}_fold{fold}_best.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    # ====================================================\n",
    "    # Inference by backbone\n",
    "    # ====================================================\n",
    "\n",
    "    train_preds = train2_inference_fn(train_loader, model, device)\n",
    "    valid_preds = train2_inference_fn(valid_loader, model, device)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler.fit(np.vstack([train_preds, valid_preds]))\n",
    "\n",
    "    train_norm = scaler.fit_transform(train_preds)\n",
    "    valid_norm = scaler.transform(valid_preds)\n",
    "\n",
    "    scaler_path = MODEL_DIR + f\"{model_name}-StandardScaler_fold{fold}_best.pkl\"\n",
    "    pickle.dump(scaler, open(scaler_path, \"wb\"))\n",
    "\n",
    "    # ====================================================\n",
    "    # Tuning SVR parameters\n",
    "    # ====================================================\n",
    "    # https://github.com/hkaneko1985/fastoptsvrhyperparams/blob/master/fastoptsvrhyperparams.ipynb\n",
    "    start_time = time.time()\n",
    "\n",
    "    svr_epss = 2 ** np.arange(-10, 1, dtype=float)  # Candidates of epsilon\n",
    "    svr_cs = 2 ** np.arange(-5, 11, dtype=float)  # Candidates of C\n",
    "    svr_gammas = 2 ** np.arange(-20, 11, dtype=float)  # Candidates of gamma\n",
    "\n",
    "    # Optimize epsilon with cross-validation\n",
    "    model_tune_eps = GridSearchCV(SVR(kernel=\"rbf\", C=3), {\"epsilon\": svr_epss}, verbose=1)\n",
    "    model_tune_eps.fit(train_norm, train_dataset.labels)\n",
    "    optimal_eps = model_tune_eps.best_params_[\"epsilon\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized eps: {elapsed:.0f}s\")\n",
    "\n",
    "    # Optimize C with cross-validation\n",
    "    model_tune_c = GridSearchCV(SVR(kernel=\"rbf\", epsilon=optimal_eps), {\"C\": svr_cs}, verbose=1)\n",
    "    model_tune_c.fit(train_norm, train_dataset.labels)\n",
    "    optimal_c = model_tune_c.best_params_[\"C\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized c: {elapsed:.0f}s\")\n",
    "\n",
    "    # Optimize gamma with cross-validation (optional)\n",
    "    model_tune_gamma = GridSearchCV(\n",
    "        SVR(kernel=\"rbf\", epsilon=optimal_eps, C=optimal_c), {\"gamma\": svr_gammas}, verbose=1\n",
    "    )\n",
    "    model_tune_gamma.fit(train_norm, train_dataset.labels)\n",
    "    optimal_gamma = model_tune_gamma.best_params_[\"gamma\"]\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Optimized gamma: {elapsed:.0f}s\")\n",
    "\n",
    "    best_params = {\n",
    "        \"C\": optimal_c,\n",
    "        \"epsilon\": optimal_eps,\n",
    "        \"gamma\": optimal_gamma,\n",
    "    }\n",
    "    print(f\"{best_params}\")\n",
    "\n",
    "    param_path = MODEL_DIR + f\"{model_name}-SVR-params_fold{fold}_best.json\"\n",
    "    with open(param_path, \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_svr = SVR(C=optimal_c, epsilon=optimal_eps, gamma=optimal_gamma)\n",
    "    model_svr.fit(train_norm, train_dataset.labels)\n",
    "\n",
    "    preds = model_svr.predict(valid_norm)\n",
    "    preds *= 100.0\n",
    "\n",
    "    # scoring\n",
    "    # score = get_score(valid_labels, preds.argmax(1))\n",
    "    score = get_score(valid_labels, preds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    LOGGER.info(f\"Score: {score}  time: {elapsed:.0f}s\")\n",
    "\n",
    "    svr_path = MODEL_DIR + f\"{model_name}-SVR_fold{fold}_best.pkl\"\n",
    "    pickle.dump(model_svr, open(svr_path, \"wb\"))\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    # valid_folds[\"preds\"] = es.best_preds\n",
    "    valid_folds[\"preds\"] = preds\n",
    "\n",
    "    return valid_folds, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVj6cfuLc4VP"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "PpdJfNgUc5N3"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Preprocess\n",
    "    # ====================================================\n",
    "    if Config.preprocess:\n",
    "        preprocess_loop(train)\n",
    "\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    if Config.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for fold in range(config.n_fold):\n",
    "            seed_torch(seed + fold)\n",
    "\n",
    "            _oof_df, score, loss = train_loop(train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_result.append([fold, score, loss])\n",
    "\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df, fold)\n",
    "            \n",
    "            break\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        loss = statistics.mean([d[2] for d in oof_result])\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        table = wandb.Table(data=oof_result, columns=[\"fold\", \"score\", \"loss\"])\n",
    "        run.log({\"Fold Result\": table})\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(config.model_name, type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)\n",
    "\n",
    "    # ====================================================\n",
    "    # Validation\n",
    "    # ====================================================\n",
    "    if Config.validate:\n",
    "        cols = [f\"preds{n}\" for n in range(len(config.runs))]\n",
    "        train[\"preds\"] = train[cols].values.mean(axis=1)\n",
    "\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(train)\n",
    "\n",
    "        # save result\n",
    "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    if Config.train2:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for n, artifact_id in enumerate(config.models):\n",
    "\n",
    "            for fold in range(config.n_fold):\n",
    "                seed_torch(seed + fold)\n",
    "                _oof_df, score = train2_loop(train, artifact_id, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df, fold)\n",
    "\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "\n",
    "            break\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(f\"{artifact_id.split(':')[0]}-SVR\", type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-J0CDXjkUaS"
   },
   "source": [
    "# üöÄ Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "oeDBzpKHdIie"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 26s (remain 62m 1s) Loss: 0.6849 Grad: 0.8255 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 24s (remain 0m 31s) Loss: 0.6531 Grad: 0.4176 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 46s (remain 0m 0s) Loss: 0.6512 Grad: 0.4929 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6627 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6512  avg_val_loss: 0.6436  time: 114s\n",
      "Epoch 1 - Score: 17.896329174554683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6436 \n",
      "Validation loss decreased (inf --> 0.643622).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 4m 41s) Loss: 0.6364 Grad: 0.7431 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6380 Grad: 0.9707 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6377 Grad: 0.6070 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 24s) Loss: 0.6618 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6377  avg_val_loss: 0.6421  time: 90s\n",
      "Epoch 2 - Score: 17.672290955413143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6421 \n",
      "Validation loss decreased (0.643622 --> 0.642150).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 12s) Loss: 0.6702 Grad: 0.7872 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6471 Grad: 0.9863 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6467 Grad: 0.4523 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6634 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6467  avg_val_loss: 0.6428  time: 91s\n",
      "Epoch 3 - Score: 17.752777714185264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6428 \n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 51s) Loss: 0.6416 Grad: 0.4447 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6459 Grad: 0.6649 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6454 Grad: 0.6251 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6660 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6454  avg_val_loss: 0.6431  time: 91s\n",
      "Epoch 4 - Score: 17.790269565946748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6431 \n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 49s) Loss: 0.6628 Grad: 0.8749 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6424 Grad: 0.8744 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6433 Grad: 0.5217 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6620 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6433  avg_val_loss: 0.6417  time: 90s\n",
      "Epoch 5 - Score: 17.610964920511847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6417 \n",
      "Validation loss decreased (0.642150 --> 0.641700).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 4m 43s) Loss: 0.6695 Grad: 1.0425 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6409 Grad: 0.8415 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6418 Grad: 0.7717 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6644 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6418  avg_val_loss: 0.6427  time: 90s\n",
      "Epoch 6 - Score: 17.73127333446184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6427 \n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 45s) Loss: 0.6408 Grad: 0.6232 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6403 Grad: 0.9893 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6413 Grad: 0.5663 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6638 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6413  avg_val_loss: 0.6423  time: 91s\n",
      "Epoch 7 - Score: 17.673156098223316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6423 \n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 4m 55s) Loss: 0.6610 Grad: 1.0911 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6393 Grad: 0.9174 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6400 Grad: 0.6082 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6644 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6430 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6400  avg_val_loss: 0.6430  time: 89s\n",
      "Epoch 8 - Score: 17.760966662412525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 32s) Loss: 0.6285 Grad: 0.3342 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6256 Grad: 1.0852 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6261 Grad: 0.5554 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 24s) Loss: 0.6654 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6261  avg_val_loss: 0.6433  time: 90s\n",
      "Epoch 9 - Score: 17.777573913619637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 4m 42s) Loss: 0.6265 Grad: 0.5697 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6243 Grad: 0.6879 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6241 Grad: 0.7300 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6664 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6441 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6241  avg_val_loss: 0.6441  time: 90s\n",
      "Epoch 10 - Score: 17.862830366967856\n",
      "========== fold: 0 result ==========\n",
      "Score: 17.61096\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 5s) Loss: 0.7025 Grad: 1.0569 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6552 Grad: 0.5812 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6527 Grad: 0.4437 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6306 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6413 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6527  avg_val_loss: 0.6413  time: 91s\n",
      "Epoch 1 - Score: 17.823165179049123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.641269).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 9s) Loss: 0.6214 Grad: 1.0252 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6383 Grad: 0.6348 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6383 Grad: 0.5484 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6278 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6383  avg_val_loss: 0.6396  time: 92s\n",
      "Epoch 2 - Score: 17.601810955892084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641269 --> 0.639582).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6665 Grad: 0.7024 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6471 Grad: 0.5296 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6475 Grad: 0.5088 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6253 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6475  avg_val_loss: 0.6394  time: 91s\n",
      "Epoch 3 - Score: 17.57404560359141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639582 --> 0.639399).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 24s) Loss: 0.6275 Grad: 0.7542 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6449 Grad: 0.6387 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6448 Grad: 0.7927 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6249 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6448  avg_val_loss: 0.6393  time: 89s\n",
      "Epoch 4 - Score: 17.55218962037771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639399 --> 0.639268).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 52s) Loss: 0.6614 Grad: 0.5764 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6437 Grad: 0.6811 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6428 Grad: 0.7539 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6258 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6428  avg_val_loss: 0.6404  time: 90s\n",
      "Epoch 5 - Score: 17.66840470417774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 12s) Loss: 0.6407 Grad: 0.5591 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6408 Grad: 0.8489 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6420 Grad: 0.4125 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6243 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6401 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6420  avg_val_loss: 0.6401  time: 89s\n",
      "Epoch 6 - Score: 17.649944883447173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 54s) Loss: 0.6540 Grad: 0.9978 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6404 Grad: 0.5927 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6408 Grad: 0.4209 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6250 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6392 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6408  avg_val_loss: 0.6392  time: 91s\n",
      "Epoch 7 - Score: 17.52926945330713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639268 --> 0.639224).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 4m 51s) Loss: 0.6444 Grad: 0.6016 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6405 Grad: 0.5989 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6396 Grad: 0.8270 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6259 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6396  avg_val_loss: 0.6394  time: 92s\n",
      "Epoch 8 - Score: 17.55638490274438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 5s) Loss: 0.6493 Grad: 0.5860 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6286 Grad: 0.4742 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6275 Grad: 0.5268 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6256 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6395 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6275  avg_val_loss: 0.6395  time: 89s\n",
      "Epoch 9 - Score: 17.557959395162207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 23s) Loss: 0.6288 Grad: 0.7649 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6262 Grad: 0.4854 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6255 Grad: 0.8357 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6256 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6398 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6255  avg_val_loss: 0.6398  time: 91s\n",
      "Epoch 10 - Score: 17.599367318919313\n",
      "========== fold: 1 result ==========\n",
      "Score: 17.52927\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 4m 54s) Loss: 0.6959 Grad: 1.0033 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6541 Grad: 0.3596 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6516 Grad: 0.4401 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6339 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6516  avg_val_loss: 0.6444  time: 91s\n",
      "Epoch 1 - Score: 18.2799494066645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6444 \n",
      "Validation loss decreased (inf --> 0.644409).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 4m 47s) Loss: 0.6273 Grad: 0.5473 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6381 Grad: 0.4614 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6375 Grad: 0.7807 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6363 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6427 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6375  avg_val_loss: 0.6427  time: 91s\n",
      "Epoch 2 - Score: 18.07281378544427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644409 --> 0.642661).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 4m 43s) Loss: 0.6373 Grad: 0.6304 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6470 Grad: 1.0984 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6465 Grad: 0.6106 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6356 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6457 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6465  avg_val_loss: 0.6457  time: 91s\n",
      "Epoch 3 - Score: 18.429085041100546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 54s) Loss: 0.6485 Grad: 0.7701 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6450 Grad: 0.4845 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6447 Grad: 0.3908 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6347 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6435 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6447  avg_val_loss: 0.6435  time: 91s\n",
      "Epoch 4 - Score: 18.17200765569571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 56s) Loss: 0.6399 Grad: 0.7363 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6436 Grad: 0.6217 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6428 Grad: 1.1141 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6367 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6428  avg_val_loss: 0.6433  time: 91s\n",
      "Epoch 5 - Score: 18.149149692876836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 5s) Loss: 0.6430 Grad: 0.5826 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6409 Grad: 0.5720 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6410 Grad: 0.7308 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6372 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6410  avg_val_loss: 0.6437  time: 91s\n",
      "Epoch 6 - Score: 18.193557680691907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 56s) Loss: 0.6302 Grad: 0.4286 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6416 Grad: 0.6494 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6402 Grad: 0.4971 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6384 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6440 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6402  avg_val_loss: 0.6440  time: 90s\n",
      "Epoch 7 - Score: 18.2258388655884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 6s) Loss: 0.6506 Grad: 0.5585 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6399 Grad: 0.7967 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6400 Grad: 0.3887 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6385 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6440 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6400  avg_val_loss: 0.6440  time: 89s\n",
      "Epoch 8 - Score: 18.232203966264336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 11s) Loss: 0.6304 Grad: 0.3918 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6273 Grad: 0.4999 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6267 Grad: 0.4196 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6391 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6267  avg_val_loss: 0.6439  time: 90s\n",
      "Epoch 9 - Score: 18.22008329565255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6439 \n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 4m 43s) Loss: 0.6149 Grad: 0.5054 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6247 Grad: 0.8131 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6251 Grad: 0.6805 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6400 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6442 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6251  avg_val_loss: 0.6442  time: 91s\n",
      "Epoch 10 - Score: 18.265993967409273\n",
      "========== fold: 2 result ==========\n",
      "Score: 18.07281\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6993 Grad: 1.0266 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6527 Grad: 0.4360 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6510 Grad: 0.4091 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6445 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6510  avg_val_loss: 0.6398  time: 89s\n",
      "Epoch 1 - Score: 17.490573020415667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6398 \n",
      "Validation loss decreased (inf --> 0.639798).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 4m 46s) Loss: 0.6188 Grad: 0.3634 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6386 Grad: 0.4841 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6383 Grad: 0.2738 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6383  avg_val_loss: 0.6372  time: 91s\n",
      "Epoch 2 - Score: 17.132468567065438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6372 \n",
      "Validation loss decreased (0.639798 --> 0.637171).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 17s) Loss: 0.6371 Grad: 0.5849 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6489 Grad: 0.9324 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6482 Grad: 0.4507 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6435 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6374 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6482  avg_val_loss: 0.6374  time: 91s\n",
      "Epoch 3 - Score: 17.1638755872736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 39s) Loss: 0.6492 Grad: 0.6122 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6444 Grad: 1.3302 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6442 Grad: 0.7525 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6440 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6442  avg_val_loss: 0.6378  time: 91s\n",
      "Epoch 4 - Score: 17.213272219093508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 47s) Loss: 0.6445 Grad: 0.6269 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6425 Grad: 0.9171 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6425 Grad: 2.8714 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6421 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6367 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6425  avg_val_loss: 0.6367  time: 89s\n",
      "Epoch 5 - Score: 17.067984946321857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.637171 --> 0.636722).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 4m 46s) Loss: 0.6512 Grad: 0.4501 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6412 Grad: 1.8548 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6412 Grad: 0.4281 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6441 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6366 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6412  avg_val_loss: 0.6366  time: 90s\n",
      "Epoch 6 - Score: 17.06590147115428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.636722 --> 0.636588).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 6s) Loss: 0.6356 Grad: 0.8859 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6414 Grad: 0.4786 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6418 Grad: 0.5806 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6437 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6361 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6418  avg_val_loss: 0.6361  time: 91s\n",
      "Epoch 7 - Score: 16.992232794443616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.636588 --> 0.636094).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 4m 45s) Loss: 0.6455 Grad: 0.4965 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6406 Grad: 0.6037 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6400 Grad: 0.6253 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6438 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6370 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6400  avg_val_loss: 0.6370  time: 91s\n",
      "Epoch 8 - Score: 17.100784577641498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 4m 46s) Loss: 0.6512 Grad: 0.8070 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6272 Grad: 0.5570 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6275 Grad: 0.4167 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6432 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6357 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6275  avg_val_loss: 0.6357  time: 91s\n",
      "Epoch 9 - Score: 16.934143229899053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.636094 --> 0.635672).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 4m 43s) Loss: 0.6167 Grad: 0.4185 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6257 Grad: 0.4046 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6256 Grad: 0.5579 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6435 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6256  avg_val_loss: 0.6356  time: 91s\n",
      "Epoch 10 - Score: 16.930409817162857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.635672 --> 0.635644).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 16.93041\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 3s) Loss: 0.7188 Grad: 1.0767 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 58s (remain 0m 22s) Loss: 0.6573 Grad: 0.4748 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6529 Grad: 0.4895 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6439 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6457 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6529  avg_val_loss: 0.6457  time: 88s\n",
      "Epoch 1 - Score: 18.43119658439564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.645714).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 4m 53s) Loss: 0.6385 Grad: 0.3860 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6389 Grad: 0.5001 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6383 Grad: 0.4941 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6453 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6383  avg_val_loss: 0.6435  time: 89s\n",
      "Epoch 2 - Score: 18.146356130903403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6435 \n",
      "Validation loss decreased (0.645714 --> 0.643520).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 4m 45s) Loss: 0.6417 Grad: 0.5591 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6479 Grad: 0.6297 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6466 Grad: 1.3674 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6401 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6443 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6466  avg_val_loss: 0.6443  time: 91s\n",
      "Epoch 3 - Score: 18.245773575872317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 47s) Loss: 0.6395 Grad: 1.8756 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6452 Grad: 0.6072 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6454 Grad: 0.4736 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6421 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6435 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6454  avg_val_loss: 0.6435  time: 91s\n",
      "Epoch 4 - Score: 18.155757426883493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 38s) Loss: 0.6430 Grad: 0.4259 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6416 Grad: 0.8406 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6428 Grad: 2.2822 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6432 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6440 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6428  avg_val_loss: 0.6440  time: 91s\n",
      "Epoch 5 - Score: 18.222411103019066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 4m 52s) Loss: 0.6494 Grad: 0.6109 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6435 Grad: 0.5739 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6419 Grad: 0.8415 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6420 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6419  avg_val_loss: 0.6445  time: 91s\n",
      "Epoch 6 - Score: 18.26648780277215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6445 \n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 23s) Loss: 0.6450 Grad: 0.6078 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6416 Grad: 0.5835 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6412 Grad: 0.6274 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6428 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6442 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6412  avg_val_loss: 0.6442  time: 90s\n",
      "Epoch 7 - Score: 18.228157396319332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 4m 40s) Loss: 0.6508 Grad: 0.6053 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6400 Grad: 0.4957 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6399 Grad: 0.5693 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6415 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6442 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6399  avg_val_loss: 0.6442  time: 90s\n",
      "Epoch 8 - Score: 18.22825633433458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 4m 57s) Loss: 0.6232 Grad: 0.3982 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6282 Grad: 0.5782 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6272 Grad: 0.7453 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6434 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6439 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6272  avg_val_loss: 0.6439  time: 89s\n",
      "Epoch 9 - Score: 18.1928954896666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 10s) Loss: 0.6355 Grad: 0.4494 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6266 Grad: 0.4388 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6257 Grad: 0.4722 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6436 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6440 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6257  avg_val_loss: 0.6440  time: 91s\n",
      "Epoch 10 - Score: 18.204336250264795\n",
      "========== fold: 4 result ==========\n",
      "Score: 18.14636\n",
      "========== fold: 5 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 11s) Loss: 0.7378 Grad: 1.4158 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6562 Grad: 0.8506 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6537 Grad: 0.4981 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6567 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6537  avg_val_loss: 0.6428  time: 89s\n",
      "Epoch 1 - Score: 17.78751042936503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.642816).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6347 Grad: 0.4473 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6385 Grad: 2.5680 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6385 Grad: 0.6376 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6564 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6410 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6385  avg_val_loss: 0.6410  time: 91s\n",
      "Epoch 2 - Score: 17.533753329899273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642816 --> 0.641034).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 25s) Loss: 0.6524 Grad: 0.7336 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6492 Grad: 0.6027 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6479 Grad: 1.0668 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6556 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6395 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6479  avg_val_loss: 0.6395  time: 91s\n",
      "Epoch 3 - Score: 17.340148820799985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641034 --> 0.639487).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 42s) Loss: 0.6631 Grad: 0.6937 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6450 Grad: 0.6966 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6446 Grad: 0.4599 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6548 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6446  avg_val_loss: 0.6393  time: 90s\n",
      "Epoch 4 - Score: 17.302753574271666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639487 --> 0.639316).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 5s) Loss: 0.6689 Grad: 0.5541 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6439 Grad: 0.7996 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6433 Grad: 0.7228 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6544 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6433  avg_val_loss: 0.6393  time: 91s\n",
      "Epoch 5 - Score: 17.30443845411637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639316 --> 0.639285).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 15s) Loss: 0.6366 Grad: 0.6017 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6424 Grad: 1.2142 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6418 Grad: 1.2570 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6565 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6398 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6418  avg_val_loss: 0.6398  time: 90s\n",
      "Epoch 6 - Score: 17.36649478688069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 44s) Loss: 0.6504 Grad: 0.8304 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6422 Grad: 0.6778 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6419 Grad: 0.9323 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 31s) Loss: 0.6566 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6419  avg_val_loss: 0.6399  time: 91s\n",
      "Epoch 7 - Score: 17.36043667361239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6399 \n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 4m 44s) Loss: 0.6254 Grad: 1.2009 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6407 Grad: 0.7448 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6397 Grad: 0.6550 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6558 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6397  avg_val_loss: 0.6396  time: 91s\n",
      "Epoch 8 - Score: 17.328854086592624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 4m 44s) Loss: 0.6229 Grad: 0.5892 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6284 Grad: 1.1015 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6280 Grad: 0.4343 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6559 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6392 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6280  avg_val_loss: 0.6392  time: 91s\n",
      "Epoch 9 - Score: 17.2879036561979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639285 --> 0.639151).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 6s) Loss: 0.5864 Grad: 0.5513 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6258 Grad: 0.7130 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6264 Grad: 0.9255 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6568 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6392 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6264  avg_val_loss: 0.6392  time: 91s\n",
      "Epoch 10 - Score: 17.291937909078477\n",
      "========== fold: 5 result ==========\n",
      "Score: 17.28790\n",
      "========== fold: 6 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 36s) Loss: 0.7030 Grad: 0.7748 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6536 Grad: 0.4011 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6507 Grad: 0.9236 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6623 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6438 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6507  avg_val_loss: 0.6438  time: 91s\n",
      "Epoch 1 - Score: 17.90254480740568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.643784).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 4m 40s) Loss: 0.6378 Grad: 0.3861 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6378 Grad: 1.1860 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6375 Grad: 0.5506 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6624 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6409 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6375  avg_val_loss: 0.6409  time: 91s\n",
      "Epoch 2 - Score: 17.52003543602043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.643784 --> 0.640916).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 4s) Loss: 0.6324 Grad: 0.9593 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6467 Grad: 0.7094 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6461 Grad: 0.4733 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6641 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6418 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6461  avg_val_loss: 0.6418  time: 90s\n",
      "Epoch 3 - Score: 17.634503502997237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 24s) Loss: 0.6328 Grad: 0.6848 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6450 Grad: 0.6857 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6448 Grad: 0.7077 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6638 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6416 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6448  avg_val_loss: 0.6416  time: 91s\n",
      "Epoch 4 - Score: 17.60654196204276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 4m 56s) Loss: 0.6184 Grad: 0.9844 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6433 Grad: 0.8986 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6422 Grad: 0.6353 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6641 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6422  avg_val_loss: 0.6407  time: 89s\n",
      "Epoch 5 - Score: 17.495425944795244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6407 \n",
      "Validation loss decreased (0.640916 --> 0.640727).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 4m 43s) Loss: 0.6497 Grad: 0.7251 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6429 Grad: 0.6813 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6419 Grad: 0.4687 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6640 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6414 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6419  avg_val_loss: 0.6414  time: 91s\n",
      "Epoch 6 - Score: 17.57137798673652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 3s) Loss: 0.6267 Grad: 0.9661 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6422 Grad: 1.2121 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6411 Grad: 0.5977 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6640 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6410 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6411  avg_val_loss: 0.6410  time: 90s\n",
      "Epoch 7 - Score: 17.517133086382817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 1s) Loss: 0.6271 Grad: 0.6101 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6392 Grad: 0.9987 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6401 Grad: 0.5743 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6642 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6401  avg_val_loss: 0.6416  time: 90s\n",
      "Epoch 8 - Score: 17.590553026143375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6416 \n",
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 17s) Loss: 0.6397 Grad: 0.8840 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6257 Grad: 0.4808 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6260 Grad: 0.3457 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6634 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6260  avg_val_loss: 0.6405  time: 91s\n",
      "Epoch 9 - Score: 17.45523746059931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.640727 --> 0.640528).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 4m 51s) Loss: 0.6258 Grad: 0.5380 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6243 Grad: 0.6196 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6244 Grad: 0.5077 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 25s) Loss: 0.6647 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6415 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6244  avg_val_loss: 0.6415  time: 91s\n",
      "Epoch 10 - Score: 17.57191718223084\n",
      "========== fold: 6 result ==========\n",
      "Score: 17.45524\n",
      "========== fold: 7 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 4m 44s) Loss: 0.6874 Grad: 0.7712 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6520 Grad: 0.4084 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6502 Grad: 0.4390 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6349 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6457 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6502  avg_val_loss: 0.6457  time: 91s\n",
      "Epoch 1 - Score: 18.379245760124967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.645716).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 1s (remain 4m 32s) Loss: 0.6270 Grad: 0.4339 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6371 Grad: 0.4884 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6376 Grad: 1.0168 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6289 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6376  avg_val_loss: 0.6428  time: 91s\n",
      "Epoch 2 - Score: 18.010926274336978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645716 --> 0.642834).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 4m 55s) Loss: 0.6694 Grad: 0.6304 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6487 Grad: 0.9922 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6470 Grad: 0.6757 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6298 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6470  avg_val_loss: 0.6452  time: 91s\n",
      "Epoch 3 - Score: 18.28163332878887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6452 \n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 5m 8s) Loss: 0.6329 Grad: 0.6779 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6456 Grad: 0.4227 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6446 Grad: 0.4751 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6278 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6438 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6446  avg_val_loss: 0.6438  time: 90s\n",
      "Epoch 4 - Score: 18.123752842707308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 1s) Loss: 0.6478 Grad: 0.5838 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6415 Grad: 0.6673 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6426 Grad: 0.4145 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6298 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6426  avg_val_loss: 0.6437  time: 91s\n",
      "Epoch 5 - Score: 18.107388642303246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6430 Grad: 0.5744 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6434 Grad: 0.4508 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6424 Grad: 0.5396 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6305 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6439 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6424  avg_val_loss: 0.6439  time: 90s\n",
      "Epoch 6 - Score: 18.131932137283357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 44s) Loss: 0.6466 Grad: 0.8384 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6411 Grad: 0.5861 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6410 Grad: 0.6220 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6298 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6441 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6410  avg_val_loss: 0.6441  time: 90s\n",
      "Epoch 7 - Score: 18.154288346219253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 11s) Loss: 0.6410 Grad: 0.7911 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6398 Grad: 0.5431 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6400 Grad: 1.3398 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6300 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6435 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6400  avg_val_loss: 0.6435  time: 91s\n",
      "Epoch 8 - Score: 18.09150747703106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 12s) Loss: 0.6388 Grad: 0.4120 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6258 Grad: 0.4145 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6272 Grad: 0.6677 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6310 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6436 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6272  avg_val_loss: 0.6436  time: 92s\n",
      "Epoch 9 - Score: 18.096518828206833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 1s) Loss: 0.6339 Grad: 0.6152 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6262 Grad: 0.8964 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6256 Grad: 0.5439 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6310 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6256  avg_val_loss: 0.6435  time: 91s\n",
      "Epoch 10 - Score: 18.079234672402272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6435 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 7 result ==========\n",
      "Score: 18.01093\n",
      "========== fold: 8 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6871 Grad: 0.9432 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6531 Grad: 0.5884 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6506 Grad: 0.4409 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6313 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6413 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6506  avg_val_loss: 0.6413  time: 90s\n",
      "Epoch 1 - Score: 17.760507424761425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.641287).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 16s) Loss: 0.6431 Grad: 0.4141 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6378 Grad: 0.4728 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6378 Grad: 0.3664 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6297 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6387 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6378  avg_val_loss: 0.6387  time: 91s\n",
      "Epoch 2 - Score: 17.40789183170688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641287 --> 0.638695).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 5m 14s) Loss: 0.6675 Grad: 0.4771 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6469 Grad: 0.6592 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6469 Grad: 0.5226 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6343 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6406 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6469  avg_val_loss: 0.6406  time: 92s\n",
      "Epoch 3 - Score: 17.663485100122145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 52s) Loss: 0.6499 Grad: 0.5184 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6434 Grad: 0.5624 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6440 Grad: 0.7275 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6307 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6440  avg_val_loss: 0.6393  time: 91s\n",
      "Epoch 4 - Score: 17.487956390073787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 8s) Loss: 0.6385 Grad: 0.6331 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6435 Grad: 0.7074 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6433 Grad: 0.8104 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 26s) Loss: 0.6289 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6433  avg_val_loss: 0.6396  time: 92s\n",
      "Epoch 5 - Score: 17.537976841445513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 0s) Loss: 0.6108 Grad: 0.5095 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6420 Grad: 0.6973 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6407 Grad: 0.5127 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6260 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6407  avg_val_loss: 0.6396  time: 91s\n",
      "Epoch 6 - Score: 17.509360727613164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 5m 8s) Loss: 0.6330 Grad: 0.5788 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6392 Grad: 0.4396 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6405 Grad: 0.6736 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6283 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6405  avg_val_loss: 0.6386  time: 92s\n",
      "Epoch 7 - Score: 17.391170075788224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.638695 --> 0.638596).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 15s) Loss: 0.6398 Grad: 0.6115 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6413 Grad: 0.4691 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6401 Grad: 2.1321 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6264 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6401  avg_val_loss: 0.6384  time: 92s\n",
      "Epoch 8 - Score: 17.36476380446835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.638596 --> 0.638369).  Saving model ...\n",
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 4s) Loss: 0.6425 Grad: 0.6012 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6258 Grad: 0.4489 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6266 Grad: 0.5763 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 28s) Loss: 0.6249 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6374 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6266  avg_val_loss: 0.6374  time: 92s\n",
      "Epoch 9 - Score: 17.2376415268026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.638369 --> 0.637423).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 4m 47s) Loss: 0.6034 Grad: 0.5069 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6250 Grad: 0.8086 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 20s (remain 0m 0s) Loss: 0.6251 Grad: 0.5910 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6256 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6372 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6251  avg_val_loss: 0.6372  time: 88s\n",
      "Epoch 10 - Score: 17.2012142346227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.637423 --> 0.637219).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 8 result ==========\n",
      "Score: 17.20121\n",
      "========== fold: 9 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 2s (remain 5m 14s) Loss: 0.7271 Grad: 1.4955 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6541 Grad: 0.4379 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6512 Grad: 0.5786 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6458 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6419 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6512  avg_val_loss: 0.6419  time: 91s\n",
      "Epoch 1 - Score: 17.90923279854033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.641873).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 2s (remain 5m 17s) Loss: 0.6229 Grad: 0.4453 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6368 Grad: 0.7153 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6374 Grad: 0.4654 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6455 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6403 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6374  avg_val_loss: 0.6403  time: 91s\n",
      "Epoch 2 - Score: 17.68934380967203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.641873 --> 0.640331).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 2s (remain 4m 59s) Loss: 0.6541 Grad: 1.9261 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 0m 59s (remain 0m 22s) Loss: 0.6464 Grad: 0.8491 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6470 Grad: 0.6619 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 30s) Loss: 0.6424 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6470  avg_val_loss: 0.6399  time: 90s\n",
      "Epoch 3 - Score: 17.63195290869037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.640331 --> 0.639889).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 2s (remain 4m 48s) Loss: 0.6219 Grad: 0.7289 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6445 Grad: 0.4960 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6449 Grad: 0.4757 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6427 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6449  avg_val_loss: 0.6399  time: 91s\n",
      "Epoch 4 - Score: 17.613181134345382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 2s (remain 5m 6s) Loss: 0.6182 Grad: 0.5074 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6432 Grad: 0.5458 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 1m 22s (remain 0m 0s) Loss: 0.6431 Grad: 0.7431 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 27s) Loss: 0.6409 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6402 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6431  avg_val_loss: 0.6402  time: 91s\n",
      "Epoch 5 - Score: 17.647763610854252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 2s (remain 5m 8s) Loss: 0.6241 Grad: 0.5489 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 1s (remain 0m 22s) Loss: 0.6415 Grad: 0.5534 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6418 Grad: 0.7236 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6397 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6418  avg_val_loss: 0.6393  time: 91s\n",
      "Epoch 6 - Score: 17.54224426897136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.639889 --> 0.639277).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 2s (remain 4m 50s) Loss: 0.6185 Grad: 0.5026 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 0s (remain 0m 22s) Loss: 0.6406 Grad: 0.5530 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 1m 21s (remain 0m 0s) Loss: 0.6412 Grad: 0.5567 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6392 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6395 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6412  avg_val_loss: 0.6395  time: 90s\n",
      "Epoch 7 - Score: 17.57257253375742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 2s (remain 5m 1s) Loss: 0.6439 Grad: 0.5676 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6413 Grad: 0.6827 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6406 Grad: 0.7093 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6402 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6406  avg_val_loss: 0.6399  time: 92s\n",
      "Epoch 8 - Score: 17.608355074339546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 2s (remain 5m 51s) Loss: 0.6197 Grad: 0.4353 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6271 Grad: 0.4665 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6271 Grad: 0.6433 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 1s (remain 0m 29s) Loss: 0.6389 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6271  avg_val_loss: 0.6396  time: 92s\n",
      "Epoch 9 - Score: 17.582837887104027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 2s (remain 5m 8s) Loss: 0.6079 Grad: 0.5830 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 1s (remain 0m 23s) Loss: 0.6261 Grad: 0.4796 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 1m 23s (remain 0m 0s) Loss: 0.6254 Grad: 0.6861 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 32s) Loss: 0.6399 \n",
      "EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6398 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6254  avg_val_loss: 0.6398  time: 92s\n",
      "Epoch 10 - Score: 17.599352638342676\n",
      "========== fold: 9 result ==========\n",
      "Score: 17.54224\n",
      "========== CV ==========\n",
      "Score: 17.58277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 13.3s\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "8ijJJUa2d2Lx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1094498... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 7463.08MB of 7463.08MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>‚ñÅ</td></tr><tr><td>Score_fold0</td><td>‚ñÅ</td></tr><tr><td>Score_fold1</td><td>‚ñÅ</td></tr><tr><td>Score_fold2</td><td>‚ñÅ</td></tr><tr><td>Score_fold3</td><td>‚ñÅ</td></tr><tr><td>Score_fold4</td><td>‚ñÅ</td></tr><tr><td>Score_fold5</td><td>‚ñÅ</td></tr><tr><td>Score_fold6</td><td>‚ñÅ</td></tr><tr><td>Score_fold7</td><td>‚ñÅ</td></tr><tr><td>Score_fold8</td><td>‚ñÅ</td></tr><tr><td>Score_fold9</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñà</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr><tr><td>loss/train_fold0</td><td>‚ñà‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold1</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold2</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold3</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold4</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold5</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold6</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold7</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold8</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold9</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold0</td><td>‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>loss/valid_fold1</td><td>‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ</td></tr><tr><td>loss/valid_fold2</td><td>‚ñÖ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ</td></tr><tr><td>loss/valid_fold3</td><td>‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold4</td><td>‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ</td></tr><tr><td>loss/valid_fold5</td><td>‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold6</td><td>‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ</td></tr><tr><td>loss/valid_fold7</td><td>‚ñà‚ñÅ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ</td></tr><tr><td>loss/valid_fold8</td><td>‚ñà‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold9</td><td>‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold0</td><td>‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñá</td></tr><tr><td>score/fold1</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ</td></tr><tr><td>score/fold2</td><td>‚ñÖ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ</td></tr><tr><td>score/fold3</td><td>‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold4</td><td>‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold5</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold6</td><td>‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ</td></tr><tr><td>score/fold7</td><td>‚ñà‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ</td></tr><tr><td>score/fold8</td><td>‚ñà‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold9</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>17.58277</td></tr><tr><td>Score_fold0</td><td>17.61096</td></tr><tr><td>Score_fold1</td><td>17.52927</td></tr><tr><td>Score_fold2</td><td>18.07281</td></tr><tr><td>Score_fold3</td><td>16.93041</td></tr><tr><td>Score_fold4</td><td>18.14636</td></tr><tr><td>Score_fold5</td><td>17.2879</td></tr><tr><td>Score_fold6</td><td>17.45524</td></tr><tr><td>Score_fold7</td><td>18.01093</td></tr><tr><td>Score_fold8</td><td>17.20121</td></tr><tr><td>Score_fold9</td><td>17.54224</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.64018</td></tr><tr><td>loss/train_fold0</td><td>0.62407</td></tr><tr><td>loss/train_fold1</td><td>0.62554</td></tr><tr><td>loss/train_fold2</td><td>0.62507</td></tr><tr><td>loss/train_fold3</td><td>0.62559</td></tr><tr><td>loss/train_fold4</td><td>0.62568</td></tr><tr><td>loss/train_fold5</td><td>0.62637</td></tr><tr><td>loss/train_fold6</td><td>0.62441</td></tr><tr><td>loss/train_fold7</td><td>0.62555</td></tr><tr><td>loss/train_fold8</td><td>0.62511</td></tr><tr><td>loss/train_fold9</td><td>0.62536</td></tr><tr><td>loss/valid_fold0</td><td>0.64405</td></tr><tr><td>loss/valid_fold1</td><td>0.63983</td></tr><tr><td>loss/valid_fold2</td><td>0.6442</td></tr><tr><td>loss/valid_fold3</td><td>0.63564</td></tr><tr><td>loss/valid_fold4</td><td>0.64403</td></tr><tr><td>loss/valid_fold5</td><td>0.6392</td></tr><tr><td>loss/valid_fold6</td><td>0.64155</td></tr><tr><td>loss/valid_fold7</td><td>0.64349</td></tr><tr><td>loss/valid_fold8</td><td>0.63722</td></tr><tr><td>loss/valid_fold9</td><td>0.63977</td></tr><tr><td>score/fold0</td><td>17.86283</td></tr><tr><td>score/fold1</td><td>17.59937</td></tr><tr><td>score/fold2</td><td>18.26599</td></tr><tr><td>score/fold3</td><td>16.93041</td></tr><tr><td>score/fold4</td><td>18.20434</td></tr><tr><td>score/fold5</td><td>17.29194</td></tr><tr><td>score/fold6</td><td>17.57192</td></tr><tr><td>score/fold7</td><td>18.07923</td></tr><tr><td>score/fold8</td><td>17.20121</td></tr><tr><td>score/fold9</td><td>17.59935</td></tr></table>\n",
       "</div></div>\n",
       "Synced 7 W&B file(s), 1 media file(s), 11 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vivid-microwave-84</strong>: <a href=\"https://wandb.ai/imokuri/petfinder2/runs/23uqyg9f\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2/runs/23uqyg9f</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211013_101802-23uqyg9f/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "petfinder2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38-all-in-one-dev",
   "language": "python",
   "name": "py38-all-in-one-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
