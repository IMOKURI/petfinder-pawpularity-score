{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YDQH4n9zdG"
   },
   "source": [
    "# üìî About this notebook\n",
    "\n",
    "PetFinder.my - Pawpularity Contest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0pnACt-CQd"
   },
   "source": [
    "## üìù Memo\n",
    "\n",
    "- transformer „ÅÆ output „Å® feature „Çí SVR „ÅßÂ≠¶Áøí„Åô„Çã„ÄÇ\n",
    "    - NN „ÅÆ head „Å® SVR „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„Åô„Çã„ÄÇ [Link](https://www.kaggle.com/cdeotte/rapids-svr-boost-17-8/notebook)\n",
    "- swin base, large „Å® CSWin „Å® B7 „Åß„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eezrDVYa_yav"
   },
   "source": [
    "# üìö Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1633394791716,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "32GYVF3l_wUO"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import collections\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1633394792859,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "DhlpmaPbNqOs"
   },
   "outputs": [],
   "source": [
    "# Competition specific libraries\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional local libraries\n",
    "\n",
    "# https://github.com/microsoft/CSWin-Transformer\n",
    "sys.path.append(\"../input/CSWin-Transformer\")\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633394792860,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qPMtyPp8AWvZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ZHMIcuPvAdZI",
    "outputId": "8b28afb5-3466-40d4-9d0f-7a7a43f786b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "# netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
    "# !cp -f {netrc} ~/\n",
    "!wandb login\n",
    "wandb_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795177,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "KPb3f6kLAYrP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uOtCk2BKGF"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m4LaDlPJBLil"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/petfinder-pawpularity-score/\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "\n",
    "!rm -rf {MODEL_DIR}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795178,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "xKKkrScBBf44"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "TRAIN_IMAGE_PATH = DATA_DIR + \"train/\"\n",
    "TEST_IMAGE_PATH = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQk8_n-5Bwun"
   },
   "source": [
    "# üõ† Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "HfK7G4EQBxpt",
    "outputId": "266be0c6-6b79-4de4-8de1-8502eb577dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randrange(10000)\n",
    "seed = 440\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795179,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "STqXGbUhBz5f"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    wandb_entity = \"imokuri\"\n",
    "    wandb_project = \"petfinder2\"\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    train2 = False  # SVR\n",
    "    validate = False\n",
    "    inference = False\n",
    "\n",
    "    debug = False\n",
    "    num_debug_data = 1000\n",
    "\n",
    "    amp = True\n",
    "    multi_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAK99CZOhfMV"
   },
   "source": [
    "Model examples\n",
    "\n",
    "- resnext50_32x4d\n",
    "- vit_base_patch16_384\n",
    "- tf_efficientnet_b7_ns\n",
    "- tf_efficientnetv2_l_in21k\n",
    "- swin_base_patch4_window12_384_in22k\n",
    "- swin_large_patch4_window12_384_in22k\n",
    "- CSWin_144_24322_large_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "Vjl7MQHiFyFS"
   },
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": seed,\n",
    "    \"n_class\": 1,\n",
    "    \"n_fold\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"es_patience\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    \"momentum\": 0.9,\n",
    "    \"model_name\": \"tf_efficientnetv2_l_in21k\",\n",
    "    \"size\": 384,\n",
    "    \"models\": [\n",
    "        \"swin_large_patch4_window12_384_in22k:v14\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795180,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "dgConxiYIqTM"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config_defaults[\"n_fold\"] = 3\n",
    "    config_defaults[\"epochs\"] = 1\n",
    "    Config.print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BteR9_gVItes"
   },
   "outputs": [],
   "source": [
    "if Config.train:\n",
    "    wandb_job_type = \"training\"\n",
    "\n",
    "elif Config.train2:\n",
    "    wandb_job_type = \"training2\"\n",
    "\n",
    "elif Config.inference:\n",
    "    wandb_job_type = \"inference\"\n",
    "\n",
    "elif Config.validate:\n",
    "    wandb_job_type = \"validation\"\n",
    "\n",
    "else:\n",
    "    wandb_job_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "wBSFI0-_XL_-"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    wandb_tags.append(\"debug\")\n",
    "\n",
    "# if Config.amp:\n",
    "#     wandb_tags.append(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394795181,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "LIDKN-b7jDOt"
   },
   "outputs": [],
   "source": [
    "# wandb_tags.append(\"feats\")\n",
    "wandb_tags.append(\"bins kfold\")\n",
    "wandb_tags.append(\"basic aug\")\n",
    "# wandb_tags.append(\"heavy aug\")\n",
    "# wandb_tags.append(\"mixup\")\n",
    "# wandb_tags.append(\"cutmix\")\n",
    "# wandb_tags.append(\"freeze norm\")\n",
    "# wandb_tags.append(\"crop image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1633394796778,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JaQsAlSfJbnt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/imokuri/petfinder2/runs/11d0mnwv\" target=\"_blank\">dry-lion-56</a></strong> to <a href=\"https://wandb.ai/imokuri/petfinder2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.debug:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        tags=wandb_tags,\n",
    "        mode=\"disabled\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        entity=Config.wandb_entity,\n",
    "        project=Config.wandb_project,\n",
    "        config=config_defaults,\n",
    "        job_type=wandb_job_type,\n",
    "        tags=wandb_tags,\n",
    "        save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633394796783,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0kD8_kP0JjAC"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYjWTUW9Jtem"
   },
   "source": [
    "# EDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1633394796784,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "-dEUJ_P9Jwzw",
    "outputId": "f98c8f40-5d7e-43f5-f524-58129cd3c758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9912 entries, 0 to 9911\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             9912 non-null   object\n",
      " 1   Subject Focus  9912 non-null   int64 \n",
      " 2   Eyes           9912 non-null   int64 \n",
      " 3   Face           9912 non-null   int64 \n",
      " 4   Near           9912 non-null   int64 \n",
      " 5   Action         9912 non-null   int64 \n",
      " 6   Accessory      9912 non-null   int64 \n",
      " 7   Group          9912 non-null   int64 \n",
      " 8   Collage        9912 non-null   int64 \n",
      " 9   Human          9912 non-null   int64 \n",
      " 10  Occlusion      9912 non-null   int64 \n",
      " 11  Info           9912 non-null   int64 \n",
      " 12  Blur           9912 non-null   int64 \n",
      " 13  Pawpularity    9912 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             8 non-null      object\n",
      " 1   Subject Focus  8 non-null      int64 \n",
      " 2   Eyes           8 non-null      int64 \n",
      " 3   Face           8 non-null      int64 \n",
      " 4   Near           8 non-null      int64 \n",
      " 5   Action         8 non-null      int64 \n",
      " 6   Accessory      8 non-null      int64 \n",
      " 7   Group          8 non-null      int64 \n",
      " 8   Collage        8 non-null      int64 \n",
      " 9   Human          8 non-null      int64 \n",
      " 10  Occlusion      8 non-null      int64 \n",
      " 11  Info           8 non-null      int64 \n",
      " 12  Blur           8 non-null      int64 \n",
      "dtypes: int64(12), object(1)\n",
      "memory usage: 960.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  \n",
       "3          0      0        0      0          0     1     0  \n",
       "4          1      0        1      0          1     1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8 non-null      object \n",
      " 1   Pawpularity  8 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>59.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>20.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>89.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3        67.75\n",
       "1  43a2262d7738e3d420d453815151079e        59.15\n",
       "2  4e429cead1848a298432a0acad014c9d        20.02\n",
       "3  80bc3ccafcc51b66303c2c263aa38486        94.53\n",
       "4  8f49844c382931444e68dffbe20228f4        89.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [train, test, sub]:\n",
    "    print(f\"=\" * 120)\n",
    "    df.info()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1633394797327,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "uK-vChyCKVhZ",
    "outputId": "3d5cf17f-3df5-4163-a7ba-be4bd83f6211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pawpularity'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[\"Pawpularity\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nN20A-4KeX2"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDt-OBGKg33"
   },
   "source": [
    "# EDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "m2XP3TB7KhvW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFYIILAsKih4"
   },
   "source": [
    "# üëë Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.train2:\n",
    "    api = wandb.Api()\n",
    "    for artifact_id in config.models:\n",
    "        name_version = artifact_id.replace(\":\", \"-\")\n",
    "        if not os.path.exists(name_version):\n",
    "            os.makedirs(name_version)\n",
    "\n",
    "        try:\n",
    "            artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{artifact_id}\"\n",
    "            artifact = api.artifact(artifact_path)\n",
    "            artifact.download(name_version)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {artifact_path}, {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "ahzUGk4sK6te"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "    if len(sub) > Config.num_debug_data:\n",
    "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
    "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF4pvz7-L7qT"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797329,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "qrlmhizKMCku"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClI1iqtWLqU0"
   },
   "source": [
    "# Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BQVW6__Rjk_N"
   },
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(1 + np.log2(len(train))))\n",
    "train.loc[:, \"bins\"] = pd.cut(train[\"Pawpularity\"], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633394797330,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "raBuQ3EjLsmo",
    "outputId": "11fbcaa3-b48c-4143-c742-b0de3e717a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  bins\n",
      "0     0        33\n",
      "      1        42\n",
      "      2       111\n",
      "      3       203\n",
      "      4       188\n",
      "             ... \n",
      "9     9        28\n",
      "      10       20\n",
      "      11       14\n",
      "      12       11\n",
      "      13       36\n",
      "Length: 140, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
    "print(train.groupby([\"fold\", \"bins\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKN3QPeMMFf"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"crop image\" in wandb_tags:\n",
    "    TRAIN_IMAGE_PATH = DATA_DIR + \"crop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "pX4piTk2MPVR"
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, label=True):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"Id\"].values\n",
    "        self.features = df.drop([\"Id\", \"Pawpularity\", \"fold\", \"bins\"], axis=1).values\n",
    "        self.transform = transform\n",
    "\n",
    "        self.use_label = label\n",
    "        if self.use_label:\n",
    "            self.path = TRAIN_IMAGE_PATH\n",
    "            self.labels = df[\"Pawpularity\"].values / 100.0\n",
    "        else:\n",
    "            self.path = TEST_IMAGE_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{self.path}/{file_name}.jpg\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        feature = torch.tensor(self.features[idx])\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        if self.use_label:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, feature, label\n",
    "        return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1633394798564,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "0CIysnf0OhGK",
    "outputId": "dca880e9-0d92-43e7-82e2-a11ecacb54c1"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train)\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633394797328,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "yJhnZyCOKf_8"
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    if data == \"train\":\n",
    "        if \"basic aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if \"heavy aug\" in wandb_tags:\n",
    "            return A.Compose(\n",
    "                [\n",
    "                    # A.Resize(config.size, config.size),\n",
    "                    A.RandomResizedCrop(config.size, config.size),\n",
    "                    A.Transpose(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.ShiftScaleRotate(p=0.5),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                    # A.CoarseDropout(p=0.5),\n",
    "                    # A.Cutout(p=0.5),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config.size, config.size),\n",
    "            # A.CenterCrop(config.size, config.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798565,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "JwLeTm_EP9kK",
    "outputId": "9193e65d-197d-4e17-91d7-ee026dc0d38a"
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    image, feature, label = train_ds[0]\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(f\"label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = cutmix(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633394797331,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "BqcwfvhMterO"
   },
   "outputs": [],
   "source": [
    "# https://github.com/yuhao318/mwh/blob/main/utils.py\n",
    "def mixup(x, feats, y, alpha=1.0, use_cuda=True):\n",
    "\n",
    "    \"\"\"Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam = max(lam, 1 - lam)\n",
    "        # lam = min(lam, 1-lam)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    ## NO SYM\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_feats = lam * feats + (1 - lam) * feats[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # return mixed_image, mixed_label, lam\n",
    "    return mixed_x, mixed_feats, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "CiCqVeWhh2gr",
    "outputId": "81496b08-c725-48b9-ad02-573eb0346269"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"valid\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        image, feature, label_a, label_b, lam = mixup(image, feature, label, alpha=0.5, use_cuda=False)\n",
    "\n",
    "        plt.imshow(image[0].permute(1, 2, 0))\n",
    "        plt.title(f\"label: {label_a[0]} and {label_b[0]}\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"feature: {feature[0]}, lam: {lam}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbrC2J4KPEp4"
   },
   "source": [
    "# üöó Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633394798566,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "827lYLgIPFyY"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        x = self.head1(x)\n",
    "        x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model):\n",
    "    model.train()\n",
    "\n",
    "    # Freeze layer normalization\n",
    "    if any(key in config.model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "        for m in model.modules():\n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.LayerNorm):\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83590,
     "status": "ok",
     "timestamp": 1633394882149,
     "user": {
      "displayName": "Yoshio S",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02953556559298393836"
     },
     "user_tz": -540
    },
    "id": "oudAIpPqQt6z",
    "outputId": "32564315-dd7d-4bc9-f24b-620488993b3a"
   },
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BaseModel(config.model_name)\n",
    "    model.apply(train_mode)\n",
    "\n",
    "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
    "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if \"resnext50_32x4d\" in model_name:\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 128)\n",
    "\n",
    "        elif any(key in model_name for key in [\"vit\", \"swin\", \"CSWin\"]):\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head1 = nn.Linear(140, 64)\n",
    "        self.head2 = nn.Linear(64, config.n_class)\n",
    "\n",
    "    @amp.autocast(enabled=Config.amp)\n",
    "    def forward(self, x, feats):\n",
    "        x = self.model(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = torch.cat([x, feats], dim=1)\n",
    "        # x = self.head1(x)\n",
    "        # x = self.head2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug and config.model_name != \"\":\n",
    "    model = BackboneModel(config.model_name)\n",
    "    print(model)\n",
    "\n",
    "    train_ds = BaseDataset(train, transform=get_transforms(data=\"train\"))\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    for image, feature, label in train_loader:\n",
    "        output = model(image, feature)\n",
    "        print(output)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa8k53cRIi_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FbkDI8DdRJ5w"
   },
   "outputs": [],
   "source": [
    "# https://github.com/davda54/sam/blob/main/sam.py\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFMHkJIMRLBi"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "f6jKOTHURLxM"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbNT_NeRMoB"
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "S4EF_M0NROIn"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0fQUwt7adOSk"
   },
   "outputs": [],
   "source": [
    "def get_result(result_df, fold=config.n_fold):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"Pawpularity\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    if fold == config.n_fold:\n",
    "        wandb.log({\"Score\": score})\n",
    "    else:\n",
    "        wandb.log({f\"Score_fold{fold}\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Ga4Bb8RQsF"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "rRPW8QwiRbPC"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "23roIn-jhfMe"
   },
   "outputs": [],
   "source": [
    "# https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_preds = None\n",
    "\n",
    "    def __call__(self, val_loss, score, model, preds):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss >= self.val_loss_min + self.delta:\n",
    "            if self.patience <= 0:\n",
    "                return\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_preds = preds\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "l9Kcw2bdeZR4"
   },
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2.0):\n",
    "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = [p for p in parameters if p.grad is not None]\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "sWtO4py7Rcud"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    if \"freeze norm\" in wandb_tags:\n",
    "        model.apply(train_mode)\n",
    "    else:\n",
    "        model.train()\n",
    "    start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            mix_decision = 1.0\n",
    "        else:\n",
    "            mix_decision = np.random.rand()\n",
    "\n",
    "        if epoch >= config.epochs - 5:\n",
    "            mix_decision *= 2\n",
    "\n",
    "        if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "            images, features, label_a, label_b, lam = mixup(images, features, labels, alpha=0.5)\n",
    "\n",
    "        with amp.autocast(enabled=Config.amp):\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "            if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "            else:\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "\n",
    "                def closure():\n",
    "                    # y_preds = model(images, features)\n",
    "                    y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "                    if \"mixup\" in wandb_tags and mix_decision < 0.5:\n",
    "                        loss = criterion(y_preds, label_a) * lam + criterion(y_preds, label_b) * (1.0 - lam)\n",
    "                    else:\n",
    "                        loss = criterion(y_preds, labels)\n",
    "\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            if \"SAM\" in config.optimizer:\n",
    "                scaler.step(optimizer, closure)\n",
    "            else:\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            grad_norm = compute_grad_norm(model.parameters())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_lr()[0]:.2e}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wlPZYJYgXRZ4"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # y_preds = model(images, features)\n",
    "            y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.avg:.4f} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training2 (Inference by backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_inference_fn(data_loader, model, device):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (images, features, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images, features)\n",
    "            # y_preds = model(images, features).squeeze(1)\n",
    "\n",
    "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % Config.print_freq == 0 or step == (len(data_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(data_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(data_loader)):s} \"\n",
    "            )\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ybZNlV6YEp8"
   },
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JIDycP9YFvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mwWqWJdX232"
   },
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ei3alnONX4RY"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"train\"))\n",
    "    train_dataset_ = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    train_loader_ = DataLoader(\n",
    "        train_dataset_,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Optimizer\n",
    "    # ====================================================\n",
    "    def get_optimizer(model):\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer == \"SAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "            )\n",
    "        elif config.optimizer == \"ASAM\":\n",
    "            base_optimizer = SGD\n",
    "            optimizer = SAM(\n",
    "                model.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=config.lr,\n",
    "                momentum=config.momentum,\n",
    "                weight_decay=config.weight_decay,\n",
    "                rho=2.0,\n",
    "                adaptive=True,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer, train_dataset):\n",
    "        num_data = len(train_dataset)\n",
    "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
    "\n",
    "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
    "            scheduler = CosineAnnealingWarmupRestarts(\n",
    "                optimizer,\n",
    "                first_cycle_steps=num_steps,\n",
    "                max_lr=config.lr,\n",
    "                min_lr=config.min_lr,\n",
    "                warmup_steps=(num_steps // 10),\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(config.model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = amp.GradScaler(enabled=Config.amp)\n",
    "    scheduler = get_scheduler(optimizer, train_dataset)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif config.criterion == \"MSELoss\":\n",
    "            criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # Early stopping\n",
    "    # ====================================================\n",
    "    es = EarlyStopping(\n",
    "        patience=config.es_patience,\n",
    "        verbose=True,\n",
    "        path=MODEL_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        if epoch < 2 or epoch >= config.epochs - 2:\n",
    "            avg_loss = train_fn(train_loader_, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "        else:\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, epoch, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "        if config.criterion == \"BCEWithLogitsLoss\":\n",
    "            preds = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "        preds *= 100.0\n",
    "\n",
    "        # scoring\n",
    "        # score = get_score(valid_labels, preds.argmax(1))\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                f\"loss/train_fold{fold}\": avg_loss,\n",
    "                f\"loss/valid_fold{fold}\": avg_val_loss,\n",
    "                f\"score/fold{fold}\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        es(avg_val_loss, score, model, preds)\n",
    "\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    valid_folds[\"preds\"] = es.best_preds\n",
    "\n",
    "    return valid_folds, es.best_score, es.val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏èüèÉ‚Äç‚ôÇÔ∏è Train2 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_loop(df, artifact_id, fold):\n",
    "    LOGGER.info(f\"========== ID: {artifact_id} fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    trn_idx = df[df[\"fold\"] != fold].index\n",
    "    val_idx = df[df[\"fold\"] == fold].index\n",
    "\n",
    "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BaseDataset(train_folds, transform=get_transforms(data=\"valid\"))\n",
    "    valid_dataset = BaseDataset(valid_folds, transform=get_transforms(data=\"valid\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    valid_labels = valid_folds[\"Pawpularity\"].values\n",
    "\n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model_name = artifact_id.split(\":\")[0]\n",
    "    model = BackboneModel(model_name)\n",
    "    if Config.multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    path = f\"{artifact_id.replace(':', '-')}/{model_name}_fold{fold}_best.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    # ====================================================\n",
    "    # Inference by backbone\n",
    "    # ====================================================\n",
    "\n",
    "    train_preds = train2_inference_fn(train_loader, model, device)\n",
    "    valid_preds = train2_inference_fn(valid_loader, model, device)\n",
    "\n",
    "    if config.criterion == \"BCEWithLogitsLoss\":\n",
    "        train_preds = 1 / (1 + np.exp(-train_preds))\n",
    "        valid_preds = 1 / (1 + np.exp(-valid_preds))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler.fit(np.vstack([train_preds, valid_preds]))\n",
    "\n",
    "    train_norm = scaler.fit_transform(train_preds)\n",
    "    valid_norm = scaler.transform(valid_preds)\n",
    "\n",
    "    scaler_path = MODEL_DIR + f\"{model_name}-StandardScaler_fold{fold}_best.pkl\"\n",
    "    pickle.dump(scaler, open(scaler_path, \"wb\"))\n",
    "\n",
    "    # ====================================================\n",
    "    # Tuning SVR parameters\n",
    "    # ====================================================\n",
    "    # https://github.com/hkaneko1985/fastoptsvrhyperparams/blob/master/fastoptsvrhyperparams.ipynb\n",
    "    start_time = time.time()\n",
    "\n",
    "    svr_epss = 2 ** np.arange(-10, 1, dtype=float)  # Candidates of epsilon\n",
    "    svr_cs = 2 ** np.arange(-5, 11, dtype=float)  # Candidates of C\n",
    "    svr_gammas = 2**np.arange( -20, 11, dtype=float)     # Candidates of gamma\n",
    "\n",
    "    # Optimize epsilon with cross-validation\n",
    "    model_tune_eps = GridSearchCV(SVR(kernel='rbf', C=3), {'epsilon':svr_epss})\n",
    "    model_tune_eps.fit(train_norm, train_dataset.labels)\n",
    "    optimal_eps = model_tune_eps.best_params_['epsilon']\n",
    "    \n",
    "    # Optimize C with cross-validation\n",
    "    model_tune_c = GridSearchCV(SVR(kernel='rbf', epsilon=optimal_eps), {'C':svr_cs})\n",
    "    model_tune_c.fit(train_norm, train_dataset.labels)\n",
    "    optimal_c = model_tune_c.best_params_['C']\n",
    "\n",
    "    # Optimize gamma with cross-validation (optional)\n",
    "    model_tune_gamma = GridSearchCV(SVR(kernel='rbf', epsilon=optimal_eps, C=optimal_c), {'gamma':svr_gammas})\n",
    "    model_tune_gamma.fit(train_norm, train_dataset.labels)\n",
    "    optimal_gamma = model_tune_gamma.best_params_['gamma']\n",
    "\n",
    "    best_params = {\n",
    "        \"C\": optimal_c,\n",
    "        \"epsilon\": optimal_epsilon,\n",
    "        \"gamma\": optimal_gamma,\n",
    "    }\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print (f\"Elapsed time in hyperparameter optimization: {elapsed:.0f}s\")\n",
    "    print (f\"{best_params}\")\n",
    "\n",
    "    param_path = MODEL_DIR + f\"{model_name}-SVR-params_fold{fold}_best.json\"\n",
    "    with open(param_path, \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "    \n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_svr = SVR(C=optimal_c, epsilon=optimal_eps, gamma=optimal_gamma)\n",
    "    model_svr.fit(train_norm, train_dataset.labels)\n",
    "\n",
    "    preds = model_svr.predict(valid_norm)\n",
    "    preds *= 100.0\n",
    "\n",
    "    # scoring\n",
    "    # score = get_score(valid_labels, preds.argmax(1))\n",
    "    score = get_score(valid_labels, preds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    LOGGER.info(f\"Score: {score}  time: {elapsed:.0f}s\")\n",
    "\n",
    "    svr_path = MODEL_DIR + f\"{model_name}-SVR_fold{fold}_best.pkl\"\n",
    "    pickle.dump(model_svr, open(svr_path, \"wb\"))\n",
    "\n",
    "    # valid_folds[[str(c) for c in range(config.n_class)]] = es.best_preds\n",
    "    # valid_folds[\"preds\"] = es.best_preds.argmax(1)\n",
    "    # valid_folds[\"preds\"] = es.best_preds\n",
    "    valid_folds[\"preds\"] = preds\n",
    "\n",
    "    return valid_folds, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVj6cfuLc4VP"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PpdJfNgUc5N3"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    if Config.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for fold in range(config.n_fold):\n",
    "            seed_torch(seed + fold)\n",
    "\n",
    "            _oof_df, score, loss = train_loop(train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_result.append([fold, score, loss])\n",
    "\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df, fold)\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        loss = statistics.mean([d[2] for d in oof_result])\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        table = wandb.Table(data=oof_result, columns=[\"fold\", \"score\", \"loss\"])\n",
    "        run.log({\"Fold Result\": table})\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(config.model_name, type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)\n",
    "\n",
    "    # ====================================================\n",
    "    # Training SVR\n",
    "    # ====================================================\n",
    "    if Config.train2:\n",
    "        oof_df = pd.DataFrame()\n",
    "        oof_result = []\n",
    "        for n, artifact_id in enumerate(config.models):\n",
    "\n",
    "            for fold in range(config.n_fold):\n",
    "                seed_torch(seed + fold)\n",
    "                _oof_df, score = train2_loop(train, artifact_id, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df, fold)\n",
    "\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "\n",
    "            break\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
    "\n",
    "        artifact = wandb.Artifact(f\"{artifact_id.split(':')[0]}-SVR\", type=\"model\")\n",
    "        artifact.add_dir(MODEL_DIR)\n",
    "        run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-J0CDXjkUaS"
   },
   "source": [
    "# üöÄ Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oeDBzpKHdIie"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 31s (remain 71m 22s) Loss: 0.6913 Grad: 0.3804 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 2m 2s (remain 0m 45s) Loss: 0.6629 Grad: 0.2962 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 33s (remain 0m 0s) Loss: 0.6603 Grad: 0.3610 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 40s) Loss: 0.6817 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6603  avg_val_loss: 0.6667  time: 164s\n",
      "Epoch 1 - Score: 19.291995783849405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.666685).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 7m 48s) Loss: 0.6404 Grad: 0.2686 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6465 Grad: 0.3046 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6466 Grad: 0.4083 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6834 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6630 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6466  avg_val_loss: 0.6630  time: 141s\n",
      "Epoch 2 - Score: 18.756020801815673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.666685 --> 0.663039).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 8m 47s) Loss: 0.6652 Grad: 0.3731 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6539 Grad: 0.2804 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6541 Grad: 0.3167 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 40s) Loss: 0.7723 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6748 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6541  avg_val_loss: 0.6748  time: 138s\n",
      "Epoch 3 - Score: 18.454609446823774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 3s (remain 8m 41s) Loss: 0.6594 Grad: 0.3142 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6523 Grad: 0.2433 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6526 Grad: 0.2866 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6647 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6579 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6526  avg_val_loss: 0.6579  time: 145s\n",
      "Epoch 4 - Score: 18.2017081763081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.663039 --> 0.657871).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 47s) Loss: 0.6580 Grad: 0.2943 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6512 Grad: 0.3586 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6507 Grad: 0.2788 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6605 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6494 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6507  avg_val_loss: 0.6494  time: 140s\n",
      "Epoch 5 - Score: 18.29788512045263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.657871 --> 0.649427).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 3s (remain 8m 40s) Loss: 0.6588 Grad: 0.4768 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6518 Grad: 0.3558 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6499 Grad: 0.3399 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6900 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6691 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6499  avg_val_loss: 0.6691  time: 140s\n",
      "Epoch 6 - Score: 18.30756777785937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 8m 20s) Loss: 0.6210 Grad: 0.3879 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6476 Grad: 0.5587 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6485 Grad: 0.3266 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 41s) Loss: 0.6812 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6502 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6485  avg_val_loss: 0.6502  time: 145s\n",
      "Epoch 7 - Score: 18.16547415161975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 8m 51s) Loss: 0.6524 Grad: 0.3439 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6485 Grad: 0.2475 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6481 Grad: 0.3569 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6649 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6481  avg_val_loss: 0.6468  time: 140s\n",
      "Epoch 8 - Score: 18.13612429024204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6468 \n",
      "Validation loss decreased (0.649427 --> 0.646797).  Saving model ...\n",
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 7m 51s) Loss: 0.6258 Grad: 0.2798 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 32s (remain 0m 34s) Loss: 0.6360 Grad: 0.2808 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 4s (remain 0m 0s) Loss: 0.6356 Grad: 0.4663 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6588 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6454 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6356  avg_val_loss: 0.6454  time: 136s\n",
      "Epoch 9 - Score: 18.05746469058937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.646797 --> 0.645395).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 14s) Loss: 0.6199 Grad: 0.2638 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6337 Grad: 0.3148 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6336 Grad: 0.4085 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6496 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6480 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6336  avg_val_loss: 0.6480  time: 140s\n",
      "Epoch 10 - Score: 18.025649254044712\n",
      "========== fold: 0 result ==========\n",
      "Score: 18.05746\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 12s) Loss: 0.6729 Grad: 0.7036 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6622 Grad: 0.2322 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6605 Grad: 0.2089 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6540 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6578 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6605  avg_val_loss: 0.6578  time: 140s\n",
      "Epoch 1 - Score: 19.14086628945081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.657809).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 8s) Loss: 0.6724 Grad: 0.3538 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 31s (remain 0m 34s) Loss: 0.6472 Grad: 0.2567 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 2s (remain 0m 0s) Loss: 0.6466 Grad: 0.2927 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6520 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6466  avg_val_loss: 0.6580  time: 133s\n",
      "Epoch 2 - Score: 18.136175375664394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6580 \n",
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 9m 0s) Loss: 0.6427 Grad: 0.2910 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6551 Grad: 0.3098 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6543 Grad: 0.3993 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6252 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6543  avg_val_loss: 0.6447  time: 141s\n",
      "Epoch 3 - Score: 18.031163364195717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.657809 --> 0.644726).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 4s (remain 9m 26s) Loss: 0.6821 Grad: 0.4136 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6511 Grad: 0.3635 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6520 Grad: 0.3857 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6287 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6488 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6520  avg_val_loss: 0.6488  time: 144s\n",
      "Epoch 4 - Score: 18.210606094123545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 31s) Loss: 0.6302 Grad: 0.3423 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6509 Grad: 0.4359 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6514 Grad: 0.3732 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6241 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6423 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6514  avg_val_loss: 0.6423  time: 143s\n",
      "Epoch 5 - Score: 17.964646743160735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644726 --> 0.642341).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6633 Grad: 0.3501 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6516 Grad: 0.2873 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6502 Grad: 0.3434 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6232 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6414 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6502  avg_val_loss: 0.6414  time: 143s\n",
      "Epoch 6 - Score: 17.850577404086238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.642341 --> 0.641440).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 9m 2s) Loss: 0.6445 Grad: 0.3802 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 41s (remain 0m 38s) Loss: 0.6477 Grad: 0.3054 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 16s (remain 0m 0s) Loss: 0.6489 Grad: 0.3771 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6274 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6502 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6489  avg_val_loss: 0.6502  time: 147s\n",
      "Epoch 7 - Score: 17.963955680764702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 8m 51s) Loss: 0.6627 Grad: 0.3813 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6477 Grad: 0.3189 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6482 Grad: 0.2602 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 50s) Loss: 0.6230 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6439 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6482  avg_val_loss: 0.6439  time: 144s\n",
      "Epoch 8 - Score: 18.09491117792598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 8s) Loss: 0.6406 Grad: 0.2865 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6364 Grad: 0.2932 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6364 Grad: 0.2980 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6381 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6445 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6364  avg_val_loss: 0.6445  time: 140s\n",
      "Epoch 9 - Score: 18.007913537503192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 44s) Loss: 0.6322 Grad: 0.2371 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6359 Grad: 0.3920 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6356 Grad: 0.2957 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 49s) Loss: 0.6285 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6356  avg_val_loss: 0.6478  time: 142s\n",
      "Epoch 10 - Score: 18.02704088870366\n",
      "========== fold: 1 result ==========\n",
      "Score: 17.85058\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 24s) Loss: 0.7094 Grad: 0.9219 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6664 Grad: 0.3321 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 6s (remain 0m 0s) Loss: 0.6634 Grad: 0.3309 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.7260 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6660 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6634  avg_val_loss: 0.6660  time: 137s\n",
      "Epoch 1 - Score: 19.62229372060576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.665993).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 7m 46s) Loss: 0.6457 Grad: 0.2246 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6461 Grad: 0.4010 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6456 Grad: 0.3263 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6429 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6456  avg_val_loss: 0.6485  time: 139s\n",
      "Epoch 2 - Score: 18.629264094842423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.665993 --> 0.648487).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 8m 53s) Loss: 0.6639 Grad: 0.3395 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6557 Grad: 0.3028 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6543 Grad: 0.3224 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 50s) Loss: 0.6470 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6470 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6543  avg_val_loss: 0.6470  time: 142s\n",
      "Epoch 3 - Score: 18.618269934512206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.648487 --> 0.647024).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 3s (remain 8m 52s) Loss: 0.6574 Grad: 0.4029 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6524 Grad: 0.3199 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6517 Grad: 0.3259 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6481 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6517  avg_val_loss: 0.6485  time: 143s\n",
      "Epoch 4 - Score: 18.815402542648545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 21s) Loss: 0.6380 Grad: 0.3860 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6496 Grad: 0.3682 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6501 Grad: 0.3383 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6472 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6475 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6501  avg_val_loss: 0.6475  time: 144s\n",
      "Epoch 5 - Score: 18.682450171638553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 4s (remain 9m 32s) Loss: 0.6462 Grad: 0.3104 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6499 Grad: 0.4363 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6499 Grad: 0.3560 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 50s) Loss: 0.6450 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6467 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6499  avg_val_loss: 0.6467  time: 141s\n",
      "Epoch 6 - Score: 18.58784911537809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.647024 --> 0.646686).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 8m 48s) Loss: 0.6651 Grad: 0.3683 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6490 Grad: 0.4456 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6491 Grad: 0.2712 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6449 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6491  avg_val_loss: 0.6455  time: 145s\n",
      "Epoch 7 - Score: 18.428549890253574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.646686 --> 0.645458).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 4s (remain 9m 20s) Loss: 0.6251 Grad: 0.4062 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6477 Grad: 0.3955 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6484 Grad: 0.3623 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6447 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6458 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6484  avg_val_loss: 0.6458  time: 143s\n",
      "Epoch 8 - Score: 18.4705082060192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 45s) Loss: 0.6388 Grad: 0.2861 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6358 Grad: 0.3111 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6355 Grad: 0.4219 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6455 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6355  avg_val_loss: 0.6447  time: 139s\n",
      "Epoch 9 - Score: 18.327161694926236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645458 --> 0.644690).  Saving model ...\n",
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 24s) Loss: 0.6281 Grad: 0.3867 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6316 Grad: 0.2718 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6335 Grad: 0.3070 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6413 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6446 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6335  avg_val_loss: 0.6446  time: 138s\n",
      "Epoch 10 - Score: 18.334804291949727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.644690 --> 0.644600).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 18.33480\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 27s) Loss: 0.6745 Grad: 0.7555 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6626 Grad: 0.4489 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6594 Grad: 0.2832 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6547 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6673 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6594  avg_val_loss: 0.6673  time: 143s\n",
      "Epoch 1 - Score: 19.236922139048612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.667313).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 28s) Loss: 0.6282 Grad: 0.4198 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6458 Grad: 0.3313 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6455 Grad: 0.4608 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6854 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6582 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6455  avg_val_loss: 0.6582  time: 141s\n",
      "Epoch 2 - Score: 18.471873861096462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.667313 --> 0.658221).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 9m 3s) Loss: 0.6656 Grad: 0.3054 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6545 Grad: 0.3417 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6543 Grad: 0.3839 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6529 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6474 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6543  avg_val_loss: 0.6474  time: 142s\n",
      "Epoch 3 - Score: 18.425125934546656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.658221 --> 0.647398).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 4s (remain 9m 22s) Loss: 0.6477 Grad: 0.3263 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6517 Grad: 0.3157 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6526 Grad: 0.3151 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6589 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6520 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6526  avg_val_loss: 0.6520  time: 143s\n",
      "Epoch 4 - Score: 18.857599243547483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 9m 11s) Loss: 0.6387 Grad: 0.4216 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6504 Grad: 0.4613 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 15s (remain 0m 0s) Loss: 0.6500 Grad: 0.3523 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 49s) Loss: 0.6526 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6498 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6500  avg_val_loss: 0.6498  time: 146s\n",
      "Epoch 5 - Score: 18.41480169373943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 3s (remain 8m 59s) Loss: 0.6504 Grad: 0.3844 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6508 Grad: 0.3691 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6506 Grad: 0.3502 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6534 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6506  avg_val_loss: 0.6456  time: 140s\n",
      "Epoch 6 - Score: 18.238023274523176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.647398 --> 0.645587).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 9m 7s) Loss: 0.6752 Grad: 0.4591 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6484 Grad: 0.3910 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6487 Grad: 0.3935 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6581 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6487  avg_val_loss: 0.6485  time: 141s\n",
      "Epoch 7 - Score: 18.475035047133332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6698 Grad: 0.5214 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6481 Grad: 0.3416 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6482 Grad: 0.7111 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6551 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6496 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6482  avg_val_loss: 0.6496  time: 145s\n",
      "Epoch 8 - Score: 18.334733683190752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 25s) Loss: 0.6481 Grad: 0.2590 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6358 Grad: 0.3184 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6353 Grad: 0.3076 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6538 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6353  avg_val_loss: 0.6514  time: 141s\n",
      "Epoch 9 - Score: 17.86707892775217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6514 \n",
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 21s) Loss: 0.6196 Grad: 0.2445 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6336 Grad: 0.2683 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6338 Grad: 0.3348 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6592 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6636 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6338  avg_val_loss: 0.6636  time: 140s\n",
      "Epoch 10 - Score: 18.169123635285224\n",
      "========== fold: 3 result ==========\n",
      "Score: 18.23802\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 2s) Loss: 0.7041 Grad: 0.8536 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6657 Grad: 0.2455 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6627 Grad: 0.2513 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6796 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6627  avg_val_loss: 0.7086  time: 143s\n",
      "Epoch 1 - Score: 19.437899887609472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.7086 \n",
      "Validation loss decreased (inf --> 0.708579).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 26s) Loss: 0.6493 Grad: 0.2399 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6470 Grad: 0.3638 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6469 Grad: 0.3398 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6734 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6885 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6469  avg_val_loss: 0.6885  time: 141s\n",
      "Epoch 2 - Score: 18.662918356821592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.708579 --> 0.688479).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 8m 43s) Loss: 0.6754 Grad: 0.2910 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6566 Grad: 0.4403 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6561 Grad: 0.3529 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6442 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6560 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6561  avg_val_loss: 0.6560  time: 142s\n",
      "Epoch 3 - Score: 18.399911490643262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.688479 --> 0.656047).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 4s (remain 9m 23s) Loss: 0.6563 Grad: 0.3737 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6523 Grad: 0.4039 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6523 Grad: 0.3032 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 40s) Loss: 0.6429 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6523  avg_val_loss: 0.6665  time: 144s\n",
      "Epoch 4 - Score: 18.416778416178612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6665 \n",
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 9m 5s) Loss: 0.6578 Grad: 0.3856 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6503 Grad: 0.2755 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6506 Grad: 0.3683 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6488 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6553 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6506  avg_val_loss: 0.6553  time: 143s\n",
      "Epoch 5 - Score: 18.74837815287389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.656047 --> 0.655326).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 4s (remain 9m 21s) Loss: 0.6776 Grad: 0.4698 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6489 Grad: 0.3458 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6497 Grad: 0.3399 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6463 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6518 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6497  avg_val_loss: 0.6518  time: 145s\n",
      "Epoch 6 - Score: 18.630868370946065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.655326 --> 0.651792).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6711 Grad: 0.3615 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6484 Grad: 0.4140 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6491 Grad: 0.4908 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6424 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6673 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6491  avg_val_loss: 0.6673  time: 145s\n",
      "Epoch 7 - Score: 18.378447720821114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 4s (remain 9m 22s) Loss: 0.6454 Grad: 0.2629 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6497 Grad: 0.2796 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6500 Grad: 0.3216 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 49s) Loss: 0.6448 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6610 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6500  avg_val_loss: 0.6610  time: 144s\n",
      "Epoch 8 - Score: 18.499088260413224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 7m 59s) Loss: 0.6028 Grad: 0.2700 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6352 Grad: 0.3730 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6361 Grad: 0.2905 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6430 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6711 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6361  avg_val_loss: 0.6711  time: 142s\n",
      "Epoch 9 - Score: 18.287540889169282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 17s) Loss: 0.6513 Grad: 0.3892 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 31s (remain 0m 34s) Loss: 0.6352 Grad: 0.3139 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 3s (remain 0m 0s) Loss: 0.6345 Grad: 0.2598 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6432 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6441 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6345  avg_val_loss: 0.6441  time: 135s\n",
      "Epoch 10 - Score: 18.225045044837398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.651792 --> 0.644089).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "Score: 18.22505\n",
      "========== fold: 5 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 7m 55s) Loss: 0.6870 Grad: 1.0830 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6628 Grad: 0.3106 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6605 Grad: 0.3193 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 41s) Loss: 0.6854 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6578 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6605  avg_val_loss: 0.6578  time: 142s\n",
      "Epoch 1 - Score: 19.502719598578935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.657840).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 15s) Loss: 0.6633 Grad: 0.3123 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6465 Grad: 0.3392 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6461 Grad: 0.3708 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.8259 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6654 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6461  avg_val_loss: 0.6654  time: 139s\n",
      "Epoch 2 - Score: 18.475024321337266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/139] Elapsed 0m 4s (remain 9m 12s) Loss: 0.6505 Grad: 0.3245 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6559 Grad: 0.3111 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 15s (remain 0m 0s) Loss: 0.6548 Grad: 0.2937 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6738 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6548  avg_val_loss: 0.6478  time: 146s\n",
      "Epoch 3 - Score: 18.19411702065891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.657840 --> 0.647755).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 3s (remain 8m 33s) Loss: 0.6709 Grad: 0.4613 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6517 Grad: 0.2340 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6526 Grad: 0.3291 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6634 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6527 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6526  avg_val_loss: 0.6527  time: 145s\n",
      "Epoch 4 - Score: 19.00659492247682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 28s) Loss: 0.6502 Grad: 0.3047 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6509 Grad: 0.3247 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6507 Grad: 0.3632 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6571 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6459 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6507  avg_val_loss: 0.6459  time: 138s\n",
      "Epoch 5 - Score: 18.20646768330303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.647755 --> 0.645932).  Saving model ...\n",
      "Epoch: [6][0/139] Elapsed 0m 4s (remain 9m 17s) Loss: 0.6567 Grad: 0.4127 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6508 Grad: 0.3154 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 10s (remain 0m 0s) Loss: 0.6497 Grad: 0.3048 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6566 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6497  avg_val_loss: 0.6456  time: 142s\n",
      "Epoch 6 - Score: 18.16344858250978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645932 --> 0.645616).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6592 Grad: 0.3092 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6487 Grad: 0.4349 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6502 Grad: 0.3149 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6532 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6503 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6502  avg_val_loss: 0.6503  time: 145s\n",
      "Epoch 7 - Score: 17.921331143594646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6513 Grad: 0.3670 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6488 Grad: 0.2829 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6486 Grad: 0.3409 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6542 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6486  avg_val_loss: 0.6437  time: 146s\n",
      "Epoch 8 - Score: 17.899412900912438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645616 --> 0.643707).  Saving model ...\n",
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 9s) Loss: 0.6452 Grad: 0.2755 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 29s (remain 0m 33s) Loss: 0.6361 Grad: 0.3033 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 1s (remain 0m 0s) Loss: 0.6361 Grad: 0.3437 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.7022 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6494 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6361  avg_val_loss: 0.6494  time: 132s\n",
      "Epoch 9 - Score: 18.228472644245297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 19s) Loss: 0.6215 Grad: 0.2931 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6344 Grad: 0.2740 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6346 Grad: 0.3332 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.7844 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6625 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6346  avg_val_loss: 0.6625  time: 140s\n",
      "Epoch 10 - Score: 18.19033896748876\n",
      "========== fold: 5 result ==========\n",
      "Score: 17.89941\n",
      "========== fold: 6 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 7m 57s) Loss: 0.7153 Grad: 0.9059 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 32s (remain 0m 34s) Loss: 0.6664 Grad: 0.3806 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 5s (remain 0m 0s) Loss: 0.6631 Grad: 0.2449 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6724 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6796 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6631  avg_val_loss: 0.6796  time: 136s\n",
      "Epoch 1 - Score: 19.35678731807889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.679554).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 28s) Loss: 0.6396 Grad: 0.2278 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6466 Grad: 0.2542 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6460 Grad: 0.2611 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6657 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6944 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6460  avg_val_loss: 0.6944  time: 138s\n",
      "Epoch 2 - Score: 18.672770254905803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/139] Elapsed 0m 4s (remain 9m 28s) Loss: 0.6586 Grad: 0.2704 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6558 Grad: 0.4225 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6547 Grad: 0.3064 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6624 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.7043 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6547  avg_val_loss: 0.7043  time: 145s\n",
      "Epoch 3 - Score: 18.779768082295877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/139] Elapsed 0m 4s (remain 9m 32s) Loss: 0.6371 Grad: 0.3065 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6513 Grad: 0.3402 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6515 Grad: 0.3232 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6626 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6692 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6515  avg_val_loss: 0.6692  time: 143s\n",
      "Epoch 4 - Score: 18.528459274190453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.679554 --> 0.669232).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 9m 7s) Loss: 0.6798 Grad: 0.5841 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6509 Grad: 0.3968 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6505 Grad: 0.3682 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6612 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6505  avg_val_loss: 0.6826  time: 145s\n",
      "Epoch 5 - Score: 18.43469426003098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 4s (remain 9m 27s) Loss: 0.6535 Grad: 0.4029 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 41s (remain 0m 38s) Loss: 0.6489 Grad: 0.2522 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 15s (remain 0m 0s) Loss: 0.6495 Grad: 0.2958 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6621 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6495  avg_val_loss: 0.6826  time: 147s\n",
      "Epoch 6 - Score: 18.385599333285622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 4s (remain 9m 27s) Loss: 0.6272 Grad: 0.4211 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6486 Grad: 0.3091 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6480 Grad: 0.4505 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6594 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6929 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6480  avg_val_loss: 0.6929  time: 145s\n",
      "Epoch 7 - Score: 18.457427748762772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 8m 54s) Loss: 0.6701 Grad: 0.4170 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6490 Grad: 0.3320 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6488 Grad: 0.3117 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6698 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6765 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6488  avg_val_loss: 0.6765  time: 143s\n",
      "Epoch 8 - Score: 18.494061339625773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 17s) Loss: 0.6488 Grad: 0.3330 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6366 Grad: 0.2967 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6360 Grad: 0.3210 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6637 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6704 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6360  avg_val_loss: 0.6704  time: 139s\n",
      "Epoch 9 - Score: 18.235339168069785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 16s) Loss: 0.6538 Grad: 0.3008 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6359 Grad: 0.2746 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6344 Grad: 0.4060 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6650 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6761 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6344  avg_val_loss: 0.6761  time: 143s\n",
      "Epoch 10 - Score: 18.21091507743001\n",
      "========== fold: 6 result ==========\n",
      "Score: 18.52846\n",
      "========== fold: 7 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 28s) Loss: 0.6910 Grad: 0.6539 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6637 Grad: 0.2160 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6608 Grad: 0.2697 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6484 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6784 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6608  avg_val_loss: 0.6784  time: 144s\n",
      "Epoch 1 - Score: 19.70757345970273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.678358).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 17s) Loss: 0.6376 Grad: 0.2135 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6470 Grad: 0.2661 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6459 Grad: 0.3373 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6369 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6970 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6459  avg_val_loss: 0.6970  time: 140s\n",
      "Epoch 2 - Score: 19.056024180449306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/139] Elapsed 0m 3s (remain 9m 2s) Loss: 0.6393 Grad: 0.3692 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 33s (remain 0m 35s) Loss: 0.6549 Grad: 0.2669 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 6s (remain 0m 0s) Loss: 0.6550 Grad: 0.2751 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6394 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6621 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6550  avg_val_loss: 0.6621  time: 137s\n",
      "Epoch 3 - Score: 18.934440961459337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.678358 --> 0.662067).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 3s (remain 8m 49s) Loss: 0.6710 Grad: 0.3571 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6532 Grad: 0.3622 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6522 Grad: 0.3512 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6350 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6473 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6522  avg_val_loss: 0.6473  time: 144s\n",
      "Epoch 4 - Score: 18.585214291134303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.662067 --> 0.647314).  Saving model ...\n",
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 56s) Loss: 0.6469 Grad: 0.3815 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 38s (remain 0m 37s) Loss: 0.6503 Grad: 0.3071 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 12s (remain 0m 0s) Loss: 0.6500 Grad: 0.3347 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6364 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6500  avg_val_loss: 0.6486  time: 143s\n",
      "Epoch 5 - Score: 18.635647453909886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 3s (remain 8m 48s) Loss: 0.6398 Grad: 0.3168 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6484 Grad: 0.3086 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 15s (remain 0m 0s) Loss: 0.6494 Grad: 0.3528 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6360 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6490 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6494  avg_val_loss: 0.6490  time: 146s\n",
      "Epoch 6 - Score: 18.650536977342846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/139] Elapsed 0m 4s (remain 9m 19s) Loss: 0.6358 Grad: 0.2965 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6490 Grad: 0.3446 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6484 Grad: 0.3916 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6372 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6484  avg_val_loss: 0.6478  time: 144s\n",
      "Epoch 7 - Score: 18.66185436455182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 4s (remain 9m 15s) Loss: 0.6570 Grad: 0.3280 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6484 Grad: 0.3166 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6485 Grad: 0.3404 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6376 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6521 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6485  avg_val_loss: 0.6521  time: 139s\n",
      "Epoch 8 - Score: 18.82707638021603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 7m 58s) Loss: 0.6304 Grad: 0.2650 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6364 Grad: 0.3376 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6361 Grad: 0.2403 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6357 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6551 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6361  avg_val_loss: 0.6551  time: 139s\n",
      "Epoch 9 - Score: 18.70640027011788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 34s) Loss: 0.6069 Grad: 0.3933 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 33s (remain 0m 35s) Loss: 0.6348 Grad: 0.2311 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 5s (remain 0m 0s) Loss: 0.6344 Grad: 0.3578 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6360 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6469 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6344  avg_val_loss: 0.6469  time: 136s\n",
      "Epoch 10 - Score: 18.542819899234537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.647314 --> 0.646885).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 7 result ==========\n",
      "Score: 18.54282\n",
      "========== fold: 8 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 7m 56s) Loss: 0.6890 Grad: 0.7390 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6634 Grad: 0.3063 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6616 Grad: 0.2433 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 44s) Loss: 0.6411 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6821 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6616  avg_val_loss: 0.6821  time: 139s\n",
      "Epoch 1 - Score: 19.339506374396173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.682067).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 14s) Loss: 0.6540 Grad: 0.2574 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6479 Grad: 0.3072 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6474 Grad: 0.2579 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6359 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6474  avg_val_loss: 0.6765  time: 139s\n",
      "Epoch 2 - Score: 18.723469401542886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6765 \n",
      "Validation loss decreased (0.682067 --> 0.676535).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 4s (remain 9m 17s) Loss: 0.6647 Grad: 0.3852 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6556 Grad: 0.2980 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6552 Grad: 0.2461 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6392 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6639 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6552  avg_val_loss: 0.6639  time: 141s\n",
      "Epoch 3 - Score: 18.425920009998723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.676535 --> 0.663909).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 3s (remain 9m 1s) Loss: 0.6471 Grad: 0.2676 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 41s (remain 0m 38s) Loss: 0.6522 Grad: 0.3360 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 16s (remain 0m 0s) Loss: 0.6524 Grad: 0.3945 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6428 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6524  avg_val_loss: 0.6690  time: 147s\n",
      "Epoch 4 - Score: 18.84661641357598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 8m 53s) Loss: 0.6535 Grad: 0.2310 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6512 Grad: 0.3531 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6512 Grad: 0.3327 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 41s) Loss: 0.6377 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6783 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6512  avg_val_loss: 0.6783  time: 139s\n",
      "Epoch 5 - Score: 18.465021068426218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 4s (remain 9m 26s) Loss: 0.6317 Grad: 0.2846 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6475 Grad: 0.3235 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6493 Grad: 0.3619 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 42s) Loss: 0.6378 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6466 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6493  avg_val_loss: 0.6466  time: 144s\n",
      "Epoch 6 - Score: 18.433173074378207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.663909 --> 0.646559).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 4s (remain 9m 18s) Loss: 0.6463 Grad: 0.3001 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6487 Grad: 0.2766 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6493 Grad: 0.3842 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 41s) Loss: 0.6428 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6495 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6493  avg_val_loss: 0.6495  time: 143s\n",
      "Epoch 7 - Score: 18.41673593805224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/139] Elapsed 0m 3s (remain 8m 34s) Loss: 0.6582 Grad: 0.5441 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6492 Grad: 0.3496 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6484 Grad: 0.3165 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6406 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6501 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6484  avg_val_loss: 0.6501  time: 144s\n",
      "Epoch 8 - Score: 18.352107693874885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 20s) Loss: 0.6331 Grad: 0.2399 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 34s (remain 0m 35s) Loss: 0.6367 Grad: 0.3451 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 7s (remain 0m 0s) Loss: 0.6361 Grad: 0.3700 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6334 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6488 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6361  avg_val_loss: 0.6488  time: 138s\n",
      "Epoch 9 - Score: 18.187953803299347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 8s) Loss: 0.6290 Grad: 0.2515 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6346 Grad: 0.2943 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6346 Grad: 0.2635 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6324 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6494 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6346  avg_val_loss: 0.6494  time: 141s\n",
      "Epoch 10 - Score: 18.13650116892637\n",
      "========== fold: 8 result ==========\n",
      "Score: 18.43317\n",
      "========== fold: 9 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/139] Elapsed 0m 3s (remain 8m 25s) Loss: 0.6787 Grad: 0.7145 LR: 1.00e-05  \n",
      "Epoch: [1][100/139] Elapsed 1m 37s (remain 0m 36s) Loss: 0.6625 Grad: 0.3853 LR: 9.88e-06  \n",
      "Epoch: [1][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6591 Grad: 0.3037 LR: 9.78e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 49s) Loss: 0.6559 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6591  avg_val_loss: 0.6732  time: 142s\n",
      "Epoch 1 - Score: 19.019648402078804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.673158).  Saving model ...\n",
      "Epoch: [2][0/139] Elapsed 0m 3s (remain 8m 8s) Loss: 0.6349 Grad: 0.2875 LR: 9.78e-06  \n",
      "Epoch: [2][100/139] Elapsed 1m 35s (remain 0m 35s) Loss: 0.6447 Grad: 0.2960 LR: 9.35e-06  \n",
      "Epoch: [2][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6451 Grad: 0.2745 LR: 9.14e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6475 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6569 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6451  avg_val_loss: 0.6569  time: 140s\n",
      "Epoch 2 - Score: 18.36662961748693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.673158 --> 0.656899).  Saving model ...\n",
      "Epoch: [3][0/139] Elapsed 0m 4s (remain 9m 18s) Loss: 0.6588 Grad: 0.3691 LR: 9.13e-06  \n",
      "Epoch: [3][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6528 Grad: 0.3814 LR: 8.45e-06  \n",
      "Epoch: [3][138/139] Elapsed 2m 13s (remain 0m 0s) Loss: 0.6535 Grad: 0.3587 LR: 8.15e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 48s) Loss: 0.6447 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6506 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6535  avg_val_loss: 0.6506  time: 144s\n",
      "Epoch 3 - Score: 18.506617504383584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.656899 --> 0.650564).  Saving model ...\n",
      "Epoch: [4][0/139] Elapsed 0m 4s (remain 9m 29s) Loss: 0.6562 Grad: 0.3550 LR: 8.14e-06  \n",
      "Epoch: [4][100/139] Elapsed 1m 38s (remain 0m 36s) Loss: 0.6508 Grad: 0.3779 LR: 7.25e-06  \n",
      "Epoch: [4][138/139] Elapsed 2m 11s (remain 0m 0s) Loss: 0.6512 Grad: 0.3444 LR: 6.89e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 50s) Loss: 0.6465 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6554 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6512  avg_val_loss: 0.6554  time: 143s\n",
      "Epoch 4 - Score: 18.411465430016396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/139] Elapsed 0m 3s (remain 9m 9s) Loss: 0.6569 Grad: 0.3450 LR: 6.88e-06  \n",
      "Epoch: [5][100/139] Elapsed 1m 40s (remain 0m 37s) Loss: 0.6512 Grad: 0.4108 LR: 5.89e-06  \n",
      "Epoch: [5][138/139] Elapsed 2m 15s (remain 0m 0s) Loss: 0.6508 Grad: 0.3431 LR: 5.50e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6449 \n",
      "EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.6506 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6508  avg_val_loss: 0.6506  time: 146s\n",
      "Epoch 5 - Score: 18.16106221402934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/139] Elapsed 0m 3s (remain 9m 6s) Loss: 0.6712 Grad: 0.3559 LR: 5.49e-06  \n",
      "Epoch: [6][100/139] Elapsed 1m 39s (remain 0m 37s) Loss: 0.6501 Grad: 0.3377 LR: 4.48e-06  \n",
      "Epoch: [6][138/139] Elapsed 2m 14s (remain 0m 0s) Loss: 0.6501 Grad: 0.3940 LR: 4.11e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6467 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6501  avg_val_loss: 0.6457  time: 146s\n",
      "Epoch 6 - Score: 18.23290814157467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6457 \n",
      "Validation loss decreased (0.650564 --> 0.645673).  Saving model ...\n",
      "Epoch: [7][0/139] Elapsed 0m 3s (remain 8m 59s) Loss: 0.6393 Grad: 0.3704 LR: 4.10e-06  \n",
      "Epoch: [7][100/139] Elapsed 1m 35s (remain 0m 36s) Loss: 0.6506 Grad: 0.4147 LR: 3.18e-06  \n",
      "Epoch: [7][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6493 Grad: 0.3720 LR: 2.85e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 46s) Loss: 0.6448 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6451 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.6493  avg_val_loss: 0.6451  time: 141s\n",
      "Epoch 7 - Score: 18.169827359724273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.645673 --> 0.645111).  Saving model ...\n",
      "Epoch: [8][0/139] Elapsed 0m 4s (remain 9m 15s) Loss: 0.6685 Grad: 0.3911 LR: 2.85e-06  \n",
      "Epoch: [8][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6476 Grad: 0.4363 LR: 2.10e-06  \n",
      "Epoch: [8][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6478 Grad: 0.3051 LR: 1.86e-06  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 45s) Loss: 0.6452 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6454 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6478  avg_val_loss: 0.6454  time: 140s\n",
      "Epoch 8 - Score: 18.193776740292517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/139] Elapsed 0m 3s (remain 8m 48s) Loss: 0.6035 Grad: 0.3493 LR: 1.85e-06  \n",
      "Epoch: [9][100/139] Elapsed 1m 35s (remain 0m 36s) Loss: 0.6358 Grad: 0.3433 LR: 1.36e-06  \n",
      "Epoch: [9][138/139] Elapsed 2m 8s (remain 0m 0s) Loss: 0.6349 Grad: 0.3095 LR: 1.22e-06  \n",
      "EVAL: [0/16] Elapsed 0m 2s (remain 0m 43s) Loss: 0.6423 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6488 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6349  avg_val_loss: 0.6488  time: 139s\n",
      "Epoch 9 - Score: 18.127350927045157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/139] Elapsed 0m 3s (remain 8m 20s) Loss: 0.6432 Grad: 0.2841 LR: 1.22e-06  \n",
      "Epoch: [10][100/139] Elapsed 1m 36s (remain 0m 36s) Loss: 0.6337 Grad: 0.2795 LR: 1.02e-06  \n",
      "Epoch: [10][138/139] Elapsed 2m 9s (remain 0m 0s) Loss: 0.6337 Grad: 0.3803 LR: 1.00e-05  \n",
      "EVAL: [0/16] Elapsed 0m 3s (remain 0m 47s) Loss: 0.6468 \n",
      "EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.6486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6337  avg_val_loss: 0.6486  time: 140s\n",
      "Epoch 10 - Score: 18.043170434237968\n",
      "========== fold: 9 result ==========\n",
      "Score: 18.16983\n",
      "========== CV ==========\n",
      "Score: 18.22935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 8.1s\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "8ijJJUa2d2Lx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2624670... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4504.64MB of 4504.64MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>‚ñÅ</td></tr><tr><td>Score_fold0</td><td>‚ñÅ</td></tr><tr><td>Score_fold1</td><td>‚ñÅ</td></tr><tr><td>Score_fold2</td><td>‚ñÅ</td></tr><tr><td>Score_fold3</td><td>‚ñÅ</td></tr><tr><td>Score_fold4</td><td>‚ñÅ</td></tr><tr><td>Score_fold5</td><td>‚ñÅ</td></tr><tr><td>Score_fold6</td><td>‚ñÅ</td></tr><tr><td>Score_fold7</td><td>‚ñÅ</td></tr><tr><td>Score_fold8</td><td>‚ñÅ</td></tr><tr><td>Score_fold9</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñà</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr><tr><td>loss/train_fold0</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ</td></tr><tr><td>loss/train_fold1</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold2</td><td>‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold3</td><td>‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold4</td><td>‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold5</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold6</td><td>‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold7</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold8</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/train_fold9</td><td>‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold0</td><td>‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ</td></tr><tr><td>loss/valid_fold1</td><td>‚ñà‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÑ</td></tr><tr><td>loss/valid_fold2</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss/valid_fold3</td><td>‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñá</td></tr><tr><td>loss/valid_fold4</td><td>‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÅ</td></tr><tr><td>loss/valid_fold5</td><td>‚ñÜ‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñá</td></tr><tr><td>loss/valid_fold6</td><td>‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>loss/valid_fold7</td><td>‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>loss/valid_fold8</td><td>‚ñà‚ñá‚ñÑ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>loss/valid_fold9</td><td>‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold0</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold1</td><td>‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold2</td><td>‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold3</td><td>‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ</td></tr><tr><td>score/fold4</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold5</td><td>‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>score/fold6</td><td>‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold7</td><td>‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>score/fold8</td><td>‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>score/fold9</td><td>‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Score</td><td>18.22935</td></tr><tr><td>Score_fold0</td><td>18.05746</td></tr><tr><td>Score_fold1</td><td>17.85058</td></tr><tr><td>Score_fold2</td><td>18.3348</td></tr><tr><td>Score_fold3</td><td>18.23802</td></tr><tr><td>Score_fold4</td><td>18.22505</td></tr><tr><td>Score_fold5</td><td>17.89941</td></tr><tr><td>Score_fold6</td><td>18.52846</td></tr><tr><td>Score_fold7</td><td>18.54282</td></tr><tr><td>Score_fold8</td><td>18.43317</td></tr><tr><td>Score_fold9</td><td>18.16983</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.64726</td></tr><tr><td>loss/train_fold0</td><td>0.63361</td></tr><tr><td>loss/train_fold1</td><td>0.63563</td></tr><tr><td>loss/train_fold2</td><td>0.63353</td></tr><tr><td>loss/train_fold3</td><td>0.63376</td></tr><tr><td>loss/train_fold4</td><td>0.63452</td></tr><tr><td>loss/train_fold5</td><td>0.63455</td></tr><tr><td>loss/train_fold6</td><td>0.63437</td></tr><tr><td>loss/train_fold7</td><td>0.63444</td></tr><tr><td>loss/train_fold8</td><td>0.63455</td></tr><tr><td>loss/train_fold9</td><td>0.63368</td></tr><tr><td>loss/valid_fold0</td><td>0.64801</td></tr><tr><td>loss/valid_fold1</td><td>0.64779</td></tr><tr><td>loss/valid_fold2</td><td>0.6446</td></tr><tr><td>loss/valid_fold3</td><td>0.66357</td></tr><tr><td>loss/valid_fold4</td><td>0.64409</td></tr><tr><td>loss/valid_fold5</td><td>0.66255</td></tr><tr><td>loss/valid_fold6</td><td>0.67606</td></tr><tr><td>loss/valid_fold7</td><td>0.64688</td></tr><tr><td>loss/valid_fold8</td><td>0.64943</td></tr><tr><td>loss/valid_fold9</td><td>0.64859</td></tr><tr><td>score/fold0</td><td>18.02565</td></tr><tr><td>score/fold1</td><td>18.02704</td></tr><tr><td>score/fold2</td><td>18.3348</td></tr><tr><td>score/fold3</td><td>18.16912</td></tr><tr><td>score/fold4</td><td>18.22505</td></tr><tr><td>score/fold5</td><td>18.19034</td></tr><tr><td>score/fold6</td><td>18.21092</td></tr><tr><td>score/fold7</td><td>18.54282</td></tr><tr><td>score/fold8</td><td>18.1365</td></tr><tr><td>score/fold9</td><td>18.04317</td></tr></table>\n",
       "</div></div>\n",
       "Synced 7 W&B file(s), 1 media file(s), 11 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dry-lion-56</strong>: <a href=\"https://wandb.ai/imokuri/petfinder2/runs/11d0mnwv\" target=\"_blank\">https://wandb.ai/imokuri/petfinder2/runs/11d0mnwv</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211008_005102-11d0mnwv/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "petfinder2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38-all-in-one",
   "language": "python",
   "name": "py38-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
